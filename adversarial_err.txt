Loading python/3.8.13/slu6jvw
  Loading requirement: bzip2/1.0.8/xipsq2f libmd/1.0.4/sioeueg
    libbsd/0.11.5/gdafde7 expat/2.4.8/5wnje43 ncurses/6.2/pqxvmoe
    readline/8.1/52qiwcn gdbm/1.23/lkx5uz6 libiconv/1.16/lr5guq5
    xz/5.2.5/khdza45 zlib/1.2.12/bsohwcg libxml2/2.9.13/f5kumg5 pigz/2.7/zay4a5o
    zstd/1.5.2/jvujieu tar/1.34/4cnckqw gettext/0.21/hgt6t5w
    libffi/3.4.2/svyohlf openssl/1.1.1o/bowp5gw sqlite/3.38.5/ulzkiln
    util-linux-uuid/2.37.4/nlecwm6
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_112951-4an2bxls
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-monkey-99
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/4an2bxls
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.297 MB of 0.316 MB uploadedwandb: \ 0.318 MB of 0.318 MB uploadedwandb: | 0.319 MB of 0.319 MB uploadedwandb: / 0.319 MB of 0.319 MB uploadedwandb: - 0.319 MB of 0.319 MB uploadedwandb: \ 0.319 MB of 0.319 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 2.85335
wandb:       example_0/auto_mse 0.01038
wandb:  example_0/mlp_euclidean nan
wandb:        example_0/mlp_mse nan
wandb: example_1/auto_euclidean 4.62834
wandb:       example_1/auto_mse 0.02732
wandb:  example_1/mlp_euclidean 3.46387
wandb:        example_1/mlp_mse 0.0153
wandb: example_2/auto_euclidean 5.5554
wandb:       example_2/auto_mse 0.03937
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run sage-monkey-99 at: https://wandb.ai/cavaokcava/autoadvex/runs/4an2bxls
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_112951-4an2bxls/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113011-qpe0bkti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-bird-100
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/qpe0bkti
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.277 MB of 0.328 MB uploadedwandb: \ 0.328 MB of 0.328 MB uploadedwandb: | 0.328 MB of 0.328 MB uploadedwandb: / 0.328 MB of 0.328 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.85766
wandb:       example_0/auto_mse 0.0301
wandb:  example_0/mlp_euclidean 3.38774
wandb:        example_0/mlp_mse 0.01464
wandb: example_1/auto_euclidean 6.0254
wandb:       example_1/auto_mse 0.04631
wandb:  example_1/mlp_euclidean 7.03022
wandb:        example_1/mlp_mse 0.06304
wandb: example_2/auto_euclidean 6.84449
wandb:       example_2/auto_mse 0.05975
wandb:  example_2/mlp_euclidean 4.76587
wandb:        example_2/mlp_mse 0.02897
wandb: 
wandb: üöÄ View run sunny-bird-100 at: https://wandb.ai/cavaokcava/autoadvex/runs/qpe0bkti
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113011-qpe0bkti/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113028-x8qk929c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-music-101
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/x8qk929c
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.317 MB of 0.321 MB uploadedwandb: \ 0.321 MB of 0.321 MB uploadedwandb: | 0.321 MB of 0.321 MB uploadedwandb: / 0.321 MB of 0.321 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 3.8081
wandb:       example_0/auto_mse 0.0185
wandb:  example_0/mlp_euclidean 3.02907
wandb:        example_0/mlp_mse 0.0117
wandb: example_1/auto_euclidean 3.4866
wandb:       example_1/auto_mse 0.01551
wandb:  example_1/mlp_euclidean 2.54157
wandb:        example_1/mlp_mse 0.00824
wandb: example_2/auto_euclidean 4.99936
wandb:       example_2/auto_mse 0.03188
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run twilight-music-101 at: https://wandb.ai/cavaokcava/autoadvex/runs/x8qk929c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113028-x8qk929c/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113045-z5zfvkvs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-cherry-102
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/z5zfvkvs
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.318 MB of 0.318 MB uploadedwandb: \ 0.318 MB of 0.318 MB uploadedwandb: | 0.318 MB of 0.318 MB uploadedwandb: / 0.318 MB of 0.318 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 5.5735
wandb:       example_0/auto_mse 0.03962
wandb:  example_0/mlp_euclidean 4.47182
wandb:        example_0/mlp_mse 0.02551
wandb: example_1/auto_euclidean 4.29154
wandb:       example_1/auto_mse 0.02349
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 5.21976
wandb:       example_2/auto_mse 0.03475
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run eternal-cherry-102 at: https://wandb.ai/cavaokcava/autoadvex/runs/z5zfvkvs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113045-z5zfvkvs/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113104-45gi5d35
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-rain-103
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/45gi5d35
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.256 MB of 0.322 MB uploadedwandb: \ 0.323 MB of 0.323 MB uploadedwandb: | 0.323 MB of 0.323 MB uploadedwandb: / 0.323 MB of 0.323 MB uploadedwandb: - 0.323 MB of 0.323 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.00812
wandb:       example_0/auto_mse 0.02049
wandb:  example_0/mlp_euclidean nan
wandb:        example_0/mlp_mse nan
wandb: example_1/auto_euclidean 5.11746
wandb:       example_1/auto_mse 0.0334
wandb:  example_1/mlp_euclidean 3.14416
wandb:        example_1/mlp_mse 0.01261
wandb: example_2/auto_euclidean 5.15198
wandb:       example_2/auto_mse 0.03386
wandb:  example_2/mlp_euclidean 3.83045
wandb:        example_2/mlp_mse 0.01871
wandb: 
wandb: üöÄ View run treasured-rain-103 at: https://wandb.ai/cavaokcava/autoadvex/runs/45gi5d35
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113104-45gi5d35/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113122-asveozcs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-blaze-104
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/asveozcs
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.253 MB of 0.319 MB uploadedwandb: \ 0.319 MB of 0.319 MB uploadedwandb: | 0.319 MB of 0.319 MB uploadedwandb: / 0.319 MB of 0.319 MB uploadedwandb: - 0.319 MB of 0.319 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 5.14023
wandb:       example_0/auto_mse 0.0337
wandb:  example_0/mlp_euclidean 4.19594
wandb:        example_0/mlp_mse 0.02246
wandb: example_1/auto_euclidean 4.10823
wandb:       example_1/auto_mse 0.02153
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 4.51305
wandb:       example_2/auto_mse 0.02598
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run smart-blaze-104 at: https://wandb.ai/cavaokcava/autoadvex/runs/asveozcs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113122-asveozcs/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113139-n1d2gaat
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-planet-105
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/n1d2gaat
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.315 MB of 0.319 MB uploadedwandb: \ 0.319 MB of 0.319 MB uploadedwandb: | 0.319 MB of 0.319 MB uploadedwandb: / 0.319 MB of 0.319 MB uploadedwandb: - 0.319 MB of 0.319 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 3.64374
wandb:       example_0/auto_mse 0.01693
wandb:  example_0/mlp_euclidean 2.45069
wandb:        example_0/mlp_mse 0.00766
wandb: example_1/auto_euclidean 6.67932
wandb:       example_1/auto_mse 0.0569
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 5.06497
wandb:       example_2/auto_mse 0.03272
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run colorful-planet-105 at: https://wandb.ai/cavaokcava/autoadvex/runs/n1d2gaat
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113139-n1d2gaat/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113158-vkn46nns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-violet-106
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/vkn46nns
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.325 MB of 0.325 MB uploadedwandb: \ 0.325 MB of 0.325 MB uploadedwandb: | 0.325 MB of 0.325 MB uploadedwandb: / 0.325 MB of 0.325 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 3.43029
wandb:       example_0/auto_mse 0.01501
wandb:  example_0/mlp_euclidean 2.71852
wandb:        example_0/mlp_mse 0.00943
wandb: example_1/auto_euclidean 5.95418
wandb:       example_1/auto_mse 0.04522
wandb:  example_1/mlp_euclidean 4.23125
wandb:        example_1/mlp_mse 0.02284
wandb: example_2/auto_euclidean 3.33829
wandb:       example_2/auto_mse 0.01421
wandb:  example_2/mlp_euclidean 2.78055
wandb:        example_2/mlp_mse 0.00986
wandb: 
wandb: üöÄ View run sweet-violet-106 at: https://wandb.ai/cavaokcava/autoadvex/runs/vkn46nns
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113158-vkn46nns/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113216-godqdnik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-pond-107
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/godqdnik
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.242 MB of 0.323 MB uploadedwandb: \ 0.324 MB of 0.324 MB uploadedwandb: | 0.324 MB of 0.324 MB uploadedwandb: / 0.324 MB of 0.324 MB uploadedwandb: - 0.324 MB of 0.324 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 5.6242
wandb:       example_0/auto_mse 0.04035
wandb:  example_0/mlp_euclidean 5.28917
wandb:        example_0/mlp_mse 0.03568
wandb: example_1/auto_euclidean 4.88737
wandb:       example_1/auto_mse 0.03047
wandb:  example_1/mlp_euclidean 4.98159
wandb:        example_1/mlp_mse 0.03165
wandb: example_2/auto_euclidean 6.76423
wandb:       example_2/auto_mse 0.05836
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run celestial-pond-107 at: https://wandb.ai/cavaokcava/autoadvex/runs/godqdnik
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113216-godqdnik/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113234-dg74mmva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-puddle-108
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/dg74mmva
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.320 MB of 0.320 MB uploadedwandb: \ 0.320 MB of 0.320 MB uploadedwandb: | 0.320 MB of 0.320 MB uploadedwandb: / 0.320 MB of 0.320 MB uploadedwandb: - 0.320 MB of 0.320 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 5.44556
wandb:       example_0/auto_mse 0.03782
wandb:  example_0/mlp_euclidean nan
wandb:        example_0/mlp_mse nan
wandb: example_1/auto_euclidean 2.34966
wandb:       example_1/auto_mse 0.00704
wandb:  example_1/mlp_euclidean 2.27479
wandb:        example_1/mlp_mse 0.0066
wandb: example_2/auto_euclidean 3.72098
wandb:       example_2/auto_mse 0.01766
wandb:  example_2/mlp_euclidean 2.9979
wandb:        example_2/mlp_mse 0.01146
wandb: 
wandb: üöÄ View run hopeful-puddle-108 at: https://wandb.ai/cavaokcava/autoadvex/runs/dg74mmva
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113234-dg74mmva/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113252-t4b1y20m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-feather-109
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/t4b1y20m
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.260 MB of 0.326 MB uploadedwandb: \ 0.327 MB of 0.327 MB uploadedwandb: | 0.327 MB of 0.327 MB uploadedwandb: / 0.327 MB of 0.327 MB uploadedwandb: - 0.327 MB of 0.327 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.86113
wandb:       example_0/auto_mse 0.03014
wandb:  example_0/mlp_euclidean 2.93533
wandb:        example_0/mlp_mse 0.01099
wandb: example_1/auto_euclidean 4.78361
wandb:       example_1/auto_mse 0.02919
wandb:  example_1/mlp_euclidean 3.49716
wandb:        example_1/mlp_mse 0.0156
wandb: example_2/auto_euclidean 4.70781
wandb:       example_2/auto_mse 0.02827
wandb:  example_2/mlp_euclidean 3.39008
wandb:        example_2/mlp_mse 0.01466
wandb: 
wandb: üöÄ View run divine-feather-109 at: https://wandb.ai/cavaokcava/autoadvex/runs/t4b1y20m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113252-t4b1y20m/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113310-yv5b3m0h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-forest-110
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/yv5b3m0h
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.254 MB of 0.320 MB uploadedwandb: \ 0.321 MB of 0.321 MB uploadedwandb: | 0.321 MB of 0.321 MB uploadedwandb: / 0.321 MB of 0.321 MB uploadedwandb: - 0.321 MB of 0.321 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.7056
wandb:       example_0/auto_mse 0.02824
wandb:  example_0/mlp_euclidean 3.46792
wandb:        example_0/mlp_mse 0.01534
wandb: example_1/auto_euclidean 6.20773
wandb:       example_1/auto_mse 0.04915
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 5.20955
wandb:       example_2/auto_mse 0.03462
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run worthy-forest-110 at: https://wandb.ai/cavaokcava/autoadvex/runs/yv5b3m0h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113310-yv5b3m0h/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113328-bcxrtwk4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-microwave-111
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/bcxrtwk4
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.312 MB of 0.314 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 5.37904
wandb:       example_0/auto_mse 0.03691
wandb:  example_0/mlp_euclidean nan
wandb:        example_0/mlp_mse nan
wandb: example_1/auto_euclidean 5.20282
wandb:       example_1/auto_mse 0.03453
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 7.55498
wandb:       example_2/auto_mse 0.0728
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run fluent-microwave-111 at: https://wandb.ai/cavaokcava/autoadvex/runs/bcxrtwk4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113328-bcxrtwk4/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113346-thkd8clt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-spaceship-112
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/thkd8clt
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.71684
wandb:       example_0/auto_mse 0.02838
wandb:  example_0/mlp_euclidean nan
wandb:        example_0/mlp_mse nan
wandb: example_1/auto_euclidean 3.86321
wandb:       example_1/auto_mse 0.01904
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 6.00508
wandb:       example_2/auto_mse 0.046
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run rosy-spaceship-112 at: https://wandb.ai/cavaokcava/autoadvex/runs/thkd8clt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113346-thkd8clt/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113403-p65xvwvy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-cosmos-113
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/p65xvwvy
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.253 MB of 0.319 MB uploadedwandb: \ 0.319 MB of 0.319 MB uploadedwandb: | 0.319 MB of 0.319 MB uploadedwandb: / 0.319 MB of 0.319 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.48198
wandb:       example_0/auto_mse 0.02562
wandb:  example_0/mlp_euclidean 3.5869
wandb:        example_0/mlp_mse 0.01641
wandb: example_1/auto_euclidean 6.81752
wandb:       example_1/auto_mse 0.05928
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 4.83923
wandb:       example_2/auto_mse 0.02987
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run easy-cosmos-113 at: https://wandb.ai/cavaokcava/autoadvex/runs/p65xvwvy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113403-p65xvwvy/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113421-dvse8is7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-wildflower-114
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/dvse8is7
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.258 MB of 0.324 MB uploadedwandb: \ 0.324 MB of 0.324 MB uploadedwandb: | 0.324 MB of 0.324 MB uploadedwandb: / 0.324 MB of 0.324 MB uploadedwandb: - 0.324 MB of 0.324 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 5.53042
wandb:       example_0/auto_mse 0.03901
wandb:  example_0/mlp_euclidean 3.57157
wandb:        example_0/mlp_mse 0.01627
wandb: example_1/auto_euclidean 4.72814
wandb:       example_1/auto_mse 0.02851
wandb:  example_1/mlp_euclidean 3.16965
wandb:        example_1/mlp_mse 0.01281
wandb: example_2/auto_euclidean 6.77477
wandb:       example_2/auto_mse 0.05854
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run zesty-wildflower-114 at: https://wandb.ai/cavaokcava/autoadvex/runs/dvse8is7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113421-dvse8is7/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113440-a6ziik7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-breeze-115
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/a6ziik7b
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.320 MB of 0.324 MB uploadedwandb: \ 0.324 MB of 0.324 MB uploadedwandb: | 0.324 MB of 0.324 MB uploadedwandb: / 0.324 MB of 0.324 MB uploadedwandb: - 0.324 MB of 0.324 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.71103
wandb:       example_0/auto_mse 0.02831
wandb:  example_0/mlp_euclidean 3.59631
wandb:        example_0/mlp_mse 0.0165
wandb: example_1/auto_euclidean 7.19717
wandb:       example_1/auto_mse 0.06607
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 4.80798
wandb:       example_2/auto_mse 0.02949
wandb:  example_2/mlp_euclidean 4.07573
wandb:        example_2/mlp_mse 0.02119
wandb: 
wandb: üöÄ View run volcanic-breeze-115 at: https://wandb.ai/cavaokcava/autoadvex/runs/a6ziik7b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113440-a6ziik7b/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_113458-3mg0lnb9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-spaceship-116
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/3mg0lnb9
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 5.33056
wandb:       example_0/auto_mse 0.03624
wandb:  example_0/mlp_euclidean nan
wandb:        example_0/mlp_mse nan
wandb: example_1/auto_euclidean 4.88785
wandb:       example_1/auto_mse 0.03047
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 6.77882
wandb:       example_2/auto_mse 0.05861
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run dulcet-spaceship-116 at: https://wandb.ai/cavaokcava/autoadvex/runs/3mg0lnb9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_113458-3mg0lnb9/logs
