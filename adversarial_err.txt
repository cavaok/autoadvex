Loading python/3.8.13/slu6jvw
  Loading requirement: bzip2/1.0.8/xipsq2f libmd/1.0.4/sioeueg
    libbsd/0.11.5/gdafde7 expat/2.4.8/5wnje43 ncurses/6.2/pqxvmoe
    readline/8.1/52qiwcn gdbm/1.23/lkx5uz6 libiconv/1.16/lr5guq5
    xz/5.2.5/khdza45 zlib/1.2.12/bsohwcg libxml2/2.9.13/f5kumg5 pigz/2.7/zay4a5o
    zstd/1.5.2/jvujieu tar/1.34/4cnckqw gettext/0.21/hgt6t5w
    libffi/3.4.2/svyohlf openssl/1.1.1o/bowp5gw sqlite/3.38.5/ulzkiln
    util-linux-uuid/2.37.4/nlecwm6
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_211742-pigapckt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_2_confused_True
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/pigapckt
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.262 MB of 0.328 MB uploadedwandb: \ 0.331 MB of 0.331 MB uploadedwandb: | 0.332 MB of 0.332 MB uploadedwandb: / 0.332 MB of 0.332 MB uploadedwandb: - 0.332 MB of 0.332 MB uploadedwandb: \ 0.332 MB of 0.332 MB uploadedwandb: | 0.332 MB of 0.332 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 3.58649
wandb:       example_0/auto_mse 0.01641
wandb:  example_0/mlp_euclidean nan
wandb:        example_0/mlp_mse nan
wandb: example_1/auto_euclidean 3.95815
wandb:       example_1/auto_mse 0.01998
wandb:  example_1/mlp_euclidean 6.52095
wandb:        example_1/mlp_mse 0.05424
wandb: example_2/auto_euclidean 5.17901
wandb:       example_2/auto_mse 0.03421
wandb:  example_2/mlp_euclidean 4.54499
wandb:        example_2/mlp_mse 0.02635
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_2_confused_True at: https://wandb.ai/cavaokcava/autoadvex/runs/pigapckt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_211742-pigapckt/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_211802-yl0jeveq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_3_confused_True
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/yl0jeveq
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.286 MB of 0.337 MB uploadedwandb: \ 0.338 MB of 0.338 MB uploadedwandb: | 0.338 MB of 0.338 MB uploadedwandb: / 0.338 MB of 0.338 MB uploadedwandb: - 0.338 MB of 0.338 MB uploadedwandb: \ 0.338 MB of 0.338 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.3343
wandb:       example_0/auto_mse 0.02396
wandb:  example_0/mlp_euclidean 5.74501
wandb:        example_0/mlp_mse 0.0421
wandb: example_1/auto_euclidean 5.58706
wandb:       example_1/auto_mse 0.03982
wandb:  example_1/mlp_euclidean 6.97075
wandb:        example_1/mlp_mse 0.06198
wandb: example_2/auto_euclidean 4.85202
wandb:       example_2/auto_mse 0.03003
wandb:  example_2/mlp_euclidean 4.05417
wandb:        example_2/mlp_mse 0.02096
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_3_confused_True at: https://wandb.ai/cavaokcava/autoadvex/runs/yl0jeveq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_211802-yl0jeveq/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_211820-4ar7uiky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_4_confused_True
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/4ar7uiky
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.330 MB of 0.334 MB uploadedwandb: \ 0.335 MB of 0.335 MB uploadedwandb: | 0.335 MB of 0.335 MB uploadedwandb: / 0.335 MB of 0.335 MB uploadedwandb: - 0.335 MB of 0.335 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 3.65185
wandb:       example_0/auto_mse 0.01701
wandb:  example_0/mlp_euclidean 3.47878
wandb:        example_0/mlp_mse 0.01544
wandb: example_1/auto_euclidean 4.28467
wandb:       example_1/auto_mse 0.02342
wandb:  example_1/mlp_euclidean 3.88374
wandb:        example_1/mlp_mse 0.01924
wandb: example_2/auto_euclidean 4.49665
wandb:       example_2/auto_mse 0.02579
wandb:  example_2/mlp_euclidean 4.24975
wandb:        example_2/mlp_mse 0.02304
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_4_confused_True at: https://wandb.ai/cavaokcava/autoadvex/runs/4ar7uiky
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_211820-4ar7uiky/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_211838-mxe70u8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_5_confused_True
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/mxe70u8s
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.337 MB of 0.337 MB uploadedwandb: \ 0.337 MB of 0.337 MB uploadedwandb: | 0.337 MB of 0.337 MB uploadedwandb: / 0.337 MB of 0.337 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 3.40666
wandb:       example_0/auto_mse 0.0148
wandb:  example_0/mlp_euclidean 4.15926
wandb:        example_0/mlp_mse 0.02207
wandb: example_1/auto_euclidean 3.90567
wandb:       example_1/auto_mse 0.01946
wandb:  example_1/mlp_euclidean 3.44738
wandb:        example_1/mlp_mse 0.01516
wandb: example_2/auto_euclidean 5.22741
wandb:       example_2/auto_mse 0.03485
wandb:  example_2/mlp_euclidean 5.99654
wandb:        example_2/mlp_mse 0.04587
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_5_confused_True at: https://wandb.ai/cavaokcava/autoadvex/runs/mxe70u8s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_211838-mxe70u8s/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_211855-14el5ec6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_6_confused_True
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/14el5ec6
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.258 MB of 0.324 MB uploadedwandb: \ 0.325 MB of 0.325 MB uploadedwandb: | 0.325 MB of 0.325 MB uploadedwandb: / 0.325 MB of 0.325 MB uploadedwandb: - 0.325 MB of 0.325 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 3.96417
wandb:       example_0/auto_mse 0.02004
wandb:  example_0/mlp_euclidean nan
wandb:        example_0/mlp_mse nan
wandb: example_1/auto_euclidean 6.41284
wandb:       example_1/auto_mse 0.05245
wandb:  example_1/mlp_euclidean 6.09762
wandb:        example_1/mlp_mse 0.04742
wandb: example_2/auto_euclidean 3.20793
wandb:       example_2/auto_mse 0.01313
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_6_confused_True at: https://wandb.ai/cavaokcava/autoadvex/runs/14el5ec6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_211855-14el5ec6/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_211913-dp05lqyu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_7_confused_True
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/dp05lqyu
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.326 MB of 0.329 MB uploadedwandb: \ 0.330 MB of 0.330 MB uploadedwandb: | 0.330 MB of 0.330 MB uploadedwandb: / 0.330 MB of 0.330 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.73053
wandb:       example_0/auto_mse 0.02854
wandb:  example_0/mlp_euclidean 3.7613
wandb:        example_0/mlp_mse 0.01805
wandb: example_1/auto_euclidean 5.07421
wandb:       example_1/auto_mse 0.03284
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 4.13872
wandb:       example_2/auto_mse 0.02185
wandb:  example_2/mlp_euclidean 4.2729
wandb:        example_2/mlp_mse 0.02329
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_7_confused_True at: https://wandb.ai/cavaokcava/autoadvex/runs/dp05lqyu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_211913-dp05lqyu/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_211930-wbcrv2kl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_8_confused_True
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/wbcrv2kl
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.332 MB of 0.336 MB uploadedwandb: \ 0.337 MB of 0.337 MB uploadedwandb: | 0.337 MB of 0.337 MB uploadedwandb: / 0.337 MB of 0.337 MB uploadedwandb: - 0.337 MB of 0.337 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 6.36151
wandb:       example_0/auto_mse 0.05162
wandb:  example_0/mlp_euclidean 6.60818
wandb:        example_0/mlp_mse 0.0557
wandb: example_1/auto_euclidean 3.79326
wandb:       example_1/auto_mse 0.01835
wandb:  example_1/mlp_euclidean 3.73186
wandb:        example_1/mlp_mse 0.01776
wandb: example_2/auto_euclidean 4.80823
wandb:       example_2/auto_mse 0.02949
wandb:  example_2/mlp_euclidean 3.70117
wandb:        example_2/mlp_mse 0.01747
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_8_confused_True at: https://wandb.ai/cavaokcava/autoadvex/runs/wbcrv2kl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_211930-wbcrv2kl/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_211948-8uj67z3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_9_confused_True
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/8uj67z3s
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.325 MB of 0.329 MB uploadedwandb: \ 0.329 MB of 0.329 MB uploadedwandb: | 0.329 MB of 0.329 MB uploadedwandb: / 0.329 MB of 0.329 MB uploadedwandb: - 0.329 MB of 0.329 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 3.98023
wandb:       example_0/auto_mse 0.02021
wandb:  example_0/mlp_euclidean 2.93137
wandb:        example_0/mlp_mse 0.01096
wandb: example_1/auto_euclidean 6.25723
wandb:       example_1/auto_mse 0.04994
wandb:  example_1/mlp_euclidean nan
wandb:        example_1/mlp_mse nan
wandb: example_2/auto_euclidean 5.4977
wandb:       example_2/auto_mse 0.03855
wandb:  example_2/mlp_euclidean 4.65788
wandb:        example_2/mlp_mse 0.02767
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_9_confused_True at: https://wandb.ai/cavaokcava/autoadvex/runs/8uj67z3s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_211948-8uj67z3s/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_212006-x8f7d3xh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_10_confused_True
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/x8f7d3xh
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.329 MB of 0.329 MB uploadedwandb: \ 0.329 MB of 0.329 MB uploadedwandb: | 0.329 MB of 0.329 MB uploadedwandb: / 0.329 MB of 0.329 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 3.19515
wandb:       example_0/auto_mse 0.01302
wandb:  example_0/mlp_euclidean 3.21653
wandb:        example_0/mlp_mse 0.0132
wandb: example_1/auto_euclidean 4.07825
wandb:       example_1/auto_mse 0.02121
wandb:  example_1/mlp_euclidean 4.36932
wandb:        example_1/mlp_mse 0.02435
wandb: example_2/auto_euclidean 3.69871
wandb:       example_2/auto_mse 0.01745
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_10_confused_True at: https://wandb.ai/cavaokcava/autoadvex/runs/x8f7d3xh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_212006-x8f7d3xh/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_212023-yx09g7n2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_1_confused_False
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/yx09g7n2
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.332 MB of 0.332 MB uploadedwandb: \ 0.332 MB of 0.332 MB uploadedwandb: | 0.332 MB of 0.332 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.97046
wandb:       example_0/auto_mse 0.03151
wandb:  example_0/mlp_euclidean 4.62116
wandb:        example_0/mlp_mse 0.02724
wandb: example_1/auto_euclidean 4.57696
wandb:       example_1/auto_mse 0.02672
wandb:  example_1/mlp_euclidean 3.4652
wandb:        example_1/mlp_mse 0.01532
wandb: example_2/auto_euclidean 3.10954
wandb:       example_2/auto_mse 0.01233
wandb:  example_2/mlp_euclidean 2.70722
wandb:        example_2/mlp_mse 0.00935
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_1_confused_False at: https://wandb.ai/cavaokcava/autoadvex/runs/yx09g7n2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_212023-yx09g7n2/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_212039-3o728vjl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_2_confused_False
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/3o728vjl
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.329 MB of 0.329 MB uploadedwandb: \ 0.329 MB of 0.329 MB uploadedwandb: | 0.329 MB of 0.329 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.29416
wandb:       example_0/auto_mse 0.02352
wandb:  example_0/mlp_euclidean nan
wandb:        example_0/mlp_mse nan
wandb: example_1/auto_euclidean 4.59038
wandb:       example_1/auto_mse 0.02688
wandb:  example_1/mlp_euclidean 3.7446
wandb:        example_1/mlp_mse 0.01789
wandb: example_2/auto_euclidean 2.89526
wandb:       example_2/auto_mse 0.01069
wandb:  example_2/mlp_euclidean 3.04491
wandb:        example_2/mlp_mse 0.01183
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_2_confused_False at: https://wandb.ai/cavaokcava/autoadvex/runs/3o728vjl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_212039-3o728vjl/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_212056-50hfyu69
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_3_confused_False
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/50hfyu69
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.270 MB of 0.337 MB uploadedwandb: \ 0.338 MB of 0.338 MB uploadedwandb: | 0.338 MB of 0.338 MB uploadedwandb: / 0.338 MB of 0.338 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 5.74941
wandb:       example_0/auto_mse 0.04216
wandb:  example_0/mlp_euclidean 5.4335
wandb:        example_0/mlp_mse 0.03766
wandb: example_1/auto_euclidean 6.49355
wandb:       example_1/auto_mse 0.05378
wandb:  example_1/mlp_euclidean 6.82155
wandb:        example_1/mlp_mse 0.05935
wandb: example_2/auto_euclidean 4.34846
wandb:       example_2/auto_mse 0.02412
wandb:  example_2/mlp_euclidean 4.85466
wandb:        example_2/mlp_mse 0.03006
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_3_confused_False at: https://wandb.ai/cavaokcava/autoadvex/runs/50hfyu69
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_212056-50hfyu69/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_212114-zno3k2tb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_4_confused_False
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/zno3k2tb
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.335 MB of 0.339 MB uploadedwandb: \ 0.340 MB of 0.340 MB uploadedwandb: | 0.340 MB of 0.340 MB uploadedwandb: / 0.340 MB of 0.340 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.74547
wandb:       example_0/auto_mse 0.02872
wandb:  example_0/mlp_euclidean 4.73366
wandb:        example_0/mlp_mse 0.02858
wandb: example_1/auto_euclidean 5.09784
wandb:       example_1/auto_mse 0.03315
wandb:  example_1/mlp_euclidean 4.50928
wandb:        example_1/mlp_mse 0.02594
wandb: example_2/auto_euclidean 4.29142
wandb:       example_2/auto_mse 0.02349
wandb:  example_2/mlp_euclidean 4.55133
wandb:        example_2/mlp_mse 0.02642
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_4_confused_False at: https://wandb.ai/cavaokcava/autoadvex/runs/zno3k2tb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_212114-zno3k2tb/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_212131-o5uwcsv5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_5_confused_False
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/o5uwcsv5
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.330 MB of 0.330 MB uploadedwandb: \ 0.330 MB of 0.330 MB uploadedwandb: | 0.330 MB of 0.330 MB uploadedwandb: / 0.330 MB of 0.330 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 3.71735
wandb:       example_0/auto_mse 0.01763
wandb:  example_0/mlp_euclidean nan
wandb:        example_0/mlp_mse nan
wandb: example_1/auto_euclidean 3.2206
wandb:       example_1/auto_mse 0.01323
wandb:  example_1/mlp_euclidean 3.2449
wandb:        example_1/mlp_mse 0.01343
wandb: example_2/auto_euclidean 5.62194
wandb:       example_2/auto_mse 0.04031
wandb:  example_2/mlp_euclidean 4.54336
wandb:        example_2/mlp_mse 0.02633
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_5_confused_False at: https://wandb.ai/cavaokcava/autoadvex/runs/o5uwcsv5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_212131-o5uwcsv5/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_212148-2rptb1vj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_6_confused_False
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/2rptb1vj
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.333 MB of 0.333 MB uploadedwandb: \ 0.333 MB of 0.333 MB uploadedwandb: | 0.333 MB of 0.333 MB uploadedwandb: / 0.333 MB of 0.333 MB uploadedwandb: - 0.333 MB of 0.333 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 5.50522
wandb:       example_0/auto_mse 0.03866
wandb:  example_0/mlp_euclidean 4.80107
wandb:        example_0/mlp_mse 0.0294
wandb: example_1/auto_euclidean 6.79829
wandb:       example_1/auto_mse 0.05895
wandb:  example_1/mlp_euclidean 7.58252
wandb:        example_1/mlp_mse 0.07333
wandb: example_2/auto_euclidean 8.41884
wandb:       example_2/auto_mse 0.0904
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_6_confused_False at: https://wandb.ai/cavaokcava/autoadvex/runs/2rptb1vj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_212148-2rptb1vj/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_212205-m2jqrfz6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_7_confused_False
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/m2jqrfz6
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.331 MB of 0.331 MB uploadedwandb: \ 0.331 MB of 0.331 MB uploadedwandb: | 0.331 MB of 0.331 MB uploadedwandb: / 0.331 MB of 0.331 MB uploadedwandb: - 0.331 MB of 0.331 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.83625
wandb:       example_0/auto_mse 0.02983
wandb:  example_0/mlp_euclidean 4.78289
wandb:        example_0/mlp_mse 0.02918
wandb: example_1/auto_euclidean 5.31902
wandb:       example_1/auto_mse 0.03609
wandb:  example_1/mlp_euclidean 5.21236
wandb:        example_1/mlp_mse 0.03465
wandb: example_2/auto_euclidean 3.30423
wandb:       example_2/auto_mse 0.01393
wandb:  example_2/mlp_euclidean nan
wandb:        example_2/mlp_mse nan
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_7_confused_False at: https://wandb.ai/cavaokcava/autoadvex/runs/m2jqrfz6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_212205-m2jqrfz6/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_212224-c36wwmqh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_8_confused_False
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/c36wwmqh
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.267 MB of 0.334 MB uploadedwandb: \ 0.335 MB of 0.335 MB uploadedwandb: | 0.335 MB of 0.335 MB uploadedwandb: / 0.335 MB of 0.335 MB uploadedwandb: - 0.335 MB of 0.335 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 5.07089
wandb:       example_0/auto_mse 0.0328
wandb:  example_0/mlp_euclidean 4.8607
wandb:        example_0/mlp_mse 0.03014
wandb: example_1/auto_euclidean 5.49194
wandb:       example_1/auto_mse 0.03847
wandb:  example_1/mlp_euclidean 4.08786
wandb:        example_1/mlp_mse 0.02131
wandb: example_2/auto_euclidean 5.05787
wandb:       example_2/auto_mse 0.03263
wandb:  example_2/mlp_euclidean 4.87188
wandb:        example_2/mlp_mse 0.03027
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_8_confused_False at: https://wandb.ai/cavaokcava/autoadvex/runs/c36wwmqh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_212224-c36wwmqh/logs
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: cavaokcava. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /home/okcava/projects/autoadvex/wandb/run-20241112_212242-5swt08vt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 4_iters_sumloss_fashion_9_confused_False
wandb: ‚≠êÔ∏è View project at https://wandb.ai/cavaokcava/autoadvex
wandb: üöÄ View run at https://wandb.ai/cavaokcava/autoadvex/runs/5swt08vt
/home/okcava/projects/autoadvex/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/okcava/projects/autoadvex/helper.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
wandb: - 0.332 MB of 0.332 MB uploadedwandb: \ 0.333 MB of 0.333 MB uploadedwandb: | 0.333 MB of 0.333 MB uploadedwandb: / 0.333 MB of 0.333 MB uploadedwandb: - 0.333 MB of 0.333 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: example_0/auto_euclidean ‚ñÅ
wandb:       example_0/auto_mse ‚ñÅ
wandb:  example_0/mlp_euclidean ‚ñÅ
wandb:        example_0/mlp_mse ‚ñÅ
wandb: example_1/auto_euclidean ‚ñÅ
wandb:       example_1/auto_mse ‚ñÅ
wandb:  example_1/mlp_euclidean ‚ñÅ
wandb:        example_1/mlp_mse ‚ñÅ
wandb: example_2/auto_euclidean ‚ñÅ
wandb:       example_2/auto_mse ‚ñÅ
wandb:  example_2/mlp_euclidean ‚ñÅ
wandb:        example_2/mlp_mse ‚ñÅ
wandb: 
wandb: Run summary:
wandb: example_0/auto_euclidean 4.89466
wandb:       example_0/auto_mse 0.03056
wandb:  example_0/mlp_euclidean 4.0627
wandb:        example_0/mlp_mse 0.02105
wandb: example_1/auto_euclidean 3.4146
wandb:       example_1/auto_mse 0.01487
wandb:  example_1/mlp_euclidean 2.88389
wandb:        example_1/mlp_mse 0.01061
wandb: example_2/auto_euclidean 4.58572
wandb:       example_2/auto_mse 0.02682
wandb:  example_2/mlp_euclidean 4.24502
wandb:        example_2/mlp_mse 0.02298
wandb: 
wandb: üöÄ View run 4_iters_sumloss_fashion_9_confused_False at: https://wandb.ai/cavaokcava/autoadvex/runs/5swt08vt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/cavaokcava/autoadvex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)
wandb: Find logs at: ./wandb/run-20241112_212242-5swt08vt/logs
