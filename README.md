# Exploring the Universality of Adversarial Examples from a Dynamical Systems Perspective

## Status ðŸš§
**Last Updated:** December 10, 2024
This research is currently a work in progress.

## Overview
This research investigates whether "snare regions" â€“ areas where classification boundaries become complex and intertwined â€“ are an inherent feature of neural networks regardless of architecture. We examine if these regions can be effectively minimized through either novel dynamical systems architectures or by manipulating degrees of confusion in classification outputs.

## Current Progress
- [âœ“] Summer 2024: Built theoretical foundations
  - Comprehensive review of denoising autoencoders
  - Studied dynamical systems theory
  - Reviewed adversarial examples literature

- [âœ“] August-October 2024:
  - Developed code repository for training adversarial examples
  - Integrated with Weights & Biases for experiment tracking
  - Created visualization pipeline

- [âœ“] October-December 2024:
  - Implemented Supabase database solution
  - Collected over 5,000 adversarial examples
  - Enhanced data collection and analysis infrastructure
  - Focused on varying degrees of confusion in adversarial training

- [ðŸš§] Current Focus:
  - Expanding theoretical framework
  - Examining different dynamical systems architectures

## Timeline
- December 4, 2024: Proposal finalization
- January 15, 2025: Complete major analyses
- March 7, 2025: First full thesis draft
- April 24, 2025: Thesis defense
- May 1, 2025: ETD submission

## Real-World Applications
This research has direct implications for:
- Autonomous vehicle security
- Medical diagnostic systems
- Critical AI infrastructure
- Development of more robust machine learning systems

## Contact
Olivia Cava  
Data Science BS/MS Student  
Worcester Polytechnic Institute
