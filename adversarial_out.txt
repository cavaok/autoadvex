running dynamical.py
Epoch [1/30], Batch [0/6000], Loss: 0.4477
Epoch [1/30], Batch [100/6000], Loss: 0.3788
Epoch [1/30], Batch [200/6000], Loss: 0.3109
Epoch [1/30], Batch [300/6000], Loss: 0.3061
Epoch [1/30], Batch [400/6000], Loss: 0.2536
Epoch [1/30], Batch [500/6000], Loss: 0.3182
Epoch [1/30], Batch [600/6000], Loss: 0.2385
Epoch [1/30], Batch [700/6000], Loss: 0.2094
Epoch [1/30], Batch [800/6000], Loss: 0.2285
Epoch [1/30], Batch [900/6000], Loss: 0.2066
Epoch [1/30], Batch [1000/6000], Loss: 0.1343
Epoch [1/30], Batch [1100/6000], Loss: 0.3021
Epoch [1/30], Batch [1200/6000], Loss: 0.2524
Epoch [1/30], Batch [1300/6000], Loss: 0.2168
Epoch [1/30], Batch [1400/6000], Loss: 0.1662
Epoch [1/30], Batch [1500/6000], Loss: 0.1964
Epoch [1/30], Batch [1600/6000], Loss: 0.2595
Epoch [1/30], Batch [1700/6000], Loss: 0.1245
Epoch [1/30], Batch [1800/6000], Loss: 0.1786
Epoch [1/30], Batch [1900/6000], Loss: 0.2251
Epoch [1/30], Batch [2000/6000], Loss: 0.1868
Epoch [1/30], Batch [2100/6000], Loss: 0.1817
Epoch [1/30], Batch [2200/6000], Loss: 0.1646
Epoch [1/30], Batch [2300/6000], Loss: 0.1520
Epoch [1/30], Batch [2400/6000], Loss: 0.1208
Epoch [1/30], Batch [2500/6000], Loss: 0.1254
Epoch [1/30], Batch [2600/6000], Loss: 0.2283
Epoch [1/30], Batch [2700/6000], Loss: 0.1533
Epoch [1/30], Batch [2800/6000], Loss: 0.1670
Epoch [1/30], Batch [2900/6000], Loss: 0.1616
Epoch [1/30], Batch [3000/6000], Loss: 0.1558
Epoch [1/30], Batch [3100/6000], Loss: 0.1403
Epoch [1/30], Batch [3200/6000], Loss: 0.1268
Epoch [1/30], Batch [3300/6000], Loss: 0.1607
Epoch [1/30], Batch [3400/6000], Loss: 0.1273
Epoch [1/30], Batch [3500/6000], Loss: 0.1400
Epoch [1/30], Batch [3600/6000], Loss: 0.1125
Epoch [1/30], Batch [3700/6000], Loss: 0.1611
Epoch [1/30], Batch [3800/6000], Loss: 0.1838
Epoch [1/30], Batch [3900/6000], Loss: 0.1134
Epoch [1/30], Batch [4000/6000], Loss: 0.0951
Epoch [1/30], Batch [4100/6000], Loss: 0.1891
Epoch [1/30], Batch [4200/6000], Loss: 0.1054
Epoch [1/30], Batch [4300/6000], Loss: 0.1006
Epoch [1/30], Batch [4400/6000], Loss: 0.1004
Epoch [1/30], Batch [4500/6000], Loss: 0.1108
Epoch [1/30], Batch [4600/6000], Loss: 0.1395
Epoch [1/30], Batch [4700/6000], Loss: 0.0819
Epoch [1/30], Batch [4800/6000], Loss: 0.1102
Epoch [1/30], Batch [4900/6000], Loss: 0.0845
Epoch [1/30], Batch [5000/6000], Loss: 0.0938
Epoch [1/30], Batch [5100/6000], Loss: 0.1436
Epoch [1/30], Batch [5200/6000], Loss: 0.1473
Epoch [1/30], Batch [5300/6000], Loss: 0.1484
Epoch [1/30], Batch [5400/6000], Loss: 0.1430
Epoch [1/30], Batch [5500/6000], Loss: 0.2037
Epoch [1/30], Batch [5600/6000], Loss: 0.0944
Epoch [1/30], Batch [5700/6000], Loss: 0.2013
Epoch [1/30], Batch [5800/6000], Loss: 0.1177
Epoch [1/30], Batch [5900/6000], Loss: 0.1834
Epoch [1/30], Loss: 0.1729
Epoch [2/30], Batch [0/6000], Loss: 0.1176
Epoch [2/30], Batch [100/6000], Loss: 0.1248
Epoch [2/30], Batch [200/6000], Loss: 0.1331
Epoch [2/30], Batch [300/6000], Loss: 0.1000
Epoch [2/30], Batch [400/6000], Loss: 0.1302
Epoch [2/30], Batch [500/6000], Loss: 0.1115
Epoch [2/30], Batch [600/6000], Loss: 0.1091
Epoch [2/30], Batch [700/6000], Loss: 0.1060
Epoch [2/30], Batch [800/6000], Loss: 0.1140
Epoch [2/30], Batch [900/6000], Loss: 0.0930
Epoch [2/30], Batch [1000/6000], Loss: 0.1866
Epoch [2/30], Batch [1100/6000], Loss: 0.1632
Epoch [2/30], Batch [1200/6000], Loss: 0.1151
Epoch [2/30], Batch [1300/6000], Loss: 0.1020
Epoch [2/30], Batch [1400/6000], Loss: 0.1662
Epoch [2/30], Batch [1500/6000], Loss: 0.1103
Epoch [2/30], Batch [1600/6000], Loss: 0.0863
Epoch [2/30], Batch [1700/6000], Loss: 0.1519
Epoch [2/30], Batch [1800/6000], Loss: 0.0881
Epoch [2/30], Batch [1900/6000], Loss: 0.1048
Epoch [2/30], Batch [2000/6000], Loss: 0.1161
Epoch [2/30], Batch [2100/6000], Loss: 0.1363
Epoch [2/30], Batch [2200/6000], Loss: 0.0917
Epoch [2/30], Batch [2300/6000], Loss: 0.1460
Epoch [2/30], Batch [2400/6000], Loss: 0.0927
Epoch [2/30], Batch [2500/6000], Loss: 0.0708
Epoch [2/30], Batch [2600/6000], Loss: 0.1850
Epoch [2/30], Batch [2700/6000], Loss: 0.0773
Epoch [2/30], Batch [2800/6000], Loss: 0.1305
Epoch [2/30], Batch [2900/6000], Loss: 0.0933
Epoch [2/30], Batch [3000/6000], Loss: 0.0796
Epoch [2/30], Batch [3100/6000], Loss: 0.1314
Epoch [2/30], Batch [3200/6000], Loss: 0.0704
Epoch [2/30], Batch [3300/6000], Loss: 0.1006
Epoch [2/30], Batch [3400/6000], Loss: 0.1059
Epoch [2/30], Batch [3500/6000], Loss: 0.0941
Epoch [2/30], Batch [3600/6000], Loss: 0.0908
Epoch [2/30], Batch [3700/6000], Loss: 0.1160
Epoch [2/30], Batch [3800/6000], Loss: 0.0884
Epoch [2/30], Batch [3900/6000], Loss: 0.0832
Epoch [2/30], Batch [4000/6000], Loss: 0.1353
Epoch [2/30], Batch [4100/6000], Loss: 0.1010
Epoch [2/30], Batch [4200/6000], Loss: 0.0852
Epoch [2/30], Batch [4300/6000], Loss: 0.0939
Epoch [2/30], Batch [4400/6000], Loss: 0.1177
Epoch [2/30], Batch [4500/6000], Loss: 0.1323
Epoch [2/30], Batch [4600/6000], Loss: 0.1057
Epoch [2/30], Batch [4700/6000], Loss: 0.0989
Epoch [2/30], Batch [4800/6000], Loss: 0.1044
Epoch [2/30], Batch [4900/6000], Loss: 0.1199
Epoch [2/30], Batch [5000/6000], Loss: 0.1295
Epoch [2/30], Batch [5100/6000], Loss: 0.1618
Epoch [2/30], Batch [5200/6000], Loss: 0.1702
Epoch [2/30], Batch [5300/6000], Loss: 0.1009
Epoch [2/30], Batch [5400/6000], Loss: 0.0863
Epoch [2/30], Batch [5500/6000], Loss: 0.1040
Epoch [2/30], Batch [5600/6000], Loss: 0.0890
Epoch [2/30], Batch [5700/6000], Loss: 0.1141
Epoch [2/30], Batch [5800/6000], Loss: 0.0918
Epoch [2/30], Batch [5900/6000], Loss: 0.0773
Epoch [2/30], Loss: 0.1128
Epoch [3/30], Batch [0/6000], Loss: 0.0814
Epoch [3/30], Batch [100/6000], Loss: 0.0951
Epoch [3/30], Batch [200/6000], Loss: 0.0872
Epoch [3/30], Batch [300/6000], Loss: 0.0732
Epoch [3/30], Batch [400/6000], Loss: 0.0699
Epoch [3/30], Batch [500/6000], Loss: 0.0828
Epoch [3/30], Batch [600/6000], Loss: 0.0773
Epoch [3/30], Batch [700/6000], Loss: 0.0883
Epoch [3/30], Batch [800/6000], Loss: 0.1077
Epoch [3/30], Batch [900/6000], Loss: 0.1640
Epoch [3/30], Batch [1000/6000], Loss: 0.0975
Epoch [3/30], Batch [1100/6000], Loss: 0.0964
Epoch [3/30], Batch [1200/6000], Loss: 0.1071
Epoch [3/30], Batch [1300/6000], Loss: 0.1635
Epoch [3/30], Batch [1400/6000], Loss: 0.1152
Epoch [3/30], Batch [1500/6000], Loss: 0.0616
Epoch [3/30], Batch [1600/6000], Loss: 0.0816
Epoch [3/30], Batch [1700/6000], Loss: 0.0936
Epoch [3/30], Batch [1800/6000], Loss: 0.0693
Epoch [3/30], Batch [1900/6000], Loss: 0.1124
Epoch [3/30], Batch [2000/6000], Loss: 0.0770
Epoch [3/30], Batch [2100/6000], Loss: 0.0781
Epoch [3/30], Batch [2200/6000], Loss: 0.1767
Epoch [3/30], Batch [2300/6000], Loss: 0.0855
Epoch [3/30], Batch [2400/6000], Loss: 0.1530
Epoch [3/30], Batch [2500/6000], Loss: 0.0689
Epoch [3/30], Batch [2600/6000], Loss: 0.0864
Epoch [3/30], Batch [2700/6000], Loss: 0.0920
Epoch [3/30], Batch [2800/6000], Loss: 0.0737
Epoch [3/30], Batch [2900/6000], Loss: 0.1127
Epoch [3/30], Batch [3000/6000], Loss: 0.0777
Epoch [3/30], Batch [3100/6000], Loss: 0.1120
Epoch [3/30], Batch [3200/6000], Loss: 0.1060
Epoch [3/30], Batch [3300/6000], Loss: 0.0671
Epoch [3/30], Batch [3400/6000], Loss: 0.0807
Epoch [3/30], Batch [3500/6000], Loss: 0.0838
Epoch [3/30], Batch [3600/6000], Loss: 0.1188
Epoch [3/30], Batch [3700/6000], Loss: 0.0758
Epoch [3/30], Batch [3800/6000], Loss: 0.0948
Epoch [3/30], Batch [3900/6000], Loss: 0.0717
Epoch [3/30], Batch [4000/6000], Loss: 0.0955
Epoch [3/30], Batch [4100/6000], Loss: 0.0636
Epoch [3/30], Batch [4200/6000], Loss: 0.1158
Epoch [3/30], Batch [4300/6000], Loss: 0.0845
Epoch [3/30], Batch [4400/6000], Loss: 0.0892
Epoch [3/30], Batch [4500/6000], Loss: 0.1515
Epoch [3/30], Batch [4600/6000], Loss: 0.0824
Epoch [3/30], Batch [4700/6000], Loss: 0.0650
Epoch [3/30], Batch [4800/6000], Loss: 0.1046
Epoch [3/30], Batch [4900/6000], Loss: 0.1034
Epoch [3/30], Batch [5000/6000], Loss: 0.0946
Epoch [3/30], Batch [5100/6000], Loss: 0.0928
Epoch [3/30], Batch [5200/6000], Loss: 0.1102
Epoch [3/30], Batch [5300/6000], Loss: 0.1211
Epoch [3/30], Batch [5400/6000], Loss: 0.0790
Epoch [3/30], Batch [5500/6000], Loss: 0.0865
Epoch [3/30], Batch [5600/6000], Loss: 0.1051
Epoch [3/30], Batch [5700/6000], Loss: 0.0868
Epoch [3/30], Batch [5800/6000], Loss: 0.0965
Epoch [3/30], Batch [5900/6000], Loss: 0.1050
Epoch [3/30], Loss: 0.0923
Epoch [4/30], Batch [0/6000], Loss: 0.0663
Epoch [4/30], Batch [100/6000], Loss: 0.0667
Epoch [4/30], Batch [200/6000], Loss: 0.0698
Epoch [4/30], Batch [300/6000], Loss: 0.0634
Epoch [4/30], Batch [400/6000], Loss: 0.1727
Epoch [4/30], Batch [500/6000], Loss: 0.0867
Epoch [4/30], Batch [600/6000], Loss: 0.0789
Epoch [4/30], Batch [700/6000], Loss: 0.0861
Epoch [4/30], Batch [800/6000], Loss: 0.1245
Epoch [4/30], Batch [900/6000], Loss: 0.0852
Epoch [4/30], Batch [1000/6000], Loss: 0.0769
Epoch [4/30], Batch [1100/6000], Loss: 0.0654
Epoch [4/30], Batch [1200/6000], Loss: 0.2157
Epoch [4/30], Batch [1300/6000], Loss: 0.0654
Epoch [4/30], Batch [1400/6000], Loss: 0.0764
Epoch [4/30], Batch [1500/6000], Loss: 0.0648
Epoch [4/30], Batch [1600/6000], Loss: 0.0807
Epoch [4/30], Batch [1700/6000], Loss: 0.1169
Epoch [4/30], Batch [1800/6000], Loss: 0.0719
Epoch [4/30], Batch [1900/6000], Loss: 0.0830
Epoch [4/30], Batch [2000/6000], Loss: 0.0884
Epoch [4/30], Batch [2100/6000], Loss: 0.0617
Epoch [4/30], Batch [2200/6000], Loss: 0.0640
Epoch [4/30], Batch [2300/6000], Loss: 0.0583
Epoch [4/30], Batch [2400/6000], Loss: 0.0591
Epoch [4/30], Batch [2500/6000], Loss: 0.1060
Epoch [4/30], Batch [2600/6000], Loss: 0.0808
Epoch [4/30], Batch [2700/6000], Loss: 0.0778
Epoch [4/30], Batch [2800/6000], Loss: 0.0642
Epoch [4/30], Batch [2900/6000], Loss: 0.0717
Epoch [4/30], Batch [3000/6000], Loss: 0.0903
Epoch [4/30], Batch [3100/6000], Loss: 0.0696
Epoch [4/30], Batch [3200/6000], Loss: 0.1641
Epoch [4/30], Batch [3300/6000], Loss: 0.0878
Epoch [4/30], Batch [3400/6000], Loss: 0.0736
Epoch [4/30], Batch [3500/6000], Loss: 0.0638
Epoch [4/30], Batch [3600/6000], Loss: 0.0720
Epoch [4/30], Batch [3700/6000], Loss: 0.0922
Epoch [4/30], Batch [3800/6000], Loss: 0.0669
Epoch [4/30], Batch [3900/6000], Loss: 0.0814
Epoch [4/30], Batch [4000/6000], Loss: 0.0757
Epoch [4/30], Batch [4100/6000], Loss: 0.1049
Epoch [4/30], Batch [4200/6000], Loss: 0.0787
Epoch [4/30], Batch [4300/6000], Loss: 0.0678
Epoch [4/30], Batch [4400/6000], Loss: 0.0926
Epoch [4/30], Batch [4500/6000], Loss: 0.0784
Epoch [4/30], Batch [4600/6000], Loss: 0.0688
Epoch [4/30], Batch [4700/6000], Loss: 0.0753
Epoch [4/30], Batch [4800/6000], Loss: 0.0934
Epoch [4/30], Batch [4900/6000], Loss: 0.0894
Epoch [4/30], Batch [5000/6000], Loss: 0.0614
Epoch [4/30], Batch [5100/6000], Loss: 0.0783
Epoch [4/30], Batch [5200/6000], Loss: 0.0839
Epoch [4/30], Batch [5300/6000], Loss: 0.0672
Epoch [4/30], Batch [5400/6000], Loss: 0.0818
Epoch [4/30], Batch [5500/6000], Loss: 0.0759
Epoch [4/30], Batch [5600/6000], Loss: 0.0567
Epoch [4/30], Batch [5700/6000], Loss: 0.0642
Epoch [4/30], Batch [5800/6000], Loss: 0.1000
Epoch [4/30], Batch [5900/6000], Loss: 0.0628
Epoch [4/30], Loss: 0.0817
Epoch [5/30], Batch [0/6000], Loss: 0.1053
Epoch [5/30], Batch [100/6000], Loss: 0.1087
Epoch [5/30], Batch [200/6000], Loss: 0.0569
Epoch [5/30], Batch [300/6000], Loss: 0.0694
Epoch [5/30], Batch [400/6000], Loss: 0.0598
Epoch [5/30], Batch [500/6000], Loss: 0.0576
Epoch [5/30], Batch [600/6000], Loss: 0.0600
Epoch [5/30], Batch [700/6000], Loss: 0.1119
Epoch [5/30], Batch [800/6000], Loss: 0.0789
Epoch [5/30], Batch [900/6000], Loss: 0.0726
Epoch [5/30], Batch [1000/6000], Loss: 0.0632
Epoch [5/30], Batch [1100/6000], Loss: 0.0563
Epoch [5/30], Batch [1200/6000], Loss: 0.0750
Epoch [5/30], Batch [1300/6000], Loss: 0.0695
Epoch [5/30], Batch [1400/6000], Loss: 0.0656
Epoch [5/30], Batch [1500/6000], Loss: 0.0926
Epoch [5/30], Batch [1600/6000], Loss: 0.0647
Epoch [5/30], Batch [1700/6000], Loss: 0.0489
Epoch [5/30], Batch [1800/6000], Loss: 0.0639
Epoch [5/30], Batch [1900/6000], Loss: 0.0700
Epoch [5/30], Batch [2000/6000], Loss: 0.0514
Epoch [5/30], Batch [2100/6000], Loss: 0.0578
Epoch [5/30], Batch [2200/6000], Loss: 0.0658
Epoch [5/30], Batch [2300/6000], Loss: 0.0742
Epoch [5/30], Batch [2400/6000], Loss: 0.1803
Epoch [5/30], Batch [2500/6000], Loss: 0.0554
Epoch [5/30], Batch [2600/6000], Loss: 0.0739
Epoch [5/30], Batch [2700/6000], Loss: 0.0670
Epoch [5/30], Batch [2800/6000], Loss: 0.0692
Epoch [5/30], Batch [2900/6000], Loss: 0.0684
Epoch [5/30], Batch [3000/6000], Loss: 0.0665
Epoch [5/30], Batch [3100/6000], Loss: 0.0672
Epoch [5/30], Batch [3200/6000], Loss: 0.0973
Epoch [5/30], Batch [3300/6000], Loss: 0.0605
Epoch [5/30], Batch [3400/6000], Loss: 0.0478
Epoch [5/30], Batch [3500/6000], Loss: 0.0646
Epoch [5/30], Batch [3600/6000], Loss: 0.0764
Epoch [5/30], Batch [3700/6000], Loss: 0.0597
Epoch [5/30], Batch [3800/6000], Loss: 0.0696
Epoch [5/30], Batch [3900/6000], Loss: 0.0530
Epoch [5/30], Batch [4000/6000], Loss: 0.0583
Epoch [5/30], Batch [4100/6000], Loss: 0.0680
Epoch [5/30], Batch [4200/6000], Loss: 0.0621
Epoch [5/30], Batch [4300/6000], Loss: 0.0682
Epoch [5/30], Batch [4400/6000], Loss: 0.0665
Epoch [5/30], Batch [4500/6000], Loss: 0.0674
Epoch [5/30], Batch [4600/6000], Loss: 0.0917
Epoch [5/30], Batch [4700/6000], Loss: 0.1030
Epoch [5/30], Batch [4800/6000], Loss: 0.0580
Epoch [5/30], Batch [4900/6000], Loss: 0.0707
Epoch [5/30], Batch [5000/6000], Loss: 0.0761
Epoch [5/30], Batch [5100/6000], Loss: 0.0589
Epoch [5/30], Batch [5200/6000], Loss: 0.0686
Epoch [5/30], Batch [5300/6000], Loss: 0.0726
Epoch [5/30], Batch [5400/6000], Loss: 0.0564
Epoch [5/30], Batch [5500/6000], Loss: 0.0945
Epoch [5/30], Batch [5600/6000], Loss: 0.1321
Epoch [5/30], Batch [5700/6000], Loss: 0.0897
Epoch [5/30], Batch [5800/6000], Loss: 0.0531
Epoch [5/30], Batch [5900/6000], Loss: 0.0592
Epoch [5/30], Loss: 0.0743
Epoch [6/30], Batch [0/6000], Loss: 0.0764
Epoch [6/30], Batch [100/6000], Loss: 0.0841
Epoch [6/30], Batch [200/6000], Loss: 0.0684
Epoch [6/30], Batch [300/6000], Loss: 0.0606
Epoch [6/30], Batch [400/6000], Loss: 0.0609
Epoch [6/30], Batch [500/6000], Loss: 0.0924
Epoch [6/30], Batch [600/6000], Loss: 0.0474
Epoch [6/30], Batch [700/6000], Loss: 0.0580
Epoch [6/30], Batch [800/6000], Loss: 0.1159
Epoch [6/30], Batch [900/6000], Loss: 0.0662
Epoch [6/30], Batch [1000/6000], Loss: 0.1445
Epoch [6/30], Batch [1100/6000], Loss: 0.0730
Epoch [6/30], Batch [1200/6000], Loss: 0.0780
Epoch [6/30], Batch [1300/6000], Loss: 0.0543
Epoch [6/30], Batch [1400/6000], Loss: 0.0529
Epoch [6/30], Batch [1500/6000], Loss: 0.0871
Epoch [6/30], Batch [1600/6000], Loss: 0.0593
Epoch [6/30], Batch [1700/6000], Loss: 0.0564
Epoch [6/30], Batch [1800/6000], Loss: 0.1197
Epoch [6/30], Batch [1900/6000], Loss: 0.0660
Epoch [6/30], Batch [2000/6000], Loss: 0.0667
Epoch [6/30], Batch [2100/6000], Loss: 0.0610
Epoch [6/30], Batch [2200/6000], Loss: 0.0760
Epoch [6/30], Batch [2300/6000], Loss: 0.0680
Epoch [6/30], Batch [2400/6000], Loss: 0.0886
Epoch [6/30], Batch [2500/6000], Loss: 0.0711
Epoch [6/30], Batch [2600/6000], Loss: 0.0635
Epoch [6/30], Batch [2700/6000], Loss: 0.0533
Epoch [6/30], Batch [2800/6000], Loss: 0.1209
Epoch [6/30], Batch [2900/6000], Loss: 0.0570
Epoch [6/30], Batch [3000/6000], Loss: 0.0635
Epoch [6/30], Batch [3100/6000], Loss: 0.0550
Epoch [6/30], Batch [3200/6000], Loss: 0.0618
Epoch [6/30], Batch [3300/6000], Loss: 0.0691
Epoch [6/30], Batch [3400/6000], Loss: 0.0999
Epoch [6/30], Batch [3500/6000], Loss: 0.0759
Epoch [6/30], Batch [3600/6000], Loss: 0.1169
Epoch [6/30], Batch [3700/6000], Loss: 0.0788
Epoch [6/30], Batch [3800/6000], Loss: 0.0948
Epoch [6/30], Batch [3900/6000], Loss: 0.1153
Epoch [6/30], Batch [4000/6000], Loss: 0.0609
Epoch [6/30], Batch [4100/6000], Loss: 0.0627
Epoch [6/30], Batch [4200/6000], Loss: 0.0610
Epoch [6/30], Batch [4300/6000], Loss: 0.0502
Epoch [6/30], Batch [4400/6000], Loss: 0.0546
Epoch [6/30], Batch [4500/6000], Loss: 0.0683
Epoch [6/30], Batch [4600/6000], Loss: 0.0586
Epoch [6/30], Batch [4700/6000], Loss: 0.0760
Epoch [6/30], Batch [4800/6000], Loss: 0.0589
Epoch [6/30], Batch [4900/6000], Loss: 0.0458
Epoch [6/30], Batch [5000/6000], Loss: 0.1072
Epoch [6/30], Batch [5100/6000], Loss: 0.1024
Epoch [6/30], Batch [5200/6000], Loss: 0.0503
Epoch [6/30], Batch [5300/6000], Loss: 0.0913
Epoch [6/30], Batch [5400/6000], Loss: 0.0622
Epoch [6/30], Batch [5500/6000], Loss: 0.1223
Epoch [6/30], Batch [5600/6000], Loss: 0.0624
Epoch [6/30], Batch [5700/6000], Loss: 0.0976
Epoch [6/30], Batch [5800/6000], Loss: 0.0763
Epoch [6/30], Batch [5900/6000], Loss: 0.0478
Epoch [6/30], Loss: 0.0684
Epoch [7/30], Batch [0/6000], Loss: 0.0490
Epoch [7/30], Batch [100/6000], Loss: 0.1277
Epoch [7/30], Batch [200/6000], Loss: 0.0541
Epoch [7/30], Batch [300/6000], Loss: 0.0471
Epoch [7/30], Batch [400/6000], Loss: 0.0657
Epoch [7/30], Batch [500/6000], Loss: 0.0568
Epoch [7/30], Batch [600/6000], Loss: 0.0560
Epoch [7/30], Batch [700/6000], Loss: 0.0690
Epoch [7/30], Batch [800/6000], Loss: 0.0650
Epoch [7/30], Batch [900/6000], Loss: 0.0585
Epoch [7/30], Batch [1000/6000], Loss: 0.0685
Epoch [7/30], Batch [1100/6000], Loss: 0.0456
Epoch [7/30], Batch [1200/6000], Loss: 0.0642
Epoch [7/30], Batch [1300/6000], Loss: 0.0591
Epoch [7/30], Batch [1400/6000], Loss: 0.0484
Epoch [7/30], Batch [1500/6000], Loss: 0.1321
Epoch [7/30], Batch [1600/6000], Loss: 0.0702
Epoch [7/30], Batch [1700/6000], Loss: 0.0504
Epoch [7/30], Batch [1800/6000], Loss: 0.0414
Epoch [7/30], Batch [1900/6000], Loss: 0.0571
Epoch [7/30], Batch [2000/6000], Loss: 0.0495
Epoch [7/30], Batch [2100/6000], Loss: 0.0533
Epoch [7/30], Batch [2200/6000], Loss: 0.0763
Epoch [7/30], Batch [2300/6000], Loss: 0.0956
Epoch [7/30], Batch [2400/6000], Loss: 0.0506
Epoch [7/30], Batch [2500/6000], Loss: 0.0433
Epoch [7/30], Batch [2600/6000], Loss: 0.0870
Epoch [7/30], Batch [2700/6000], Loss: 0.0419
Epoch [7/30], Batch [2800/6000], Loss: 0.0484
Epoch [7/30], Batch [2900/6000], Loss: 0.0440
Epoch [7/30], Batch [3000/6000], Loss: 0.0568
Epoch [7/30], Batch [3100/6000], Loss: 0.0559
Epoch [7/30], Batch [3200/6000], Loss: 0.0524
Epoch [7/30], Batch [3300/6000], Loss: 0.0489
Epoch [7/30], Batch [3400/6000], Loss: 0.0706
Epoch [7/30], Batch [3500/6000], Loss: 0.0593
Epoch [7/30], Batch [3600/6000], Loss: 0.0846
Epoch [7/30], Batch [3700/6000], Loss: 0.1050
Epoch [7/30], Batch [3800/6000], Loss: 0.0548
Epoch [7/30], Batch [3900/6000], Loss: 0.0575
Epoch [7/30], Batch [4000/6000], Loss: 0.0541
Epoch [7/30], Batch [4100/6000], Loss: 0.0552
Epoch [7/30], Batch [4200/6000], Loss: 0.0610
Epoch [7/30], Batch [4300/6000], Loss: 0.0489
Epoch [7/30], Batch [4400/6000], Loss: 0.0562
Epoch [7/30], Batch [4500/6000], Loss: 0.0396
Epoch [7/30], Batch [4600/6000], Loss: 0.0576
Epoch [7/30], Batch [4700/6000], Loss: 0.0609
Epoch [7/30], Batch [4800/6000], Loss: 0.0460
Epoch [7/30], Batch [4900/6000], Loss: 0.0567
Epoch [7/30], Batch [5000/6000], Loss: 0.0634
Epoch [7/30], Batch [5100/6000], Loss: 0.0520
Epoch [7/30], Batch [5200/6000], Loss: 0.0869
Epoch [7/30], Batch [5300/6000], Loss: 0.0719
Epoch [7/30], Batch [5400/6000], Loss: 0.0985
Epoch [7/30], Batch [5500/6000], Loss: 0.0664
Epoch [7/30], Batch [5600/6000], Loss: 0.0506
Epoch [7/30], Batch [5700/6000], Loss: 0.0542
Epoch [7/30], Batch [5800/6000], Loss: 0.0665
Epoch [7/30], Batch [5900/6000], Loss: 0.1114
Epoch [7/30], Loss: 0.0637
Epoch [8/30], Batch [0/6000], Loss: 0.0650
Epoch [8/30], Batch [100/6000], Loss: 0.0542
Epoch [8/30], Batch [200/6000], Loss: 0.0528
Epoch [8/30], Batch [300/6000], Loss: 0.0505
Epoch [8/30], Batch [400/6000], Loss: 0.0517
Epoch [8/30], Batch [500/6000], Loss: 0.0424
Epoch [8/30], Batch [600/6000], Loss: 0.0594
Epoch [8/30], Batch [700/6000], Loss: 0.0466
Epoch [8/30], Batch [800/6000], Loss: 0.0430
Epoch [8/30], Batch [900/6000], Loss: 0.0698
Epoch [8/30], Batch [1000/6000], Loss: 0.0576
Epoch [8/30], Batch [1100/6000], Loss: 0.0585
Epoch [8/30], Batch [1200/6000], Loss: 0.0469
Epoch [8/30], Batch [1300/6000], Loss: 0.0425
Epoch [8/30], Batch [1400/6000], Loss: 0.0476
Epoch [8/30], Batch [1500/6000], Loss: 0.0542
Epoch [8/30], Batch [1600/6000], Loss: 0.1360
Epoch [8/30], Batch [1700/6000], Loss: 0.0627
Epoch [8/30], Batch [1800/6000], Loss: 0.0456
Epoch [8/30], Batch [1900/6000], Loss: 0.0912
Epoch [8/30], Batch [2000/6000], Loss: 0.0541
Epoch [8/30], Batch [2100/6000], Loss: 0.0606
Epoch [8/30], Batch [2200/6000], Loss: 0.0580
Epoch [8/30], Batch [2300/6000], Loss: 0.1122
Epoch [8/30], Batch [2400/6000], Loss: 0.0481
Epoch [8/30], Batch [2500/6000], Loss: 0.0550
Epoch [8/30], Batch [2600/6000], Loss: 0.0596
Epoch [8/30], Batch [2700/6000], Loss: 0.0563
Epoch [8/30], Batch [2800/6000], Loss: 0.0480
Epoch [8/30], Batch [2900/6000], Loss: 0.0415
Epoch [8/30], Batch [3000/6000], Loss: 0.0540
Epoch [8/30], Batch [3100/6000], Loss: 0.0618
Epoch [8/30], Batch [3200/6000], Loss: 0.0437
Epoch [8/30], Batch [3300/6000], Loss: 0.0463
Epoch [8/30], Batch [3400/6000], Loss: 0.1086
Epoch [8/30], Batch [3500/6000], Loss: 0.0518
Epoch [8/30], Batch [3600/6000], Loss: 0.0519
Epoch [8/30], Batch [3700/6000], Loss: 0.0407
Epoch [8/30], Batch [3800/6000], Loss: 0.0942
Epoch [8/30], Batch [3900/6000], Loss: 0.0558
Epoch [8/30], Batch [4000/6000], Loss: 0.1128
Epoch [8/30], Batch [4100/6000], Loss: 0.0580
Epoch [8/30], Batch [4200/6000], Loss: 0.0552
Epoch [8/30], Batch [4300/6000], Loss: 0.0544
Epoch [8/30], Batch [4400/6000], Loss: 0.0729
Epoch [8/30], Batch [4500/6000], Loss: 0.0577
Epoch [8/30], Batch [4600/6000], Loss: 0.0578
Epoch [8/30], Batch [4700/6000], Loss: 0.0486
Epoch [8/30], Batch [4800/6000], Loss: 0.0493
Epoch [8/30], Batch [4900/6000], Loss: 0.0608
Epoch [8/30], Batch [5000/6000], Loss: 0.0554
Epoch [8/30], Batch [5100/6000], Loss: 0.0503
Epoch [8/30], Batch [5200/6000], Loss: 0.0789
Epoch [8/30], Batch [5300/6000], Loss: 0.0512
Epoch [8/30], Batch [5400/6000], Loss: 0.0486
Epoch [8/30], Batch [5500/6000], Loss: 0.0535
Epoch [8/30], Batch [5600/6000], Loss: 0.0988
Epoch [8/30], Batch [5700/6000], Loss: 0.0574
Epoch [8/30], Batch [5800/6000], Loss: 0.0508
Epoch [8/30], Batch [5900/6000], Loss: 0.0493
Epoch [8/30], Loss: 0.0599
Epoch [9/30], Batch [0/6000], Loss: 0.0465
Epoch [9/30], Batch [100/6000], Loss: 0.0419
Epoch [9/30], Batch [200/6000], Loss: 0.0386
Epoch [9/30], Batch [300/6000], Loss: 0.0509
Epoch [9/30], Batch [400/6000], Loss: 0.0438
Epoch [9/30], Batch [500/6000], Loss: 0.0494
Epoch [9/30], Batch [600/6000], Loss: 0.1053
Epoch [9/30], Batch [700/6000], Loss: 0.0613
Epoch [9/30], Batch [800/6000], Loss: 0.0435
Epoch [9/30], Batch [900/6000], Loss: 0.0553
Epoch [9/30], Batch [1000/6000], Loss: 0.0616
Epoch [9/30], Batch [1100/6000], Loss: 0.0477
Epoch [9/30], Batch [1200/6000], Loss: 0.0479
Epoch [9/30], Batch [1300/6000], Loss: 0.0533
Epoch [9/30], Batch [1400/6000], Loss: 0.0507
Epoch [9/30], Batch [1500/6000], Loss: 0.0655
Epoch [9/30], Batch [1600/6000], Loss: 0.0711
Epoch [9/30], Batch [1700/6000], Loss: 0.0604
Epoch [9/30], Batch [1800/6000], Loss: 0.0780
Epoch [9/30], Batch [1900/6000], Loss: 0.0662
Epoch [9/30], Batch [2000/6000], Loss: 0.0440
Epoch [9/30], Batch [2100/6000], Loss: 0.0466
Epoch [9/30], Batch [2200/6000], Loss: 0.0977
Epoch [9/30], Batch [2300/6000], Loss: 0.0704
Epoch [9/30], Batch [2400/6000], Loss: 0.0518
Epoch [9/30], Batch [2500/6000], Loss: 0.0440
Epoch [9/30], Batch [2600/6000], Loss: 0.0501
Epoch [9/30], Batch [2700/6000], Loss: 0.0414
Epoch [9/30], Batch [2800/6000], Loss: 0.0501
Epoch [9/30], Batch [2900/6000], Loss: 0.0403
Epoch [9/30], Batch [3000/6000], Loss: 0.0686
Epoch [9/30], Batch [3100/6000], Loss: 0.0526
Epoch [9/30], Batch [3200/6000], Loss: 0.0356
Epoch [9/30], Batch [3300/6000], Loss: 0.0494
Epoch [9/30], Batch [3400/6000], Loss: 0.0448
Epoch [9/30], Batch [3500/6000], Loss: 0.0452
Epoch [9/30], Batch [3600/6000], Loss: 0.0494
Epoch [9/30], Batch [3700/6000], Loss: 0.0476
Epoch [9/30], Batch [3800/6000], Loss: 0.0673
Epoch [9/30], Batch [3900/6000], Loss: 0.0616
Epoch [9/30], Batch [4000/6000], Loss: 0.0388
Epoch [9/30], Batch [4100/6000], Loss: 0.0387
Epoch [9/30], Batch [4200/6000], Loss: 0.0703
Epoch [9/30], Batch [4300/6000], Loss: 0.0436
Epoch [9/30], Batch [4400/6000], Loss: 0.0554
Epoch [9/30], Batch [4500/6000], Loss: 0.0396
Epoch [9/30], Batch [4600/6000], Loss: 0.0639
Epoch [9/30], Batch [4700/6000], Loss: 0.0535
Epoch [9/30], Batch [4800/6000], Loss: 0.0803
Epoch [9/30], Batch [4900/6000], Loss: 0.0459
Epoch [9/30], Batch [5000/6000], Loss: 0.0567
Epoch [9/30], Batch [5100/6000], Loss: 0.0686
Epoch [9/30], Batch [5200/6000], Loss: 0.0698
Epoch [9/30], Batch [5300/6000], Loss: 0.0423
Epoch [9/30], Batch [5400/6000], Loss: 0.0714
Epoch [9/30], Batch [5500/6000], Loss: 0.0583
Epoch [9/30], Batch [5600/6000], Loss: 0.0514
Epoch [9/30], Batch [5700/6000], Loss: 0.0539
Epoch [9/30], Batch [5800/6000], Loss: 0.0509
Epoch [9/30], Batch [5900/6000], Loss: 0.0449
Epoch [9/30], Loss: 0.0567
Epoch [10/30], Batch [0/6000], Loss: 0.0389
Epoch [10/30], Batch [100/6000], Loss: 0.0568
Epoch [10/30], Batch [200/6000], Loss: 0.0602
Epoch [10/30], Batch [300/6000], Loss: 0.0556
Epoch [10/30], Batch [400/6000], Loss: 0.0819
Epoch [10/30], Batch [500/6000], Loss: 0.0713
Epoch [10/30], Batch [600/6000], Loss: 0.0541
Epoch [10/30], Batch [700/6000], Loss: 0.0494
Epoch [10/30], Batch [800/6000], Loss: 0.0447
Epoch [10/30], Batch [900/6000], Loss: 0.0583
Epoch [10/30], Batch [1000/6000], Loss: 0.0443
Epoch [10/30], Batch [1100/6000], Loss: 0.0549
Epoch [10/30], Batch [1200/6000], Loss: 0.0490
Epoch [10/30], Batch [1300/6000], Loss: 0.0665
Epoch [10/30], Batch [1400/6000], Loss: 0.0492
Epoch [10/30], Batch [1500/6000], Loss: 0.0508
Epoch [10/30], Batch [1600/6000], Loss: 0.0558
Epoch [10/30], Batch [1700/6000], Loss: 0.0525
Epoch [10/30], Batch [1800/6000], Loss: 0.0447
Epoch [10/30], Batch [1900/6000], Loss: 0.0556
Epoch [10/30], Batch [2000/6000], Loss: 0.0545
Epoch [10/30], Batch [2100/6000], Loss: 0.0685
Epoch [10/30], Batch [2200/6000], Loss: 0.0602
Epoch [10/30], Batch [2300/6000], Loss: 0.0548
Epoch [10/30], Batch [2400/6000], Loss: 0.0587
Epoch [10/30], Batch [2500/6000], Loss: 0.0626
Epoch [10/30], Batch [2600/6000], Loss: 0.0439
Epoch [10/30], Batch [2700/6000], Loss: 0.0657
Epoch [10/30], Batch [2800/6000], Loss: 0.0499
Epoch [10/30], Batch [2900/6000], Loss: 0.0398
Epoch [10/30], Batch [3000/6000], Loss: 0.0408
Epoch [10/30], Batch [3100/6000], Loss: 0.0965
Epoch [10/30], Batch [3200/6000], Loss: 0.0413
Epoch [10/30], Batch [3300/6000], Loss: 0.0472
Epoch [10/30], Batch [3400/6000], Loss: 0.0883
Epoch [10/30], Batch [3500/6000], Loss: 0.0432
Epoch [10/30], Batch [3600/6000], Loss: 0.0586
Epoch [10/30], Batch [3700/6000], Loss: 0.0447
Epoch [10/30], Batch [3800/6000], Loss: 0.0349
Epoch [10/30], Batch [3900/6000], Loss: 0.0371
Epoch [10/30], Batch [4000/6000], Loss: 0.0522
Epoch [10/30], Batch [4100/6000], Loss: 0.0488
Epoch [10/30], Batch [4200/6000], Loss: 0.0430
Epoch [10/30], Batch [4300/6000], Loss: 0.0473
Epoch [10/30], Batch [4400/6000], Loss: 0.0515
Epoch [10/30], Batch [4500/6000], Loss: 0.0425
Epoch [10/30], Batch [4600/6000], Loss: 0.0519
Epoch [10/30], Batch [4700/6000], Loss: 0.0496
Epoch [10/30], Batch [4800/6000], Loss: 0.0550
Epoch [10/30], Batch [4900/6000], Loss: 0.0553
Epoch [10/30], Batch [5000/6000], Loss: 0.0490
Epoch [10/30], Batch [5100/6000], Loss: 0.0525
Epoch [10/30], Batch [5200/6000], Loss: 0.0350
Epoch [10/30], Batch [5300/6000], Loss: 0.0412
Epoch [10/30], Batch [5400/6000], Loss: 0.0431
Epoch [10/30], Batch [5500/6000], Loss: 0.0350
Epoch [10/30], Batch [5600/6000], Loss: 0.0475
Epoch [10/30], Batch [5700/6000], Loss: 0.0342
Epoch [10/30], Batch [5800/6000], Loss: 0.0509
Epoch [10/30], Batch [5900/6000], Loss: 0.0664
Epoch [10/30], Loss: 0.0538
Epoch [11/30], Batch [0/6000], Loss: 0.0568
Epoch [11/30], Batch [100/6000], Loss: 0.0758
Epoch [11/30], Batch [200/6000], Loss: 0.0548
Epoch [11/30], Batch [300/6000], Loss: 0.0456
Epoch [11/30], Batch [400/6000], Loss: 0.0601
Epoch [11/30], Batch [500/6000], Loss: 0.0524
Epoch [11/30], Batch [600/6000], Loss: 0.0394
Epoch [11/30], Batch [700/6000], Loss: 0.1012
Epoch [11/30], Batch [800/6000], Loss: 0.0412
Epoch [11/30], Batch [900/6000], Loss: 0.0451
Epoch [11/30], Batch [1000/6000], Loss: 0.0392
Epoch [11/30], Batch [1100/6000], Loss: 0.0497
Epoch [11/30], Batch [1200/6000], Loss: 0.0773
Epoch [11/30], Batch [1300/6000], Loss: 0.0461
Epoch [11/30], Batch [1400/6000], Loss: 0.0686
Epoch [11/30], Batch [1500/6000], Loss: 0.0521
Epoch [11/30], Batch [1600/6000], Loss: 0.0408
Epoch [11/30], Batch [1700/6000], Loss: 0.0452
Epoch [11/30], Batch [1800/6000], Loss: 0.0529
Epoch [11/30], Batch [1900/6000], Loss: 0.0355
Epoch [11/30], Batch [2000/6000], Loss: 0.0361
Epoch [11/30], Batch [2100/6000], Loss: 0.0440
Epoch [11/30], Batch [2200/6000], Loss: 0.0528
Epoch [11/30], Batch [2300/6000], Loss: 0.0774
Epoch [11/30], Batch [2400/6000], Loss: 0.0472
Epoch [11/30], Batch [2500/6000], Loss: 0.0343
Epoch [11/30], Batch [2600/6000], Loss: 0.0415
Epoch [11/30], Batch [2700/6000], Loss: 0.0342
Epoch [11/30], Batch [2800/6000], Loss: 0.0478
Epoch [11/30], Batch [2900/6000], Loss: 0.0420
Epoch [11/30], Batch [3000/6000], Loss: 0.0437
Epoch [11/30], Batch [3100/6000], Loss: 0.0457
Epoch [11/30], Batch [3200/6000], Loss: 0.0471
Epoch [11/30], Batch [3300/6000], Loss: 0.0406
Epoch [11/30], Batch [3400/6000], Loss: 0.0488
Epoch [11/30], Batch [3500/6000], Loss: 0.0377
Epoch [11/30], Batch [3600/6000], Loss: 0.0467
Epoch [11/30], Batch [3700/6000], Loss: 0.0618
Epoch [11/30], Batch [3800/6000], Loss: 0.0459
Epoch [11/30], Batch [3900/6000], Loss: 0.0525
Epoch [11/30], Batch [4000/6000], Loss: 0.0404
Epoch [11/30], Batch [4100/6000], Loss: 0.0546
Epoch [11/30], Batch [4200/6000], Loss: 0.0464
Epoch [11/30], Batch [4300/6000], Loss: 0.0723
Epoch [11/30], Batch [4400/6000], Loss: 0.0532
Epoch [11/30], Batch [4500/6000], Loss: 0.0415
Epoch [11/30], Batch [4600/6000], Loss: 0.0581
Epoch [11/30], Batch [4700/6000], Loss: 0.0493
Epoch [11/30], Batch [4800/6000], Loss: 0.0459
Epoch [11/30], Batch [4900/6000], Loss: 0.0644
Epoch [11/30], Batch [5000/6000], Loss: 0.0534
Epoch [11/30], Batch [5100/6000], Loss: 0.0487
Epoch [11/30], Batch [5200/6000], Loss: 0.0719
Epoch [11/30], Batch [5300/6000], Loss: 0.0506
Epoch [11/30], Batch [5400/6000], Loss: 0.0444
Epoch [11/30], Batch [5500/6000], Loss: 0.0400
Epoch [11/30], Batch [5600/6000], Loss: 0.0492
Epoch [11/30], Batch [5700/6000], Loss: 0.0440
Epoch [11/30], Batch [5800/6000], Loss: 0.0383
Epoch [11/30], Batch [5900/6000], Loss: 0.0410
Epoch [11/30], Loss: 0.0518
Epoch [12/30], Batch [0/6000], Loss: 0.0606
Epoch [12/30], Batch [100/6000], Loss: 0.0458
Epoch [12/30], Batch [200/6000], Loss: 0.0575
Epoch [12/30], Batch [300/6000], Loss: 0.0683
Epoch [12/30], Batch [400/6000], Loss: 0.0416
Epoch [12/30], Batch [500/6000], Loss: 0.0564
Epoch [12/30], Batch [600/6000], Loss: 0.0623
Epoch [12/30], Batch [700/6000], Loss: 0.0382
Epoch [12/30], Batch [800/6000], Loss: 0.0422
Epoch [12/30], Batch [900/6000], Loss: 0.0435
Epoch [12/30], Batch [1000/6000], Loss: 0.0439
Epoch [12/30], Batch [1100/6000], Loss: 0.0501
Epoch [12/30], Batch [1200/6000], Loss: 0.0361
Epoch [12/30], Batch [1300/6000], Loss: 0.0646
Epoch [12/30], Batch [1400/6000], Loss: 0.0538
Epoch [12/30], Batch [1500/6000], Loss: 0.0527
Epoch [12/30], Batch [1600/6000], Loss: 0.0527
Epoch [12/30], Batch [1700/6000], Loss: 0.0561
Epoch [12/30], Batch [1800/6000], Loss: 0.0499
Epoch [12/30], Batch [1900/6000], Loss: 0.0560
Epoch [12/30], Batch [2000/6000], Loss: 0.0530
Epoch [12/30], Batch [2100/6000], Loss: 0.0939
Epoch [12/30], Batch [2200/6000], Loss: 0.0552
Epoch [12/30], Batch [2300/6000], Loss: 0.0360
Epoch [12/30], Batch [2400/6000], Loss: 0.0458
Epoch [12/30], Batch [2500/6000], Loss: 0.0510
Epoch [12/30], Batch [2600/6000], Loss: 0.0575
Epoch [12/30], Batch [2700/6000], Loss: 0.0458
Epoch [12/30], Batch [2800/6000], Loss: 0.0537
Epoch [12/30], Batch [2900/6000], Loss: 0.0541
Epoch [12/30], Batch [3000/6000], Loss: 0.0480
Epoch [12/30], Batch [3100/6000], Loss: 0.0374
Epoch [12/30], Batch [3200/6000], Loss: 0.0484
Epoch [12/30], Batch [3300/6000], Loss: 0.0510
Epoch [12/30], Batch [3400/6000], Loss: 0.0402
Epoch [12/30], Batch [3500/6000], Loss: 0.0452
Epoch [12/30], Batch [3600/6000], Loss: 0.0385
Epoch [12/30], Batch [3700/6000], Loss: 0.0491
Epoch [12/30], Batch [3800/6000], Loss: 0.0405
Epoch [12/30], Batch [3900/6000], Loss: 0.0544
Epoch [12/30], Batch [4000/6000], Loss: 0.0458
Epoch [12/30], Batch [4100/6000], Loss: 0.0498
Epoch [12/30], Batch [4200/6000], Loss: 0.0352
Epoch [12/30], Batch [4300/6000], Loss: 0.0527
Epoch [12/30], Batch [4400/6000], Loss: 0.0524
Epoch [12/30], Batch [4500/6000], Loss: 0.0541
Epoch [12/30], Batch [4600/6000], Loss: 0.0532
Epoch [12/30], Batch [4700/6000], Loss: 0.0445
Epoch [12/30], Batch [4800/6000], Loss: 0.0423
Epoch [12/30], Batch [4900/6000], Loss: 0.0537
Epoch [12/30], Batch [5000/6000], Loss: 0.0440
Epoch [12/30], Batch [5100/6000], Loss: 0.0314
Epoch [12/30], Batch [5200/6000], Loss: 0.0406
Epoch [12/30], Batch [5300/6000], Loss: 0.0614
Epoch [12/30], Batch [5400/6000], Loss: 0.0484
Epoch [12/30], Batch [5500/6000], Loss: 0.0386
Epoch [12/30], Batch [5600/6000], Loss: 0.0376
Epoch [12/30], Batch [5700/6000], Loss: 0.0496
Epoch [12/30], Batch [5800/6000], Loss: 0.1040
Epoch [12/30], Batch [5900/6000], Loss: 0.0426
Epoch [12/30], Loss: 0.0497
Epoch [13/30], Batch [0/6000], Loss: 0.0435
Epoch [13/30], Batch [100/6000], Loss: 0.0479
Epoch [13/30], Batch [200/6000], Loss: 0.0350
Epoch [13/30], Batch [300/6000], Loss: 0.0979
Epoch [13/30], Batch [400/6000], Loss: 0.0475
Epoch [13/30], Batch [500/6000], Loss: 0.0393
Epoch [13/30], Batch [600/6000], Loss: 0.0508
Epoch [13/30], Batch [700/6000], Loss: 0.0418
Epoch [13/30], Batch [800/6000], Loss: 0.0418
Epoch [13/30], Batch [900/6000], Loss: 0.0453
Epoch [13/30], Batch [1000/6000], Loss: 0.0395
Epoch [13/30], Batch [1100/6000], Loss: 0.0426
Epoch [13/30], Batch [1200/6000], Loss: 0.0617
Epoch [13/30], Batch [1300/6000], Loss: 0.0427
Epoch [13/30], Batch [1400/6000], Loss: 0.0414
Epoch [13/30], Batch [1500/6000], Loss: 0.0359
Epoch [13/30], Batch [1600/6000], Loss: 0.0542
Epoch [13/30], Batch [1700/6000], Loss: 0.0630
Epoch [13/30], Batch [1800/6000], Loss: 0.0505
Epoch [13/30], Batch [1900/6000], Loss: 0.0449
Epoch [13/30], Batch [2000/6000], Loss: 0.0469
Epoch [13/30], Batch [2100/6000], Loss: 0.0524
Epoch [13/30], Batch [2200/6000], Loss: 0.0581
Epoch [13/30], Batch [2300/6000], Loss: 0.0343
Epoch [13/30], Batch [2400/6000], Loss: 0.0371
Epoch [13/30], Batch [2500/6000], Loss: 0.0528
Epoch [13/30], Batch [2600/6000], Loss: 0.0479
Epoch [13/30], Batch [2700/6000], Loss: 0.0523
Epoch [13/30], Batch [2800/6000], Loss: 0.0443
Epoch [13/30], Batch [2900/6000], Loss: 0.0599
Epoch [13/30], Batch [3000/6000], Loss: 0.0369
Epoch [13/30], Batch [3100/6000], Loss: 0.0616
Epoch [13/30], Batch [3200/6000], Loss: 0.0620
Epoch [13/30], Batch [3300/6000], Loss: 0.0480
Epoch [13/30], Batch [3400/6000], Loss: 0.0411
Epoch [13/30], Batch [3500/6000], Loss: 0.0430
Epoch [13/30], Batch [3600/6000], Loss: 0.0495
Epoch [13/30], Batch [3700/6000], Loss: 0.0347
Epoch [13/30], Batch [3800/6000], Loss: 0.0515
Epoch [13/30], Batch [3900/6000], Loss: 0.0548
Epoch [13/30], Batch [4000/6000], Loss: 0.0551
Epoch [13/30], Batch [4100/6000], Loss: 0.0467
Epoch [13/30], Batch [4200/6000], Loss: 0.0469
Epoch [13/30], Batch [4300/6000], Loss: 0.0473
Epoch [13/30], Batch [4400/6000], Loss: 0.0635
Epoch [13/30], Batch [4500/6000], Loss: 0.0406
Epoch [13/30], Batch [4600/6000], Loss: 0.0400
Epoch [13/30], Batch [4700/6000], Loss: 0.0620
Epoch [13/30], Batch [4800/6000], Loss: 0.0587
Epoch [13/30], Batch [4900/6000], Loss: 0.0331
Epoch [13/30], Batch [5000/6000], Loss: 0.0484
Epoch [13/30], Batch [5100/6000], Loss: 0.0454
Epoch [13/30], Batch [5200/6000], Loss: 0.0417
Epoch [13/30], Batch [5300/6000], Loss: 0.0342
Epoch [13/30], Batch [5400/6000], Loss: 0.0435
Epoch [13/30], Batch [5500/6000], Loss: 0.0380
Epoch [13/30], Batch [5600/6000], Loss: 0.0488
Epoch [13/30], Batch [5700/6000], Loss: 0.0370
Epoch [13/30], Batch [5800/6000], Loss: 0.0468
Epoch [13/30], Batch [5900/6000], Loss: 0.0367
Epoch [13/30], Loss: 0.0482
Epoch [14/30], Batch [0/6000], Loss: 0.0402
Epoch [14/30], Batch [100/6000], Loss: 0.0452
Epoch [14/30], Batch [200/6000], Loss: 0.0469
Epoch [14/30], Batch [300/6000], Loss: 0.0433
Epoch [14/30], Batch [400/6000], Loss: 0.0558
Epoch [14/30], Batch [500/6000], Loss: 0.0491
Epoch [14/30], Batch [600/6000], Loss: 0.0423
Epoch [14/30], Batch [700/6000], Loss: 0.0416
Epoch [14/30], Batch [800/6000], Loss: 0.0380
Epoch [14/30], Batch [900/6000], Loss: 0.0497
Epoch [14/30], Batch [1000/6000], Loss: 0.0399
Epoch [14/30], Batch [1100/6000], Loss: 0.0430
Epoch [14/30], Batch [1200/6000], Loss: 0.0444
Epoch [14/30], Batch [1300/6000], Loss: 0.0612
Epoch [14/30], Batch [1400/6000], Loss: 0.0499
Epoch [14/30], Batch [1500/6000], Loss: 0.0445
Epoch [14/30], Batch [1600/6000], Loss: 0.0488
Epoch [14/30], Batch [1700/6000], Loss: 0.0499
Epoch [14/30], Batch [1800/6000], Loss: 0.0508
Epoch [14/30], Batch [1900/6000], Loss: 0.0366
Epoch [14/30], Batch [2000/6000], Loss: 0.0509
Epoch [14/30], Batch [2100/6000], Loss: 0.0396
Epoch [14/30], Batch [2200/6000], Loss: 0.0363
Epoch [14/30], Batch [2300/6000], Loss: 0.0412
Epoch [14/30], Batch [2400/6000], Loss: 0.0345
Epoch [14/30], Batch [2500/6000], Loss: 0.0543
Epoch [14/30], Batch [2600/6000], Loss: 0.0417
Epoch [14/30], Batch [2700/6000], Loss: 0.0790
Epoch [14/30], Batch [2800/6000], Loss: 0.0398
Epoch [14/30], Batch [2900/6000], Loss: 0.0543
Epoch [14/30], Batch [3000/6000], Loss: 0.0438
Epoch [14/30], Batch [3100/6000], Loss: 0.0413
Epoch [14/30], Batch [3200/6000], Loss: 0.0367
Epoch [14/30], Batch [3300/6000], Loss: 0.0406
Epoch [14/30], Batch [3400/6000], Loss: 0.0520
Epoch [14/30], Batch [3500/6000], Loss: 0.0422
Epoch [14/30], Batch [3600/6000], Loss: 0.0417
Epoch [14/30], Batch [3700/6000], Loss: 0.0386
Epoch [14/30], Batch [3800/6000], Loss: 0.0471
Epoch [14/30], Batch [3900/6000], Loss: 0.0895
Epoch [14/30], Batch [4000/6000], Loss: 0.0345
Epoch [14/30], Batch [4100/6000], Loss: 0.0519
Epoch [14/30], Batch [4200/6000], Loss: 0.0441
Epoch [14/30], Batch [4300/6000], Loss: 0.0360
Epoch [14/30], Batch [4400/6000], Loss: 0.0518
Epoch [14/30], Batch [4500/6000], Loss: 0.0354
Epoch [14/30], Batch [4600/6000], Loss: 0.0431
Epoch [14/30], Batch [4700/6000], Loss: 0.0441
Epoch [14/30], Batch [4800/6000], Loss: 0.0482
Epoch [14/30], Batch [4900/6000], Loss: 0.0430
Epoch [14/30], Batch [5000/6000], Loss: 0.0426
Epoch [14/30], Batch [5100/6000], Loss: 0.0493
Epoch [14/30], Batch [5200/6000], Loss: 0.0418
Epoch [14/30], Batch [5300/6000], Loss: 0.0511
Epoch [14/30], Batch [5400/6000], Loss: 0.0419
Epoch [14/30], Batch [5500/6000], Loss: 0.0376
Epoch [14/30], Batch [5600/6000], Loss: 0.0400
Epoch [14/30], Batch [5700/6000], Loss: 0.0404
Epoch [14/30], Batch [5800/6000], Loss: 0.0492
Epoch [14/30], Batch [5900/6000], Loss: 0.0428
Epoch [14/30], Loss: 0.0463
Epoch [15/30], Batch [0/6000], Loss: 0.0477
Epoch [15/30], Batch [100/6000], Loss: 0.0419
Epoch [15/30], Batch [200/6000], Loss: 0.0376
Epoch [15/30], Batch [300/6000], Loss: 0.0312
Epoch [15/30], Batch [400/6000], Loss: 0.0420
Epoch [15/30], Batch [500/6000], Loss: 0.0452
Epoch [15/30], Batch [600/6000], Loss: 0.0342
Epoch [15/30], Batch [700/6000], Loss: 0.0418
Epoch [15/30], Batch [800/6000], Loss: 0.0394
Epoch [15/30], Batch [900/6000], Loss: 0.0792
Epoch [15/30], Batch [1000/6000], Loss: 0.0414
Epoch [15/30], Batch [1100/6000], Loss: 0.0373
Epoch [15/30], Batch [1200/6000], Loss: 0.0427
Epoch [15/30], Batch [1300/6000], Loss: 0.0599
Epoch [15/30], Batch [1400/6000], Loss: 0.0377
Epoch [15/30], Batch [1500/6000], Loss: 0.0436
Epoch [15/30], Batch [1600/6000], Loss: 0.0316
Epoch [15/30], Batch [1700/6000], Loss: 0.0649
Epoch [15/30], Batch [1800/6000], Loss: 0.0344
Epoch [15/30], Batch [1900/6000], Loss: 0.0459
Epoch [15/30], Batch [2000/6000], Loss: 0.0507
Epoch [15/30], Batch [2100/6000], Loss: 0.0536
Epoch [15/30], Batch [2200/6000], Loss: 0.0525
Epoch [15/30], Batch [2300/6000], Loss: 0.0380
Epoch [15/30], Batch [2400/6000], Loss: 0.0430
Epoch [15/30], Batch [2500/6000], Loss: 0.0492
Epoch [15/30], Batch [2600/6000], Loss: 0.0407
Epoch [15/30], Batch [2700/6000], Loss: 0.0785
Epoch [15/30], Batch [2800/6000], Loss: 0.0453
Epoch [15/30], Batch [2900/6000], Loss: 0.0396
Epoch [15/30], Batch [3000/6000], Loss: 0.0335
Epoch [15/30], Batch [3100/6000], Loss: 0.0397
Epoch [15/30], Batch [3200/6000], Loss: 0.0452
Epoch [15/30], Batch [3300/6000], Loss: 0.0397
Epoch [15/30], Batch [3400/6000], Loss: 0.0301
Epoch [15/30], Batch [3500/6000], Loss: 0.0466
Epoch [15/30], Batch [3600/6000], Loss: 0.0488
Epoch [15/30], Batch [3700/6000], Loss: 0.0313
Epoch [15/30], Batch [3800/6000], Loss: 0.0358
Epoch [15/30], Batch [3900/6000], Loss: 0.0463
Epoch [15/30], Batch [4000/6000], Loss: 0.0413
Epoch [15/30], Batch [4100/6000], Loss: 0.0450
Epoch [15/30], Batch [4200/6000], Loss: 0.0312
Epoch [15/30], Batch [4300/6000], Loss: 0.0410
Epoch [15/30], Batch [4400/6000], Loss: 0.0390
Epoch [15/30], Batch [4500/6000], Loss: 0.0396
Epoch [15/30], Batch [4600/6000], Loss: 0.0416
Epoch [15/30], Batch [4700/6000], Loss: 0.0563
Epoch [15/30], Batch [4800/6000], Loss: 0.0347
Epoch [15/30], Batch [4900/6000], Loss: 0.0408
Epoch [15/30], Batch [5000/6000], Loss: 0.0357
Epoch [15/30], Batch [5100/6000], Loss: 0.0277
Epoch [15/30], Batch [5200/6000], Loss: 0.0725
Epoch [15/30], Batch [5300/6000], Loss: 0.0414
Epoch [15/30], Batch [5400/6000], Loss: 0.0425
Epoch [15/30], Batch [5500/6000], Loss: 0.0344
Epoch [15/30], Batch [5600/6000], Loss: 0.0418
Epoch [15/30], Batch [5700/6000], Loss: 0.0399
Epoch [15/30], Batch [5800/6000], Loss: 0.0486
Epoch [15/30], Batch [5900/6000], Loss: 0.0363
Epoch [15/30], Loss: 0.0448
Epoch [16/30], Batch [0/6000], Loss: 0.0468
Epoch [16/30], Batch [100/6000], Loss: 0.0410
Epoch [16/30], Batch [200/6000], Loss: 0.0396
Epoch [16/30], Batch [300/6000], Loss: 0.0412
Epoch [16/30], Batch [400/6000], Loss: 0.0298
Epoch [16/30], Batch [500/6000], Loss: 0.0638
Epoch [16/30], Batch [600/6000], Loss: 0.0404
Epoch [16/30], Batch [700/6000], Loss: 0.0408
Epoch [16/30], Batch [800/6000], Loss: 0.0390
Epoch [16/30], Batch [900/6000], Loss: 0.0574
Epoch [16/30], Batch [1000/6000], Loss: 0.0388
Epoch [16/30], Batch [1100/6000], Loss: 0.0415
Epoch [16/30], Batch [1200/6000], Loss: 0.0381
Epoch [16/30], Batch [1300/6000], Loss: 0.0471
Epoch [16/30], Batch [1400/6000], Loss: 0.0475
Epoch [16/30], Batch [1500/6000], Loss: 0.0436
Epoch [16/30], Batch [1600/6000], Loss: 0.0357
Epoch [16/30], Batch [1700/6000], Loss: 0.0373
Epoch [16/30], Batch [1800/6000], Loss: 0.0540
Epoch [16/30], Batch [1900/6000], Loss: 0.0403
Epoch [16/30], Batch [2000/6000], Loss: 0.0611
Epoch [16/30], Batch [2100/6000], Loss: 0.0589
Epoch [16/30], Batch [2200/6000], Loss: 0.0312
Epoch [16/30], Batch [2300/6000], Loss: 0.0353
Epoch [16/30], Batch [2400/6000], Loss: 0.0349
Epoch [16/30], Batch [2500/6000], Loss: 0.0334
Epoch [16/30], Batch [2600/6000], Loss: 0.0307
Epoch [16/30], Batch [2700/6000], Loss: 0.0348
Epoch [16/30], Batch [2800/6000], Loss: 0.0347
Epoch [16/30], Batch [2900/6000], Loss: 0.0428
Epoch [16/30], Batch [3000/6000], Loss: 0.0619
Epoch [16/30], Batch [3100/6000], Loss: 0.0464
Epoch [16/30], Batch [3200/6000], Loss: 0.0548
Epoch [16/30], Batch [3300/6000], Loss: 0.0327
Epoch [16/30], Batch [3400/6000], Loss: 0.0519
Epoch [16/30], Batch [3500/6000], Loss: 0.0799
Epoch [16/30], Batch [3600/6000], Loss: 0.0347
Epoch [16/30], Batch [3700/6000], Loss: 0.0379
Epoch [16/30], Batch [3800/6000], Loss: 0.0391
Epoch [16/30], Batch [3900/6000], Loss: 0.0366
Epoch [16/30], Batch [4000/6000], Loss: 0.0539
Epoch [16/30], Batch [4100/6000], Loss: 0.0331
Epoch [16/30], Batch [4200/6000], Loss: 0.0334
Epoch [16/30], Batch [4300/6000], Loss: 0.0438
Epoch [16/30], Batch [4400/6000], Loss: 0.0543
Epoch [16/30], Batch [4500/6000], Loss: 0.0481
Epoch [16/30], Batch [4600/6000], Loss: 0.0493
Epoch [16/30], Batch [4700/6000], Loss: 0.0420
Epoch [16/30], Batch [4800/6000], Loss: 0.0707
Epoch [16/30], Batch [4900/6000], Loss: 0.0543
Epoch [16/30], Batch [5000/6000], Loss: 0.0315
Epoch [16/30], Batch [5100/6000], Loss: 0.0493
Epoch [16/30], Batch [5200/6000], Loss: 0.0349
Epoch [16/30], Batch [5300/6000], Loss: 0.0507
Epoch [16/30], Batch [5400/6000], Loss: 0.0424
Epoch [16/30], Batch [5500/6000], Loss: 0.0396
Epoch [16/30], Batch [5600/6000], Loss: 0.0429
Epoch [16/30], Batch [5700/6000], Loss: 0.0361
Epoch [16/30], Batch [5800/6000], Loss: 0.0658
Epoch [16/30], Batch [5900/6000], Loss: 0.0506
Epoch [16/30], Loss: 0.0436
Epoch [17/30], Batch [0/6000], Loss: 0.0420
Epoch [17/30], Batch [100/6000], Loss: 0.0427
Epoch [17/30], Batch [200/6000], Loss: 0.0504
Epoch [17/30], Batch [300/6000], Loss: 0.0372
Epoch [17/30], Batch [400/6000], Loss: 0.0346
Epoch [17/30], Batch [500/6000], Loss: 0.0319
Epoch [17/30], Batch [600/6000], Loss: 0.0413
Epoch [17/30], Batch [700/6000], Loss: 0.0494
Epoch [17/30], Batch [800/6000], Loss: 0.0477
Epoch [17/30], Batch [900/6000], Loss: 0.0401
Epoch [17/30], Batch [1000/6000], Loss: 0.0475
Epoch [17/30], Batch [1100/6000], Loss: 0.0590
Epoch [17/30], Batch [1200/6000], Loss: 0.0479
Epoch [17/30], Batch [1300/6000], Loss: 0.0718
Epoch [17/30], Batch [1400/6000], Loss: 0.0356
Epoch [17/30], Batch [1500/6000], Loss: 0.0478
Epoch [17/30], Batch [1600/6000], Loss: 0.0355
Epoch [17/30], Batch [1700/6000], Loss: 0.0359
Epoch [17/30], Batch [1800/6000], Loss: 0.0295
Epoch [17/30], Batch [1900/6000], Loss: 0.0421
Epoch [17/30], Batch [2000/6000], Loss: 0.0452
Epoch [17/30], Batch [2100/6000], Loss: 0.0324
Epoch [17/30], Batch [2200/6000], Loss: 0.0437
Epoch [17/30], Batch [2300/6000], Loss: 0.0443
Epoch [17/30], Batch [2400/6000], Loss: 0.0383
Epoch [17/30], Batch [2500/6000], Loss: 0.0253
Epoch [17/30], Batch [2600/6000], Loss: 0.0480
Epoch [17/30], Batch [2700/6000], Loss: 0.0325
Epoch [17/30], Batch [2800/6000], Loss: 0.0464
Epoch [17/30], Batch [2900/6000], Loss: 0.0481
Epoch [17/30], Batch [3000/6000], Loss: 0.0508
Epoch [17/30], Batch [3100/6000], Loss: 0.0603
Epoch [17/30], Batch [3200/6000], Loss: 0.0390
Epoch [17/30], Batch [3300/6000], Loss: 0.0263
Epoch [17/30], Batch [3400/6000], Loss: 0.0580
Epoch [17/30], Batch [3500/6000], Loss: 0.0416
Epoch [17/30], Batch [3600/6000], Loss: 0.0397
Epoch [17/30], Batch [3700/6000], Loss: 0.0392
Epoch [17/30], Batch [3800/6000], Loss: 0.0500
Epoch [17/30], Batch [3900/6000], Loss: 0.0429
Epoch [17/30], Batch [4000/6000], Loss: 0.0430
Epoch [17/30], Batch [4100/6000], Loss: 0.0333
Epoch [17/30], Batch [4200/6000], Loss: 0.1397
Epoch [17/30], Batch [4300/6000], Loss: 0.0380
Epoch [17/30], Batch [4400/6000], Loss: 0.0376
Epoch [17/30], Batch [4500/6000], Loss: 0.0356
Epoch [17/30], Batch [4600/6000], Loss: 0.0421
Epoch [17/30], Batch [4700/6000], Loss: 0.0391
Epoch [17/30], Batch [4800/6000], Loss: 0.0400
Epoch [17/30], Batch [4900/6000], Loss: 0.0412
Epoch [17/30], Batch [5000/6000], Loss: 0.0470
Epoch [17/30], Batch [5100/6000], Loss: 0.0344
Epoch [17/30], Batch [5200/6000], Loss: 0.0449
Epoch [17/30], Batch [5300/6000], Loss: 0.0329
Epoch [17/30], Batch [5400/6000], Loss: 0.0379
Epoch [17/30], Batch [5500/6000], Loss: 0.0494
Epoch [17/30], Batch [5600/6000], Loss: 0.0408
Epoch [17/30], Batch [5700/6000], Loss: 0.0355
Epoch [17/30], Batch [5800/6000], Loss: 0.0360
Epoch [17/30], Batch [5900/6000], Loss: 0.0378
Epoch [17/30], Loss: 0.0424
Epoch [18/30], Batch [0/6000], Loss: 0.0525
Epoch [18/30], Batch [100/6000], Loss: 0.0376
Epoch [18/30], Batch [200/6000], Loss: 0.0426
Epoch [18/30], Batch [300/6000], Loss: 0.0366
Epoch [18/30], Batch [400/6000], Loss: 0.0417
Epoch [18/30], Batch [500/6000], Loss: 0.0340
Epoch [18/30], Batch [600/6000], Loss: 0.0443
Epoch [18/30], Batch [700/6000], Loss: 0.0463
Epoch [18/30], Batch [800/6000], Loss: 0.0351
Epoch [18/30], Batch [900/6000], Loss: 0.0355
Epoch [18/30], Batch [1000/6000], Loss: 0.0354
Epoch [18/30], Batch [1100/6000], Loss: 0.0409
Epoch [18/30], Batch [1200/6000], Loss: 0.0363
Epoch [18/30], Batch [1300/6000], Loss: 0.0345
Epoch [18/30], Batch [1400/6000], Loss: 0.0358
Epoch [18/30], Batch [1500/6000], Loss: 0.0473
Epoch [18/30], Batch [1600/6000], Loss: 0.0390
Epoch [18/30], Batch [1700/6000], Loss: 0.0345
Epoch [18/30], Batch [1800/6000], Loss: 0.0415
Epoch [18/30], Batch [1900/6000], Loss: 0.0381
Epoch [18/30], Batch [2000/6000], Loss: 0.0394
Epoch [18/30], Batch [2100/6000], Loss: 0.0408
Epoch [18/30], Batch [2200/6000], Loss: 0.0440
Epoch [18/30], Batch [2300/6000], Loss: 0.0377
Epoch [18/30], Batch [2400/6000], Loss: 0.0400
Epoch [18/30], Batch [2500/6000], Loss: 0.0478
Epoch [18/30], Batch [2600/6000], Loss: 0.0489
Epoch [18/30], Batch [2700/6000], Loss: 0.0369
Epoch [18/30], Batch [2800/6000], Loss: 0.0374
Epoch [18/30], Batch [2900/6000], Loss: 0.0359
Epoch [18/30], Batch [3000/6000], Loss: 0.0318
Epoch [18/30], Batch [3100/6000], Loss: 0.0351
Epoch [18/30], Batch [3200/6000], Loss: 0.0400
Epoch [18/30], Batch [3300/6000], Loss: 0.0288
Epoch [18/30], Batch [3400/6000], Loss: 0.0635
Epoch [18/30], Batch [3500/6000], Loss: 0.0338
Epoch [18/30], Batch [3600/6000], Loss: 0.0660
Epoch [18/30], Batch [3700/6000], Loss: 0.0284
Epoch [18/30], Batch [3800/6000], Loss: 0.0397
Epoch [18/30], Batch [3900/6000], Loss: 0.0429
Epoch [18/30], Batch [4000/6000], Loss: 0.0378
Epoch [18/30], Batch [4100/6000], Loss: 0.0429
Epoch [18/30], Batch [4200/6000], Loss: 0.0428
Epoch [18/30], Batch [4300/6000], Loss: 0.0339
Epoch [18/30], Batch [4400/6000], Loss: 0.0392
Epoch [18/30], Batch [4500/6000], Loss: 0.0597
Epoch [18/30], Batch [4600/6000], Loss: 0.0456
Epoch [18/30], Batch [4700/6000], Loss: 0.0411
Epoch [18/30], Batch [4800/6000], Loss: 0.0405
Epoch [18/30], Batch [4900/6000], Loss: 0.0559
Epoch [18/30], Batch [5000/6000], Loss: 0.0282
Epoch [18/30], Batch [5100/6000], Loss: 0.0355
Epoch [18/30], Batch [5200/6000], Loss: 0.0368
Epoch [18/30], Batch [5300/6000], Loss: 0.0281
Epoch [18/30], Batch [5400/6000], Loss: 0.0413
Epoch [18/30], Batch [5500/6000], Loss: 0.0412
Epoch [18/30], Batch [5600/6000], Loss: 0.0412
Epoch [18/30], Batch [5700/6000], Loss: 0.0442
Epoch [18/30], Batch [5800/6000], Loss: 0.0281
Epoch [18/30], Batch [5900/6000], Loss: 0.0367
Epoch [18/30], Loss: 0.0414
Epoch [19/30], Batch [0/6000], Loss: 0.0420
Epoch [19/30], Batch [100/6000], Loss: 0.0346
Epoch [19/30], Batch [200/6000], Loss: 0.0393
Epoch [19/30], Batch [300/6000], Loss: 0.0805
Epoch [19/30], Batch [400/6000], Loss: 0.0347
Epoch [19/30], Batch [500/6000], Loss: 0.0318
Epoch [19/30], Batch [600/6000], Loss: 0.0433
Epoch [19/30], Batch [700/6000], Loss: 0.0477
Epoch [19/30], Batch [800/6000], Loss: 0.0373
Epoch [19/30], Batch [900/6000], Loss: 0.0376
Epoch [19/30], Batch [1000/6000], Loss: 0.0289
Epoch [19/30], Batch [1100/6000], Loss: 0.0334
Epoch [19/30], Batch [1200/6000], Loss: 0.0284
Epoch [19/30], Batch [1300/6000], Loss: 0.0320
Epoch [19/30], Batch [1400/6000], Loss: 0.0362
Epoch [19/30], Batch [1500/6000], Loss: 0.0409
Epoch [19/30], Batch [1600/6000], Loss: 0.0346
Epoch [19/30], Batch [1700/6000], Loss: 0.0365
Epoch [19/30], Batch [1800/6000], Loss: 0.0449
Epoch [19/30], Batch [1900/6000], Loss: 0.0432
Epoch [19/30], Batch [2000/6000], Loss: 0.0502
Epoch [19/30], Batch [2100/6000], Loss: 0.0392
Epoch [19/30], Batch [2200/6000], Loss: 0.0376
Epoch [19/30], Batch [2300/6000], Loss: 0.0375
Epoch [19/30], Batch [2400/6000], Loss: 0.0429
Epoch [19/30], Batch [2500/6000], Loss: 0.0395
Epoch [19/30], Batch [2600/6000], Loss: 0.0332
Epoch [19/30], Batch [2700/6000], Loss: 0.0637
Epoch [19/30], Batch [2800/6000], Loss: 0.0424
Epoch [19/30], Batch [2900/6000], Loss: 0.0361
Epoch [19/30], Batch [3000/6000], Loss: 0.0475
Epoch [19/30], Batch [3100/6000], Loss: 0.0364
Epoch [19/30], Batch [3200/6000], Loss: 0.0440
Epoch [19/30], Batch [3300/6000], Loss: 0.0377
Epoch [19/30], Batch [3400/6000], Loss: 0.0557
Epoch [19/30], Batch [3500/6000], Loss: 0.0404
Epoch [19/30], Batch [3600/6000], Loss: 0.0453
Epoch [19/30], Batch [3700/6000], Loss: 0.0445
Epoch [19/30], Batch [3800/6000], Loss: 0.0511
Epoch [19/30], Batch [3900/6000], Loss: 0.0390
Epoch [19/30], Batch [4000/6000], Loss: 0.0806
Epoch [19/30], Batch [4100/6000], Loss: 0.0356
Epoch [19/30], Batch [4200/6000], Loss: 0.0346
Epoch [19/30], Batch [4300/6000], Loss: 0.0346
Epoch [19/30], Batch [4400/6000], Loss: 0.0439
Epoch [19/30], Batch [4500/6000], Loss: 0.0462
Epoch [19/30], Batch [4600/6000], Loss: 0.0337
Epoch [19/30], Batch [4700/6000], Loss: 0.0340
Epoch [19/30], Batch [4800/6000], Loss: 0.0397
Epoch [19/30], Batch [4900/6000], Loss: 0.0357
Epoch [19/30], Batch [5000/6000], Loss: 0.0387
Epoch [19/30], Batch [5100/6000], Loss: 0.0280
Epoch [19/30], Batch [5200/6000], Loss: 0.0363
Epoch [19/30], Batch [5300/6000], Loss: 0.0459
Epoch [19/30], Batch [5400/6000], Loss: 0.0332
Epoch [19/30], Batch [5500/6000], Loss: 0.0373
Epoch [19/30], Batch [5600/6000], Loss: 0.0302
Epoch [19/30], Batch [5700/6000], Loss: 0.0351
Epoch [19/30], Batch [5800/6000], Loss: 0.0343
Epoch [19/30], Batch [5900/6000], Loss: 0.0559
Epoch [19/30], Loss: 0.0404
Epoch [20/30], Batch [0/6000], Loss: 0.0385
Epoch [20/30], Batch [100/6000], Loss: 0.0368
Epoch [20/30], Batch [200/6000], Loss: 0.0392
Epoch [20/30], Batch [300/6000], Loss: 0.0378
Epoch [20/30], Batch [400/6000], Loss: 0.0528
Epoch [20/30], Batch [500/6000], Loss: 0.0397
Epoch [20/30], Batch [600/6000], Loss: 0.0270
Epoch [20/30], Batch [700/6000], Loss: 0.0398
Epoch [20/30], Batch [800/6000], Loss: 0.0333
Epoch [20/30], Batch [900/6000], Loss: 0.0411
Epoch [20/30], Batch [1000/6000], Loss: 0.0276
Epoch [20/30], Batch [1100/6000], Loss: 0.0411
Epoch [20/30], Batch [1200/6000], Loss: 0.0321
Epoch [20/30], Batch [1300/6000], Loss: 0.0290
Epoch [20/30], Batch [1400/6000], Loss: 0.0322
Epoch [20/30], Batch [1500/6000], Loss: 0.0428
Epoch [20/30], Batch [1600/6000], Loss: 0.0352
Epoch [20/30], Batch [1700/6000], Loss: 0.0417
Epoch [20/30], Batch [1800/6000], Loss: 0.0246
Epoch [20/30], Batch [1900/6000], Loss: 0.0316
Epoch [20/30], Batch [2000/6000], Loss: 0.0329
Epoch [20/30], Batch [2100/6000], Loss: 0.0417
Epoch [20/30], Batch [2200/6000], Loss: 0.0339
Epoch [20/30], Batch [2300/6000], Loss: 0.0320
Epoch [20/30], Batch [2400/6000], Loss: 0.0475
Epoch [20/30], Batch [2500/6000], Loss: 0.0567
Epoch [20/30], Batch [2600/6000], Loss: 0.0288
Epoch [20/30], Batch [2700/6000], Loss: 0.0357
Epoch [20/30], Batch [2800/6000], Loss: 0.0355
Epoch [20/30], Batch [2900/6000], Loss: 0.0440
Epoch [20/30], Batch [3000/6000], Loss: 0.0360
Epoch [20/30], Batch [3100/6000], Loss: 0.0355
Epoch [20/30], Batch [3200/6000], Loss: 0.0394
Epoch [20/30], Batch [3300/6000], Loss: 0.0364
Epoch [20/30], Batch [3400/6000], Loss: 0.0373
Epoch [20/30], Batch [3500/6000], Loss: 0.0404
Epoch [20/30], Batch [3600/6000], Loss: 0.0481
Epoch [20/30], Batch [3700/6000], Loss: 0.0362
Epoch [20/30], Batch [3800/6000], Loss: 0.0420
Epoch [20/30], Batch [3900/6000], Loss: 0.0355
Epoch [20/30], Batch [4000/6000], Loss: 0.0408
Epoch [20/30], Batch [4100/6000], Loss: 0.0361
Epoch [20/30], Batch [4200/6000], Loss: 0.0429
Epoch [20/30], Batch [4300/6000], Loss: 0.0405
Epoch [20/30], Batch [4400/6000], Loss: 0.0401
Epoch [20/30], Batch [4500/6000], Loss: 0.0363
Epoch [20/30], Batch [4600/6000], Loss: 0.0382
Epoch [20/30], Batch [4700/6000], Loss: 0.0323
Epoch [20/30], Batch [4800/6000], Loss: 0.0310
Epoch [20/30], Batch [4900/6000], Loss: 0.0364
Epoch [20/30], Batch [5000/6000], Loss: 0.0398
Epoch [20/30], Batch [5100/6000], Loss: 0.0353
Epoch [20/30], Batch [5200/6000], Loss: 0.0318
Epoch [20/30], Batch [5300/6000], Loss: 0.0375
Epoch [20/30], Batch [5400/6000], Loss: 0.0365
Epoch [20/30], Batch [5500/6000], Loss: 0.0501
Epoch [20/30], Batch [5600/6000], Loss: 0.0348
Epoch [20/30], Batch [5700/6000], Loss: 0.0394
Epoch [20/30], Batch [5800/6000], Loss: 0.1001
Epoch [20/30], Batch [5900/6000], Loss: 0.0436
Epoch [20/30], Loss: 0.0394
Epoch [21/30], Batch [0/6000], Loss: 0.0310
Epoch [21/30], Batch [100/6000], Loss: 0.0331
Epoch [21/30], Batch [200/6000], Loss: 0.0477
Epoch [21/30], Batch [300/6000], Loss: 0.0312
Epoch [21/30], Batch [400/6000], Loss: 0.0485
Epoch [21/30], Batch [500/6000], Loss: 0.0443
Epoch [21/30], Batch [600/6000], Loss: 0.0473
Epoch [21/30], Batch [700/6000], Loss: 0.0336
Epoch [21/30], Batch [800/6000], Loss: 0.0353
Epoch [21/30], Batch [900/6000], Loss: 0.0283
Epoch [21/30], Batch [1000/6000], Loss: 0.0363
Epoch [21/30], Batch [1100/6000], Loss: 0.0551
Epoch [21/30], Batch [1200/6000], Loss: 0.0544
Epoch [21/30], Batch [1300/6000], Loss: 0.0301
Epoch [21/30], Batch [1400/6000], Loss: 0.0271
Epoch [21/30], Batch [1500/6000], Loss: 0.0394
Epoch [21/30], Batch [1600/6000], Loss: 0.0319
Epoch [21/30], Batch [1700/6000], Loss: 0.0496
Epoch [21/30], Batch [1800/6000], Loss: 0.0421
Epoch [21/30], Batch [1900/6000], Loss: 0.0425
Epoch [21/30], Batch [2000/6000], Loss: 0.0351
Epoch [21/30], Batch [2100/6000], Loss: 0.0260
Epoch [21/30], Batch [2200/6000], Loss: 0.0367
Epoch [21/30], Batch [2300/6000], Loss: 0.0367
Epoch [21/30], Batch [2400/6000], Loss: 0.0336
Epoch [21/30], Batch [2500/6000], Loss: 0.0377
Epoch [21/30], Batch [2600/6000], Loss: 0.0347
Epoch [21/30], Batch [2700/6000], Loss: 0.0352
Epoch [21/30], Batch [2800/6000], Loss: 0.0391
Epoch [21/30], Batch [2900/6000], Loss: 0.0347
Epoch [21/30], Batch [3000/6000], Loss: 0.0375
Epoch [21/30], Batch [3100/6000], Loss: 0.0251
Epoch [21/30], Batch [3200/6000], Loss: 0.0318
Epoch [21/30], Batch [3300/6000], Loss: 0.0417
Epoch [21/30], Batch [3400/6000], Loss: 0.0410
Epoch [21/30], Batch [3500/6000], Loss: 0.0480
Epoch [21/30], Batch [3600/6000], Loss: 0.0352
Epoch [21/30], Batch [3700/6000], Loss: 0.0300
Epoch [21/30], Batch [3800/6000], Loss: 0.0367
Epoch [21/30], Batch [3900/6000], Loss: 0.0339
Epoch [21/30], Batch [4000/6000], Loss: 0.0367
Epoch [21/30], Batch [4100/6000], Loss: 0.0290
Epoch [21/30], Batch [4200/6000], Loss: 0.0501
Epoch [21/30], Batch [4300/6000], Loss: 0.0408
Epoch [21/30], Batch [4400/6000], Loss: 0.0356
Epoch [21/30], Batch [4500/6000], Loss: 0.0340
Epoch [21/30], Batch [4600/6000], Loss: 0.0329
Epoch [21/30], Batch [4700/6000], Loss: 0.0251
Epoch [21/30], Batch [4800/6000], Loss: 0.0372
Epoch [21/30], Batch [4900/6000], Loss: 0.0228
Epoch [21/30], Batch [5000/6000], Loss: 0.0354
Epoch [21/30], Batch [5100/6000], Loss: 0.0310
Epoch [21/30], Batch [5200/6000], Loss: 0.0509
Epoch [21/30], Batch [5300/6000], Loss: 0.0368
Epoch [21/30], Batch [5400/6000], Loss: 0.0677
Epoch [21/30], Batch [5500/6000], Loss: 0.0390
Epoch [21/30], Batch [5600/6000], Loss: 0.0308
Epoch [21/30], Batch [5700/6000], Loss: 0.0304
Epoch [21/30], Batch [5800/6000], Loss: 0.0494
Epoch [21/30], Batch [5900/6000], Loss: 0.0328
Epoch [21/30], Loss: 0.0385
Epoch [22/30], Batch [0/6000], Loss: 0.0403
Epoch [22/30], Batch [100/6000], Loss: 0.0298
Epoch [22/30], Batch [200/6000], Loss: 0.0396
Epoch [22/30], Batch [300/6000], Loss: 0.0385
Epoch [22/30], Batch [400/6000], Loss: 0.0392
Epoch [22/30], Batch [500/6000], Loss: 0.0247
Epoch [22/30], Batch [600/6000], Loss: 0.0411
Epoch [22/30], Batch [700/6000], Loss: 0.0577
Epoch [22/30], Batch [800/6000], Loss: 0.0373
Epoch [22/30], Batch [900/6000], Loss: 0.0436
Epoch [22/30], Batch [1000/6000], Loss: 0.0302
Epoch [22/30], Batch [1100/6000], Loss: 0.0385
Epoch [22/30], Batch [1200/6000], Loss: 0.0321
Epoch [22/30], Batch [1300/6000], Loss: 0.0346
Epoch [22/30], Batch [1400/6000], Loss: 0.0397
Epoch [22/30], Batch [1500/6000], Loss: 0.0385
Epoch [22/30], Batch [1600/6000], Loss: 0.0402
Epoch [22/30], Batch [1700/6000], Loss: 0.0402
Epoch [22/30], Batch [1800/6000], Loss: 0.0390
Epoch [22/30], Batch [1900/6000], Loss: 0.0432
Epoch [22/30], Batch [2000/6000], Loss: 0.0267
Epoch [22/30], Batch [2100/6000], Loss: 0.0378
Epoch [22/30], Batch [2200/6000], Loss: 0.0340
Epoch [22/30], Batch [2300/6000], Loss: 0.0327
Epoch [22/30], Batch [2400/6000], Loss: 0.0402
Epoch [22/30], Batch [2500/6000], Loss: 0.0281
Epoch [22/30], Batch [2600/6000], Loss: 0.0391
Epoch [22/30], Batch [2700/6000], Loss: 0.0311
Epoch [22/30], Batch [2800/6000], Loss: 0.0398
Epoch [22/30], Batch [2900/6000], Loss: 0.0355
Epoch [22/30], Batch [3000/6000], Loss: 0.0378
Epoch [22/30], Batch [3100/6000], Loss: 0.0367
Epoch [22/30], Batch [3200/6000], Loss: 0.0422
Epoch [22/30], Batch [3300/6000], Loss: 0.0290
Epoch [22/30], Batch [3400/6000], Loss: 0.0292
Epoch [22/30], Batch [3500/6000], Loss: 0.0361
Epoch [22/30], Batch [3600/6000], Loss: 0.0376
Epoch [22/30], Batch [3700/6000], Loss: 0.0400
Epoch [22/30], Batch [3800/6000], Loss: 0.0370
Epoch [22/30], Batch [3900/6000], Loss: 0.0366
Epoch [22/30], Batch [4000/6000], Loss: 0.0475
Epoch [22/30], Batch [4100/6000], Loss: 0.0346
Epoch [22/30], Batch [4200/6000], Loss: 0.0403
Epoch [22/30], Batch [4300/6000], Loss: 0.0413
Epoch [22/30], Batch [4400/6000], Loss: 0.0392
Epoch [22/30], Batch [4500/6000], Loss: 0.0364
Epoch [22/30], Batch [4600/6000], Loss: 0.0314
Epoch [22/30], Batch [4700/6000], Loss: 0.0390
Epoch [22/30], Batch [4800/6000], Loss: 0.0375
Epoch [22/30], Batch [4900/6000], Loss: 0.0366
Epoch [22/30], Batch [5000/6000], Loss: 0.0523
Epoch [22/30], Batch [5100/6000], Loss: 0.0326
Epoch [22/30], Batch [5200/6000], Loss: 0.0484
Epoch [22/30], Batch [5300/6000], Loss: 0.0451
Epoch [22/30], Batch [5400/6000], Loss: 0.0326
Epoch [22/30], Batch [5500/6000], Loss: 0.0377
Epoch [22/30], Batch [5600/6000], Loss: 0.0522
Epoch [22/30], Batch [5700/6000], Loss: 0.0584
Epoch [22/30], Batch [5800/6000], Loss: 0.0340
Epoch [22/30], Batch [5900/6000], Loss: 0.0395
Epoch [22/30], Loss: 0.0378
Epoch [23/30], Batch [0/6000], Loss: 0.0327
Epoch [23/30], Batch [100/6000], Loss: 0.0361
Epoch [23/30], Batch [200/6000], Loss: 0.0480
Epoch [23/30], Batch [300/6000], Loss: 0.0299
Epoch [23/30], Batch [400/6000], Loss: 0.0384
Epoch [23/30], Batch [500/6000], Loss: 0.0340
Epoch [23/30], Batch [600/6000], Loss: 0.0332
Epoch [23/30], Batch [700/6000], Loss: 0.0291
Epoch [23/30], Batch [800/6000], Loss: 0.0259
Epoch [23/30], Batch [900/6000], Loss: 0.0368
Epoch [23/30], Batch [1000/6000], Loss: 0.0352
Epoch [23/30], Batch [1100/6000], Loss: 0.0286
Epoch [23/30], Batch [1200/6000], Loss: 0.0359
Epoch [23/30], Batch [1300/6000], Loss: 0.0384
Epoch [23/30], Batch [1400/6000], Loss: 0.0353
Epoch [23/30], Batch [1500/6000], Loss: 0.0243
Epoch [23/30], Batch [1600/6000], Loss: 0.0276
Epoch [23/30], Batch [1700/6000], Loss: 0.0371
Epoch [23/30], Batch [1800/6000], Loss: 0.0352
Epoch [23/30], Batch [1900/6000], Loss: 0.0291
Epoch [23/30], Batch [2000/6000], Loss: 0.0348
Epoch [23/30], Batch [2100/6000], Loss: 0.0413
Epoch [23/30], Batch [2200/6000], Loss: 0.0326
Epoch [23/30], Batch [2300/6000], Loss: 0.0315
Epoch [23/30], Batch [2400/6000], Loss: 0.0302
Epoch [23/30], Batch [2500/6000], Loss: 0.0584
Epoch [23/30], Batch [2600/6000], Loss: 0.0383
Epoch [23/30], Batch [2700/6000], Loss: 0.0319
Epoch [23/30], Batch [2800/6000], Loss: 0.0365
Epoch [23/30], Batch [2900/6000], Loss: 0.0404
Epoch [23/30], Batch [3000/6000], Loss: 0.0294
Epoch [23/30], Batch [3100/6000], Loss: 0.0326
Epoch [23/30], Batch [3200/6000], Loss: 0.0340
Epoch [23/30], Batch [3300/6000], Loss: 0.0387
Epoch [23/30], Batch [3400/6000], Loss: 0.0368
Epoch [23/30], Batch [3500/6000], Loss: 0.0504
Epoch [23/30], Batch [3600/6000], Loss: 0.0337
Epoch [23/30], Batch [3700/6000], Loss: 0.0440
Epoch [23/30], Batch [3800/6000], Loss: 0.0341
Epoch [23/30], Batch [3900/6000], Loss: 0.0329
Epoch [23/30], Batch [4000/6000], Loss: 0.0414
Epoch [23/30], Batch [4100/6000], Loss: 0.0283
Epoch [23/30], Batch [4200/6000], Loss: 0.0483
Epoch [23/30], Batch [4300/6000], Loss: 0.0480
Epoch [23/30], Batch [4400/6000], Loss: 0.0355
Epoch [23/30], Batch [4500/6000], Loss: 0.0285
Epoch [23/30], Batch [4600/6000], Loss: 0.0442
Epoch [23/30], Batch [4700/6000], Loss: 0.0396
Epoch [23/30], Batch [4800/6000], Loss: 0.0521
Epoch [23/30], Batch [4900/6000], Loss: 0.0390
Epoch [23/30], Batch [5000/6000], Loss: 0.0342
Epoch [23/30], Batch [5100/6000], Loss: 0.0309
Epoch [23/30], Batch [5200/6000], Loss: 0.0360
Epoch [23/30], Batch [5300/6000], Loss: 0.0448
Epoch [23/30], Batch [5400/6000], Loss: 0.0281
Epoch [23/30], Batch [5500/6000], Loss: 0.0494
Epoch [23/30], Batch [5600/6000], Loss: 0.0290
Epoch [23/30], Batch [5700/6000], Loss: 0.0381
Epoch [23/30], Batch [5800/6000], Loss: 0.0295
Epoch [23/30], Batch [5900/6000], Loss: 0.0283
Epoch [23/30], Loss: 0.0368
Epoch [24/30], Batch [0/6000], Loss: 0.0464
Epoch [24/30], Batch [100/6000], Loss: 0.0435
Epoch [24/30], Batch [200/6000], Loss: 0.0359
Epoch [24/30], Batch [300/6000], Loss: 0.0332
Epoch [24/30], Batch [400/6000], Loss: 0.0337
Epoch [24/30], Batch [500/6000], Loss: 0.0436
Epoch [24/30], Batch [600/6000], Loss: 0.0286
Epoch [24/30], Batch [700/6000], Loss: 0.0258
Epoch [24/30], Batch [800/6000], Loss: 0.0302
Epoch [24/30], Batch [900/6000], Loss: 0.0482
Epoch [24/30], Batch [1000/6000], Loss: 0.0397
Epoch [24/30], Batch [1100/6000], Loss: 0.0321
Epoch [24/30], Batch [1200/6000], Loss: 0.0280
Epoch [24/30], Batch [1300/6000], Loss: 0.0349
Epoch [24/30], Batch [1400/6000], Loss: 0.0264
Epoch [24/30], Batch [1500/6000], Loss: 0.0327
Epoch [24/30], Batch [1600/6000], Loss: 0.0338
Epoch [24/30], Batch [1700/6000], Loss: 0.0317
Epoch [24/30], Batch [1800/6000], Loss: 0.0347
Epoch [24/30], Batch [1900/6000], Loss: 0.0291
Epoch [24/30], Batch [2000/6000], Loss: 0.0353
Epoch [24/30], Batch [2100/6000], Loss: 0.0324
Epoch [24/30], Batch [2200/6000], Loss: 0.0339
Epoch [24/30], Batch [2300/6000], Loss: 0.0331
Epoch [24/30], Batch [2400/6000], Loss: 0.0310
Epoch [24/30], Batch [2500/6000], Loss: 0.0516
Epoch [24/30], Batch [2600/6000], Loss: 0.0340
Epoch [24/30], Batch [2700/6000], Loss: 0.0517
Epoch [24/30], Batch [2800/6000], Loss: 0.0310
Epoch [24/30], Batch [2900/6000], Loss: 0.0411
Epoch [24/30], Batch [3000/6000], Loss: 0.0263
Epoch [24/30], Batch [3100/6000], Loss: 0.0268
Epoch [24/30], Batch [3200/6000], Loss: 0.0345
Epoch [24/30], Batch [3300/6000], Loss: 0.0317
Epoch [24/30], Batch [3400/6000], Loss: 0.0231
Epoch [24/30], Batch [3500/6000], Loss: 0.0383
Epoch [24/30], Batch [3600/6000], Loss: 0.0420
Epoch [24/30], Batch [3700/6000], Loss: 0.0289
Epoch [24/30], Batch [3800/6000], Loss: 0.0632
Epoch [24/30], Batch [3900/6000], Loss: 0.0357
Epoch [24/30], Batch [4000/6000], Loss: 0.0435
Epoch [24/30], Batch [4100/6000], Loss: 0.0244
Epoch [24/30], Batch [4200/6000], Loss: 0.0971
Epoch [24/30], Batch [4300/6000], Loss: 0.0530
Epoch [24/30], Batch [4400/6000], Loss: 0.0453
Epoch [24/30], Batch [4500/6000], Loss: 0.0364
Epoch [24/30], Batch [4600/6000], Loss: 0.0282
Epoch [24/30], Batch [4700/6000], Loss: 0.0314
Epoch [24/30], Batch [4800/6000], Loss: 0.0415
Epoch [24/30], Batch [4900/6000], Loss: 0.0337
Epoch [24/30], Batch [5000/6000], Loss: 0.0325
Epoch [24/30], Batch [5100/6000], Loss: 0.0342
Epoch [24/30], Batch [5200/6000], Loss: 0.0433
Epoch [24/30], Batch [5300/6000], Loss: 0.0416
Epoch [24/30], Batch [5400/6000], Loss: 0.0402
Epoch [24/30], Batch [5500/6000], Loss: 0.0274
Epoch [24/30], Batch [5600/6000], Loss: 0.0275
Epoch [24/30], Batch [5700/6000], Loss: 0.0356
Epoch [24/30], Batch [5800/6000], Loss: 0.0257
Epoch [24/30], Batch [5900/6000], Loss: 0.0357
Epoch [24/30], Loss: 0.0363
Epoch [25/30], Batch [0/6000], Loss: 0.0364
Epoch [25/30], Batch [100/6000], Loss: 0.0377
Epoch [25/30], Batch [200/6000], Loss: 0.0272
Epoch [25/30], Batch [300/6000], Loss: 0.0375
Epoch [25/30], Batch [400/6000], Loss: 0.0463
Epoch [25/30], Batch [500/6000], Loss: 0.0308
Epoch [25/30], Batch [600/6000], Loss: 0.0413
Epoch [25/30], Batch [700/6000], Loss: 0.0283
Epoch [25/30], Batch [800/6000], Loss: 0.0322
Epoch [25/30], Batch [900/6000], Loss: 0.0288
Epoch [25/30], Batch [1000/6000], Loss: 0.0348
Epoch [25/30], Batch [1100/6000], Loss: 0.0291
Epoch [25/30], Batch [1200/6000], Loss: 0.0286
Epoch [25/30], Batch [1300/6000], Loss: 0.0406
Epoch [25/30], Batch [1400/6000], Loss: 0.0350
Epoch [25/30], Batch [1500/6000], Loss: 0.0358
Epoch [25/30], Batch [1600/6000], Loss: 0.0276
Epoch [25/30], Batch [1700/6000], Loss: 0.0393
Epoch [25/30], Batch [1800/6000], Loss: 0.0316
Epoch [25/30], Batch [1900/6000], Loss: 0.0289
Epoch [25/30], Batch [2000/6000], Loss: 0.0345
Epoch [25/30], Batch [2100/6000], Loss: 0.0305
Epoch [25/30], Batch [2200/6000], Loss: 0.0378
Epoch [25/30], Batch [2300/6000], Loss: 0.0299
Epoch [25/30], Batch [2400/6000], Loss: 0.0409
Epoch [25/30], Batch [2500/6000], Loss: 0.0409
Epoch [25/30], Batch [2600/6000], Loss: 0.0355
Epoch [25/30], Batch [2700/6000], Loss: 0.0313
Epoch [25/30], Batch [2800/6000], Loss: 0.0325
Epoch [25/30], Batch [2900/6000], Loss: 0.0370
Epoch [25/30], Batch [3000/6000], Loss: 0.0296
Epoch [25/30], Batch [3100/6000], Loss: 0.0386
Epoch [25/30], Batch [3200/6000], Loss: 0.0372
Epoch [25/30], Batch [3300/6000], Loss: 0.0361
Epoch [25/30], Batch [3400/6000], Loss: 0.0317
Epoch [25/30], Batch [3500/6000], Loss: 0.0252
Epoch [25/30], Batch [3600/6000], Loss: 0.0349
Epoch [25/30], Batch [3700/6000], Loss: 0.0305
Epoch [25/30], Batch [3800/6000], Loss: 0.0485
Epoch [25/30], Batch [3900/6000], Loss: 0.0314
Epoch [25/30], Batch [4000/6000], Loss: 0.0416
Epoch [25/30], Batch [4100/6000], Loss: 0.0322
Epoch [25/30], Batch [4200/6000], Loss: 0.0434
Epoch [25/30], Batch [4300/6000], Loss: 0.0286
Epoch [25/30], Batch [4400/6000], Loss: 0.0335
Epoch [25/30], Batch [4500/6000], Loss: 0.0294
Epoch [25/30], Batch [4600/6000], Loss: 0.0452
Epoch [25/30], Batch [4700/6000], Loss: 0.0336
Epoch [25/30], Batch [4800/6000], Loss: 0.0333
Epoch [25/30], Batch [4900/6000], Loss: 0.0422
Epoch [25/30], Batch [5000/6000], Loss: 0.0374
Epoch [25/30], Batch [5100/6000], Loss: 0.0306
Epoch [25/30], Batch [5200/6000], Loss: 0.0338
Epoch [25/30], Batch [5300/6000], Loss: 0.0387
Epoch [25/30], Batch [5400/6000], Loss: 0.0433
Epoch [25/30], Batch [5500/6000], Loss: 0.0312
Epoch [25/30], Batch [5600/6000], Loss: 0.0264
Epoch [25/30], Batch [5700/6000], Loss: 0.0305
Epoch [25/30], Batch [5800/6000], Loss: 0.0402
Epoch [25/30], Batch [5900/6000], Loss: 0.0354
Epoch [25/30], Loss: 0.0356
Epoch [26/30], Batch [0/6000], Loss: 0.0380
Epoch [26/30], Batch [100/6000], Loss: 0.0315
Epoch [26/30], Batch [200/6000], Loss: 0.0359
Epoch [26/30], Batch [300/6000], Loss: 0.0356
Epoch [26/30], Batch [400/6000], Loss: 0.0364
Epoch [26/30], Batch [500/6000], Loss: 0.0305
Epoch [26/30], Batch [600/6000], Loss: 0.0322
Epoch [26/30], Batch [700/6000], Loss: 0.0302
Epoch [26/30], Batch [800/6000], Loss: 0.0274
Epoch [26/30], Batch [900/6000], Loss: 0.0268
Epoch [26/30], Batch [1000/6000], Loss: 0.0290
Epoch [26/30], Batch [1100/6000], Loss: 0.0353
Epoch [26/30], Batch [1200/6000], Loss: 0.0377
Epoch [26/30], Batch [1300/6000], Loss: 0.0383
Epoch [26/30], Batch [1400/6000], Loss: 0.0283
Epoch [26/30], Batch [1500/6000], Loss: 0.0286
Epoch [26/30], Batch [1600/6000], Loss: 0.0273
Epoch [26/30], Batch [1700/6000], Loss: 0.0292
Epoch [26/30], Batch [1800/6000], Loss: 0.0514
Epoch [26/30], Batch [1900/6000], Loss: 0.0390
Epoch [26/30], Batch [2000/6000], Loss: 0.0354
Epoch [26/30], Batch [2100/6000], Loss: 0.0359
Epoch [26/30], Batch [2200/6000], Loss: 0.0350
Epoch [26/30], Batch [2300/6000], Loss: 0.0387
Epoch [26/30], Batch [2400/6000], Loss: 0.0377
Epoch [26/30], Batch [2500/6000], Loss: 0.0349
Epoch [26/30], Batch [2600/6000], Loss: 0.0277
Epoch [26/30], Batch [2700/6000], Loss: 0.0216
Epoch [26/30], Batch [2800/6000], Loss: 0.0259
Epoch [26/30], Batch [2900/6000], Loss: 0.0322
Epoch [26/30], Batch [3000/6000], Loss: 0.0308
Epoch [26/30], Batch [3100/6000], Loss: 0.0326
Epoch [26/30], Batch [3200/6000], Loss: 0.0381
Epoch [26/30], Batch [3300/6000], Loss: 0.0295
Epoch [26/30], Batch [3400/6000], Loss: 0.0380
Epoch [26/30], Batch [3500/6000], Loss: 0.0530
Epoch [26/30], Batch [3600/6000], Loss: 0.0514
Epoch [26/30], Batch [3700/6000], Loss: 0.0333
Epoch [26/30], Batch [3800/6000], Loss: 0.0358
Epoch [26/30], Batch [3900/6000], Loss: 0.0266
Epoch [26/30], Batch [4000/6000], Loss: 0.0352
Epoch [26/30], Batch [4100/6000], Loss: 0.0250
Epoch [26/30], Batch [4200/6000], Loss: 0.0435
Epoch [26/30], Batch [4300/6000], Loss: 0.0374
Epoch [26/30], Batch [4400/6000], Loss: 0.0417
Epoch [26/30], Batch [4500/6000], Loss: 0.0341
Epoch [26/30], Batch [4600/6000], Loss: 0.0300
Epoch [26/30], Batch [4700/6000], Loss: 0.0390
Epoch [26/30], Batch [4800/6000], Loss: 0.0292
Epoch [26/30], Batch [4900/6000], Loss: 0.0259
Epoch [26/30], Batch [5000/6000], Loss: 0.0322
Epoch [26/30], Batch [5100/6000], Loss: 0.0369
Epoch [26/30], Batch [5200/6000], Loss: 0.0301
Epoch [26/30], Batch [5300/6000], Loss: 0.0280
Epoch [26/30], Batch [5400/6000], Loss: 0.0261
Epoch [26/30], Batch [5500/6000], Loss: 0.0423
Epoch [26/30], Batch [5600/6000], Loss: 0.0286
Epoch [26/30], Batch [5700/6000], Loss: 0.0693
Epoch [26/30], Batch [5800/6000], Loss: 0.0433
Epoch [26/30], Batch [5900/6000], Loss: 0.0338
Epoch [26/30], Loss: 0.0349
Epoch [27/30], Batch [0/6000], Loss: 0.0362
Epoch [27/30], Batch [100/6000], Loss: 0.0237
Epoch [27/30], Batch [200/6000], Loss: 0.0280
Epoch [27/30], Batch [300/6000], Loss: 0.0292
Epoch [27/30], Batch [400/6000], Loss: 0.0324
Epoch [27/30], Batch [500/6000], Loss: 0.0353
Epoch [27/30], Batch [600/6000], Loss: 0.0457
Epoch [27/30], Batch [700/6000], Loss: 0.0378
Epoch [27/30], Batch [800/6000], Loss: 0.0423
Epoch [27/30], Batch [900/6000], Loss: 0.0293
Epoch [27/30], Batch [1000/6000], Loss: 0.0362
Epoch [27/30], Batch [1100/6000], Loss: 0.0263
Epoch [27/30], Batch [1200/6000], Loss: 0.0323
Epoch [27/30], Batch [1300/6000], Loss: 0.0343
Epoch [27/30], Batch [1400/6000], Loss: 0.0271
Epoch [27/30], Batch [1500/6000], Loss: 0.0316
Epoch [27/30], Batch [1600/6000], Loss: 0.0382
Epoch [27/30], Batch [1700/6000], Loss: 0.0281
Epoch [27/30], Batch [1800/6000], Loss: 0.0291
Epoch [27/30], Batch [1900/6000], Loss: 0.0359
Epoch [27/30], Batch [2000/6000], Loss: 0.0349
Epoch [27/30], Batch [2100/6000], Loss: 0.0286
Epoch [27/30], Batch [2200/6000], Loss: 0.0358
Epoch [27/30], Batch [2300/6000], Loss: 0.0321
Epoch [27/30], Batch [2400/6000], Loss: 0.0792
Epoch [27/30], Batch [2500/6000], Loss: 0.0351
Epoch [27/30], Batch [2600/6000], Loss: 0.0272
Epoch [27/30], Batch [2700/6000], Loss: 0.0358
Epoch [27/30], Batch [2800/6000], Loss: 0.0364
Epoch [27/30], Batch [2900/6000], Loss: 0.0277
Epoch [27/30], Batch [3000/6000], Loss: 0.0432
Epoch [27/30], Batch [3100/6000], Loss: 0.0342
Epoch [27/30], Batch [3200/6000], Loss: 0.0289
Epoch [27/30], Batch [3300/6000], Loss: 0.0313
Epoch [27/30], Batch [3400/6000], Loss: 0.0342
Epoch [27/30], Batch [3500/6000], Loss: 0.0415
Epoch [27/30], Batch [3600/6000], Loss: 0.0236
Epoch [27/30], Batch [3700/6000], Loss: 0.0300
Epoch [27/30], Batch [3800/6000], Loss: 0.0287
Epoch [27/30], Batch [3900/6000], Loss: 0.0338
Epoch [27/30], Batch [4000/6000], Loss: 0.0311
Epoch [27/30], Batch [4100/6000], Loss: 0.0561
Epoch [27/30], Batch [4200/6000], Loss: 0.0337
Epoch [27/30], Batch [4300/6000], Loss: 0.0376
Epoch [27/30], Batch [4400/6000], Loss: 0.0323
Epoch [27/30], Batch [4500/6000], Loss: 0.0292
Epoch [27/30], Batch [4600/6000], Loss: 0.0292
Epoch [27/30], Batch [4700/6000], Loss: 0.0271
Epoch [27/30], Batch [4800/6000], Loss: 0.0268
Epoch [27/30], Batch [4900/6000], Loss: 0.0349
Epoch [27/30], Batch [5000/6000], Loss: 0.0384
Epoch [27/30], Batch [5100/6000], Loss: 0.0301
Epoch [27/30], Batch [5200/6000], Loss: 0.0236
Epoch [27/30], Batch [5300/6000], Loss: 0.0319
Epoch [27/30], Batch [5400/6000], Loss: 0.0327
Epoch [27/30], Batch [5500/6000], Loss: 0.0370
Epoch [27/30], Batch [5600/6000], Loss: 0.0388
Epoch [27/30], Batch [5700/6000], Loss: 0.0355
Epoch [27/30], Batch [5800/6000], Loss: 0.0232
Epoch [27/30], Batch [5900/6000], Loss: 0.0334
Epoch [27/30], Loss: 0.0341
Epoch [28/30], Batch [0/6000], Loss: 0.0226
Epoch [28/30], Batch [100/6000], Loss: 0.0499
Epoch [28/30], Batch [200/6000], Loss: 0.0363
Epoch [28/30], Batch [300/6000], Loss: 0.0320
Epoch [28/30], Batch [400/6000], Loss: 0.0301
Epoch [28/30], Batch [500/6000], Loss: 0.0267
Epoch [28/30], Batch [600/6000], Loss: 0.0238
Epoch [28/30], Batch [700/6000], Loss: 0.0365
Epoch [28/30], Batch [800/6000], Loss: 0.0257
Epoch [28/30], Batch [900/6000], Loss: 0.0271
Epoch [28/30], Batch [1000/6000], Loss: 0.0348
Epoch [28/30], Batch [1100/6000], Loss: 0.0260
Epoch [28/30], Batch [1200/6000], Loss: 0.0284
Epoch [28/30], Batch [1300/6000], Loss: 0.0308
Epoch [28/30], Batch [1400/6000], Loss: 0.0365
Epoch [28/30], Batch [1500/6000], Loss: 0.0327
Epoch [28/30], Batch [1600/6000], Loss: 0.0319
Epoch [28/30], Batch [1700/6000], Loss: 0.0333
Epoch [28/30], Batch [1800/6000], Loss: 0.0327
Epoch [28/30], Batch [1900/6000], Loss: 0.0384
Epoch [28/30], Batch [2000/6000], Loss: 0.0296
Epoch [28/30], Batch [2100/6000], Loss: 0.0290
Epoch [28/30], Batch [2200/6000], Loss: 0.0400
Epoch [28/30], Batch [2300/6000], Loss: 0.0598
Epoch [28/30], Batch [2400/6000], Loss: 0.0354
Epoch [28/30], Batch [2500/6000], Loss: 0.0300
Epoch [28/30], Batch [2600/6000], Loss: 0.0307
Epoch [28/30], Batch [2700/6000], Loss: 0.0318
Epoch [28/30], Batch [2800/6000], Loss: 0.0341
Epoch [28/30], Batch [2900/6000], Loss: 0.0315
Epoch [28/30], Batch [3000/6000], Loss: 0.0288
Epoch [28/30], Batch [3100/6000], Loss: 0.0292
Epoch [28/30], Batch [3200/6000], Loss: 0.0286
Epoch [28/30], Batch [3300/6000], Loss: 0.0312
Epoch [28/30], Batch [3400/6000], Loss: 0.0299
Epoch [28/30], Batch [3500/6000], Loss: 0.0376
Epoch [28/30], Batch [3600/6000], Loss: 0.0344
Epoch [28/30], Batch [3700/6000], Loss: 0.0298
Epoch [28/30], Batch [3800/6000], Loss: 0.0317
Epoch [28/30], Batch [3900/6000], Loss: 0.0389
Epoch [28/30], Batch [4000/6000], Loss: 0.0304
Epoch [28/30], Batch [4100/6000], Loss: 0.0428
Epoch [28/30], Batch [4200/6000], Loss: 0.0866
Epoch [28/30], Batch [4300/6000], Loss: 0.0305
Epoch [28/30], Batch [4400/6000], Loss: 0.0350
Epoch [28/30], Batch [4500/6000], Loss: 0.0328
Epoch [28/30], Batch [4600/6000], Loss: 0.0317
Epoch [28/30], Batch [4700/6000], Loss: 0.0334
Epoch [28/30], Batch [4800/6000], Loss: 0.0368
Epoch [28/30], Batch [4900/6000], Loss: 0.0309
Epoch [28/30], Batch [5000/6000], Loss: 0.0293
Epoch [28/30], Batch [5100/6000], Loss: 0.0310
Epoch [28/30], Batch [5200/6000], Loss: 0.0352
Epoch [28/30], Batch [5300/6000], Loss: 0.0339
Epoch [28/30], Batch [5400/6000], Loss: 0.0363
Epoch [28/30], Batch [5500/6000], Loss: 0.0299
Epoch [28/30], Batch [5600/6000], Loss: 0.0351
Epoch [28/30], Batch [5700/6000], Loss: 0.0345
Epoch [28/30], Batch [5800/6000], Loss: 0.0338
Epoch [28/30], Batch [5900/6000], Loss: 0.0409
Epoch [28/30], Loss: 0.0337
Epoch [29/30], Batch [0/6000], Loss: 0.0283
Epoch [29/30], Batch [100/6000], Loss: 0.0343
Epoch [29/30], Batch [200/6000], Loss: 0.0323
Epoch [29/30], Batch [300/6000], Loss: 0.0271
Epoch [29/30], Batch [400/6000], Loss: 0.0234
Epoch [29/30], Batch [500/6000], Loss: 0.0393
Epoch [29/30], Batch [600/6000], Loss: 0.0410
Epoch [29/30], Batch [700/6000], Loss: 0.0319
Epoch [29/30], Batch [800/6000], Loss: 0.0367
Epoch [29/30], Batch [900/6000], Loss: 0.0262
Epoch [29/30], Batch [1000/6000], Loss: 0.0310
Epoch [29/30], Batch [1100/6000], Loss: 0.0326
Epoch [29/30], Batch [1200/6000], Loss: 0.0237
Epoch [29/30], Batch [1300/6000], Loss: 0.0361
Epoch [29/30], Batch [1400/6000], Loss: 0.0347
Epoch [29/30], Batch [1500/6000], Loss: 0.0338
Epoch [29/30], Batch [1600/6000], Loss: 0.0300
Epoch [29/30], Batch [1700/6000], Loss: 0.0350
Epoch [29/30], Batch [1800/6000], Loss: 0.0344
Epoch [29/30], Batch [1900/6000], Loss: 0.0284
Epoch [29/30], Batch [2000/6000], Loss: 0.0401
Epoch [29/30], Batch [2100/6000], Loss: 0.0406
Epoch [29/30], Batch [2200/6000], Loss: 0.0254
Epoch [29/30], Batch [2300/6000], Loss: 0.0406
Epoch [29/30], Batch [2400/6000], Loss: 0.0311
Epoch [29/30], Batch [2500/6000], Loss: 0.0328
Epoch [29/30], Batch [2600/6000], Loss: 0.0249
Epoch [29/30], Batch [2700/6000], Loss: 0.0301
Epoch [29/30], Batch [2800/6000], Loss: 0.0317
Epoch [29/30], Batch [2900/6000], Loss: 0.0269
Epoch [29/30], Batch [3000/6000], Loss: 0.0308
Epoch [29/30], Batch [3100/6000], Loss: 0.0311
Epoch [29/30], Batch [3200/6000], Loss: 0.0279
Epoch [29/30], Batch [3300/6000], Loss: 0.0308
Epoch [29/30], Batch [3400/6000], Loss: 0.0242
Epoch [29/30], Batch [3500/6000], Loss: 0.0287
Epoch [29/30], Batch [3600/6000], Loss: 0.0440
Epoch [29/30], Batch [3700/6000], Loss: 0.0278
Epoch [29/30], Batch [3800/6000], Loss: 0.0294
Epoch [29/30], Batch [3900/6000], Loss: 0.0358
Epoch [29/30], Batch [4000/6000], Loss: 0.0457
Epoch [29/30], Batch [4100/6000], Loss: 0.0264
Epoch [29/30], Batch [4200/6000], Loss: 0.0518
Epoch [29/30], Batch [4300/6000], Loss: 0.0394
Epoch [29/30], Batch [4400/6000], Loss: 0.0347
Epoch [29/30], Batch [4500/6000], Loss: 0.0351
Epoch [29/30], Batch [4600/6000], Loss: 0.0282
Epoch [29/30], Batch [4700/6000], Loss: 0.0346
Epoch [29/30], Batch [4800/6000], Loss: 0.0345
Epoch [29/30], Batch [4900/6000], Loss: 0.0347
Epoch [29/30], Batch [5000/6000], Loss: 0.0423
Epoch [29/30], Batch [5100/6000], Loss: 0.0593
Epoch [29/30], Batch [5200/6000], Loss: 0.0264
Epoch [29/30], Batch [5300/6000], Loss: 0.0406
Epoch [29/30], Batch [5400/6000], Loss: 0.0320
Epoch [29/30], Batch [5500/6000], Loss: 0.0358
Epoch [29/30], Batch [5600/6000], Loss: 0.0373
Epoch [29/30], Batch [5700/6000], Loss: 0.0271
Epoch [29/30], Batch [5800/6000], Loss: 0.0663
Epoch [29/30], Batch [5900/6000], Loss: 0.0290
Epoch [29/30], Loss: 0.0332
Epoch [30/30], Batch [0/6000], Loss: 0.0354
Epoch [30/30], Batch [100/6000], Loss: 0.0301
Epoch [30/30], Batch [200/6000], Loss: 0.0272
Epoch [30/30], Batch [300/6000], Loss: 0.0390
Epoch [30/30], Batch [400/6000], Loss: 0.0278
Epoch [30/30], Batch [500/6000], Loss: 0.0278
Epoch [30/30], Batch [600/6000], Loss: 0.0305
Epoch [30/30], Batch [700/6000], Loss: 0.0294
Epoch [30/30], Batch [800/6000], Loss: 0.0236
Epoch [30/30], Batch [900/6000], Loss: 0.0265
Epoch [30/30], Batch [1000/6000], Loss: 0.0267
Epoch [30/30], Batch [1100/6000], Loss: 0.0341
Epoch [30/30], Batch [1200/6000], Loss: 0.0325
Epoch [30/30], Batch [1300/6000], Loss: 0.0328
Epoch [30/30], Batch [1400/6000], Loss: 0.0339
Epoch [30/30], Batch [1500/6000], Loss: 0.0235
Epoch [30/30], Batch [1600/6000], Loss: 0.0290
Epoch [30/30], Batch [1700/6000], Loss: 0.0314
Epoch [30/30], Batch [1800/6000], Loss: 0.0279
Epoch [30/30], Batch [1900/6000], Loss: 0.0326
Epoch [30/30], Batch [2000/6000], Loss: 0.0355
Epoch [30/30], Batch [2100/6000], Loss: 0.0275
Epoch [30/30], Batch [2200/6000], Loss: 0.0343
Epoch [30/30], Batch [2300/6000], Loss: 0.0379
Epoch [30/30], Batch [2400/6000], Loss: 0.0283
Epoch [30/30], Batch [2500/6000], Loss: 0.1519
Epoch [30/30], Batch [2600/6000], Loss: 0.0393
Epoch [30/30], Batch [2700/6000], Loss: 0.0263
Epoch [30/30], Batch [2800/6000], Loss: 0.0300
Epoch [30/30], Batch [2900/6000], Loss: 0.0350
Epoch [30/30], Batch [3000/6000], Loss: 0.0294
Epoch [30/30], Batch [3100/6000], Loss: 0.0278
Epoch [30/30], Batch [3200/6000], Loss: 0.0369
Epoch [30/30], Batch [3300/6000], Loss: 0.0342
Epoch [30/30], Batch [3400/6000], Loss: 0.0381
Epoch [30/30], Batch [3500/6000], Loss: 0.0293
Epoch [30/30], Batch [3600/6000], Loss: 0.0265
Epoch [30/30], Batch [3700/6000], Loss: 0.0257
Epoch [30/30], Batch [3800/6000], Loss: 0.0300
Epoch [30/30], Batch [3900/6000], Loss: 0.0328
Epoch [30/30], Batch [4000/6000], Loss: 0.0322
Epoch [30/30], Batch [4100/6000], Loss: 0.0283
Epoch [30/30], Batch [4200/6000], Loss: 0.0263
Epoch [30/30], Batch [4300/6000], Loss: 0.0273
Epoch [30/30], Batch [4400/6000], Loss: 0.0275
Epoch [30/30], Batch [4500/6000], Loss: 0.0238
Epoch [30/30], Batch [4600/6000], Loss: 0.0852
Epoch [30/30], Batch [4700/6000], Loss: 0.0371
Epoch [30/30], Batch [4800/6000], Loss: 0.0335
Epoch [30/30], Batch [4900/6000], Loss: 0.0361
Epoch [30/30], Batch [5000/6000], Loss: 0.0291
Epoch [30/30], Batch [5100/6000], Loss: 0.0335
Epoch [30/30], Batch [5200/6000], Loss: 0.0443
Epoch [30/30], Batch [5300/6000], Loss: 0.0326
Epoch [30/30], Batch [5400/6000], Loss: 0.0256
Epoch [30/30], Batch [5500/6000], Loss: 0.0363
Epoch [30/30], Batch [5600/6000], Loss: 0.0358
Epoch [30/30], Batch [5700/6000], Loss: 0.0314
Epoch [30/30], Batch [5800/6000], Loss: 0.0230
Epoch [30/30], Batch [5900/6000], Loss: 0.0291
Epoch [30/30], Loss: 0.0327
Test Loss: 0.0166, Accuracy: 98.36%
Visualization saved to adversarial_figures/reconstruction.png
  Output probs: [[0.057 0.    0.002 0.    0.004 0.001 0.    0.818 0.    0.117]]
Adversarial Training Loop 1/300:
  Label Loss: 0.2468
  Image Loss: 0.0149
  Total Loss: 0.1383
  Image grad max: 0.0419623926281929
  Output probs: [[0.099 0.    0.01  0.    0.005 0.001 0.    0.797 0.    0.087]]
Adversarial Training Loop 2/300:
  Label Loss: 0.1700
  Image Loss: 0.0147
  Total Loss: 0.0997
  Image grad max: 0.0405425950884819
  Output probs: [[0.147 0.001 0.043 0.001 0.005 0.001 0.    0.741 0.001 0.061]]
Adversarial Training Loop 3/300:
  Label Loss: 0.1031
  Image Loss: 0.0147
  Total Loss: 0.0662
  Image grad max: 0.03662164881825447
  Output probs: [[0.179 0.002 0.148 0.001 0.004 0.001 0.    0.625 0.003 0.038]]
Adversarial Training Loop 4/300:
  Label Loss: 0.0499
  Image Loss: 0.0147
  Total Loss: 0.0397
  Image grad max: 0.027492806315422058
  Output probs: [[0.159 0.002 0.375 0.001 0.003 0.001 0.    0.434 0.004 0.02 ]]
Adversarial Training Loop 5/300:
  Label Loss: 0.0214
  Image Loss: 0.0148
  Total Loss: 0.0255
  Image grad max: 0.010996433906257153
  Output probs: [[0.099 0.002 0.639 0.001 0.002 0.    0.    0.244 0.005 0.008]]
Adversarial Training Loop 6/300:
  Label Loss: 0.0236
  Image Loss: 0.0149
  Total Loss: 0.0267
  Image grad max: 0.014222738333046436
  Output probs: [[0.054 0.001 0.795 0.001 0.001 0.    0.    0.14  0.004 0.004]]
Adversarial Training Loop 7/300:
  Label Loss: 0.0404
  Image Loss: 0.0150
  Total Loss: 0.0353
  Image grad max: 0.023976804688572884
  Output probs: [[0.033 0.001 0.856 0.001 0.001 0.    0.    0.103 0.003 0.002]]
Adversarial Training Loop 8/300:
  Label Loss: 0.0523
  Image Loss: 0.0151
  Total Loss: 0.0412
  Image grad max: 0.02863292396068573
  Output probs: [[0.025 0.001 0.869 0.001 0.001 0.    0.    0.099 0.003 0.002]]
Adversarial Training Loop 9/300:
  Label Loss: 0.0532
  Image Loss: 0.0150
  Total Loss: 0.0416
  Image grad max: 0.029727492481470108
  Output probs: [[0.022 0.001 0.849 0.001 0.001 0.    0.    0.122 0.003 0.002]]
Adversarial Training Loop 10/300:
  Label Loss: 0.0441
  Image Loss: 0.0149
  Total Loss: 0.0370
  Image grad max: 0.02854250930249691
  Output probs: [[0.022 0.002 0.792 0.001 0.001 0.    0.    0.178 0.003 0.002]]
Adversarial Training Loop 11/300:
  Label Loss: 0.0285
  Image Loss: 0.0148
  Total Loss: 0.0290
  Image grad max: 0.0239796731621027
  Output probs: [[0.022 0.002 0.686 0.001 0.001 0.    0.    0.282 0.002 0.003]]
Adversarial Training Loop 12/300:
  Label Loss: 0.0128
  Image Loss: 0.0146
  Total Loss: 0.0211
  Image grad max: 0.015275448560714722
  Output probs: [[0.022 0.002 0.537 0.001 0.001 0.    0.    0.43  0.002 0.004]]
Adversarial Training Loop 13/300:
  Label Loss: 0.0040
  Image Loss: 0.0145
  Total Loss: 0.0165
  Image grad max: 0.0038336205761879683
  Output probs: [[0.02  0.003 0.388 0.001 0.002 0.    0.    0.58  0.002 0.004]]
Adversarial Training Loop 14/300:
  Label Loss: 0.0052
  Image Loss: 0.0144
  Total Loss: 0.0170
  Image grad max: 0.008663203567266464
  Output probs: [[0.016 0.003 0.282 0.001 0.002 0.    0.    0.69  0.001 0.005]]
Adversarial Training Loop 15/300:
  Label Loss: 0.0125
  Image Loss: 0.0143
  Total Loss: 0.0205
  Image grad max: 0.017191575840115547
  Output probs: [[0.014 0.002 0.228 0.001 0.002 0.    0.    0.748 0.001 0.004]]
Adversarial Training Loop 16/300:
  Label Loss: 0.0192
  Image Loss: 0.0142
  Total Loss: 0.0238
  Image grad max: 0.021628718823194504
  Output probs: [[0.012 0.002 0.215 0.001 0.002 0.    0.    0.763 0.001 0.004]]
Adversarial Training Loop 17/300:
  Label Loss: 0.0212
  Image Loss: 0.0141
  Total Loss: 0.0247
  Image grad max: 0.02271820791065693
  Output probs: [[0.011 0.002 0.234 0.001 0.002 0.    0.    0.744 0.001 0.004]]
Adversarial Training Loop 18/300:
  Label Loss: 0.0180
  Image Loss: 0.0140
  Total Loss: 0.0230
  Image grad max: 0.021132657304406166
  Output probs: [[0.011 0.003 0.286 0.001 0.002 0.    0.    0.694 0.001 0.003]]
Adversarial Training Loop 19/300:
  Label Loss: 0.0116
  Image Loss: 0.0139
  Total Loss: 0.0197
  Image grad max: 0.017024945467710495
  Output probs: [[0.011 0.003 0.366 0.001 0.001 0.    0.    0.614 0.001 0.003]]
Adversarial Training Loop 20/300:
  Label Loss: 0.0053
  Image Loss: 0.0138
  Total Loss: 0.0164
  Image grad max: 0.010530533269047737
  Output probs: [[0.01  0.003 0.464 0.001 0.001 0.    0.    0.517 0.001 0.002]]
Adversarial Training Loop 21/300:
  Label Loss: 0.0020
  Image Loss: 0.0137
  Total Loss: 0.0147
  Image grad max: 0.002643284620717168
  Output probs: [[0.009 0.002 0.559 0.001 0.001 0.    0.    0.424 0.002 0.002]]
Adversarial Training Loop 22/300:
  Label Loss: 0.0026
  Image Loss: 0.0136
  Total Loss: 0.0149
  Image grad max: 0.004959296900779009
  Output probs: [[0.008 0.002 0.629 0.001 0.001 0.    0.    0.356 0.002 0.002]]
Adversarial Training Loop 23/300:
  Label Loss: 0.0056
  Image Loss: 0.0135
  Total Loss: 0.0162
  Image grad max: 0.010678740218281746
  Output probs: [[0.007 0.002 0.669 0.001 0.001 0.    0.    0.317 0.002 0.001]]
Adversarial Training Loop 24/300:
  Label Loss: 0.0082
  Image Loss: 0.0133
  Total Loss: 0.0174
  Image grad max: 0.01394643634557724
  Output probs: [[0.007 0.002 0.679 0.001 0.001 0.    0.    0.307 0.002 0.001]]
Adversarial Training Loop 25/300:
  Label Loss: 0.0090
  Image Loss: 0.0132
  Total Loss: 0.0177
  Image grad max: 0.014800035394728184
  Output probs: [[0.007 0.002 0.663 0.001 0.001 0.    0.    0.324 0.001 0.001]]
Adversarial Training Loop 26/300:
  Label Loss: 0.0076
  Image Loss: 0.0130
  Total Loss: 0.0168
  Image grad max: 0.0134622473269701
  Output probs: [[0.007 0.002 0.622 0.001 0.001 0.    0.    0.364 0.001 0.001]]
Adversarial Training Loop 27/300:
  Label Loss: 0.0049
  Image Loss: 0.0128
  Total Loss: 0.0153
  Image grad max: 0.010173403657972813
  Output probs: [[0.007 0.002 0.564 0.001 0.001 0.    0.    0.423 0.001 0.002]]
Adversarial Training Loop 28/300:
  Label Loss: 0.0024
  Image Loss: 0.0126
  Total Loss: 0.0139
  Image grad max: 0.005384542979300022
  Output probs: [[0.007 0.002 0.497 0.001 0.001 0.    0.    0.489 0.001 0.002]]
Adversarial Training Loop 29/300:
  Label Loss: 0.0014
  Image Loss: 0.0124
  Total Loss: 0.0132
  Image grad max: 0.0018448225455358624
  Output probs: [[0.007 0.002 0.435 0.001 0.001 0.    0.    0.551 0.001 0.002]]
Adversarial Training Loop 30/300:
  Label Loss: 0.0021
  Image Loss: 0.0123
  Total Loss: 0.0133
  Image grad max: 0.005087749566882849
  Output probs: [[0.006 0.002 0.389 0.001 0.001 0.    0.    0.597 0.001 0.002]]
Adversarial Training Loop 31/300:
  Label Loss: 0.0037
  Image Loss: 0.0121
  Total Loss: 0.0139
  Image grad max: 0.008791537955403328
  Output probs: [[0.006 0.002 0.367 0.001 0.001 0.    0.    0.619 0.001 0.002]]
Adversarial Training Loop 32/300:
  Label Loss: 0.0048
  Image Loss: 0.0119
  Total Loss: 0.0143
  Image grad max: 0.010625324212014675
  Output probs: [[0.006 0.002 0.368 0.001 0.001 0.    0.    0.618 0.001 0.002]]
Adversarial Training Loop 33/300:
  Label Loss: 0.0047
  Image Loss: 0.0117
  Total Loss: 0.0141
  Image grad max: 0.01056191511452198
  Output probs: [[0.006 0.002 0.39  0.001 0.001 0.    0.    0.596 0.001 0.002]]
Adversarial Training Loop 34/300:
  Label Loss: 0.0036
  Image Loss: 0.0116
  Total Loss: 0.0134
  Image grad max: 0.00876933429390192
  Output probs: [[0.006 0.002 0.429 0.001 0.001 0.    0.    0.558 0.001 0.002]]
Adversarial Training Loop 35/300:
  Label Loss: 0.0022
  Image Loss: 0.0114
  Total Loss: 0.0125
  Image grad max: 0.005622463766485453
  Output probs: [[0.006 0.002 0.476 0.001 0.001 0.    0.    0.511 0.001 0.002]]
Adversarial Training Loop 36/300:
  Label Loss: 0.0014
  Image Loss: 0.0113
  Total Loss: 0.0119
  Image grad max: 0.0020273616537451744
  Output probs: [[0.006 0.002 0.522 0.001 0.001 0.    0.    0.466 0.001 0.002]]
Adversarial Training Loop 37/300:
  Label Loss: 0.0014
  Image Loss: 0.0111
  Total Loss: 0.0118
  Image grad max: 0.0023582109715789557
  Output probs: [[0.006 0.002 0.557 0.001 0.001 0.    0.    0.431 0.001 0.002]]
Adversarial Training Loop 38/300:
  Label Loss: 0.0021
  Image Loss: 0.0110
  Total Loss: 0.0120
  Image grad max: 0.004920955281704664
  Output probs: [[0.005 0.002 0.577 0.001 0.001 0.    0.    0.411 0.001 0.001]]
Adversarial Training Loop 39/300:
  Label Loss: 0.0026
  Image Loss: 0.0108
  Total Loss: 0.0121
  Image grad max: 0.006560024805366993
  Output probs: [[0.005 0.002 0.579 0.001 0.001 0.    0.    0.409 0.001 0.001]]
Adversarial Training Loop 40/300:
  Label Loss: 0.0027
  Image Loss: 0.0107
  Total Loss: 0.0120
  Image grad max: 0.006752760615199804
  Output probs: [[0.005 0.002 0.565 0.001 0.001 0.    0.    0.423 0.001 0.002]]
Adversarial Training Loop 41/300:
  Label Loss: 0.0022
  Image Loss: 0.0105
  Total Loss: 0.0116
  Image grad max: 0.005583038087934256
  Output probs: [[0.005 0.002 0.538 0.001 0.001 0.    0.    0.45  0.001 0.002]]
Adversarial Training Loop 42/300:
  Label Loss: 0.0016
  Image Loss: 0.0103
  Total Loss: 0.0112
  Image grad max: 0.0033422589767724276
  Output probs: [[0.005 0.002 0.504 0.001 0.001 0.    0.    0.484 0.001 0.002]]
Adversarial Training Loop 43/300:
  Label Loss: 0.0013
  Image Loss: 0.0102
  Total Loss: 0.0108
  Image grad max: 0.0017551840282976627
  Output probs: [[0.005 0.002 0.471 0.001 0.001 0.    0.    0.516 0.001 0.002]]
Adversarial Training Loop 44/300:
  Label Loss: 0.0014
  Image Loss: 0.0100
  Total Loss: 0.0107
  Image grad max: 0.0022101704962551594
  Output probs: [[0.005 0.002 0.446 0.001 0.001 0.    0.    0.541 0.001 0.002]]
Adversarial Training Loop 45/300:
  Label Loss: 0.0017
  Image Loss: 0.0099
  Total Loss: 0.0107
  Image grad max: 0.004277025815099478
  Output probs: [[0.005 0.002 0.434 0.001 0.001 0.    0.    0.554 0.001 0.002]]
Adversarial Training Loop 46/300:
  Label Loss: 0.0020
  Image Loss: 0.0097
  Total Loss: 0.0107
  Image grad max: 0.005347341299057007
  Output probs: [[0.005 0.002 0.435 0.001 0.001 0.    0.    0.553 0.001 0.002]]
Adversarial Training Loop 47/300:
  Label Loss: 0.0020
  Image Loss: 0.0096
  Total Loss: 0.0106
  Image grad max: 0.005281803198158741
  Output probs: [[0.005 0.002 0.448 0.001 0.001 0.    0.    0.54  0.001 0.002]]
Adversarial Training Loop 48/300:
  Label Loss: 0.0017
  Image Loss: 0.0094
  Total Loss: 0.0103
  Image grad max: 0.004181429743766785
  Output probs: [[0.005 0.002 0.469 0.001 0.001 0.    0.    0.518 0.001 0.002]]
Adversarial Training Loop 49/300:
  Label Loss: 0.0014
  Image Loss: 0.0093
  Total Loss: 0.0100
  Image grad max: 0.0023584486916661263
  Output probs: [[0.005 0.002 0.494 0.001 0.001 0.    0.    0.494 0.001 0.002]]
Adversarial Training Loop 50/300:
  Label Loss: 0.0012
  Image Loss: 0.0092
  Total Loss: 0.0098
  Image grad max: 0.00151066726539284
  Output probs: [[0.005 0.002 0.516 0.001 0.001 0.    0.    0.472 0.001 0.002]]
Adversarial Training Loop 51/300:
  Label Loss: 0.0013
  Image Loss: 0.0091
  Total Loss: 0.0097
  Image grad max: 0.0020666723139584064
  Output probs: [[0.005 0.002 0.531 0.001 0.001 0.    0.    0.457 0.001 0.002]]
Adversarial Training Loop 52/300:
  Label Loss: 0.0015
  Image Loss: 0.0090
  Total Loss: 0.0097
  Image grad max: 0.0029025946278125048
  Output probs: [[0.005 0.002 0.536 0.001 0.001 0.    0.    0.452 0.001 0.002]]
Adversarial Training Loop 53/300:
  Label Loss: 0.0016
  Image Loss: 0.0088
  Total Loss: 0.0096
  Image grad max: 0.0032773413695394993
  Output probs: [[0.005 0.002 0.53  0.001 0.001 0.    0.    0.458 0.001 0.002]]
Adversarial Training Loop 54/300:
  Label Loss: 0.0015
  Image Loss: 0.0087
  Total Loss: 0.0094
  Image grad max: 0.0028651030734181404
  Output probs: [[0.005 0.002 0.517 0.001 0.001 0.    0.    0.471 0.001 0.002]]
Adversarial Training Loop 55/300:
  Label Loss: 0.0013
  Image Loss: 0.0086
  Total Loss: 0.0092
  Image grad max: 0.002082841470837593
  Output probs: [[0.005 0.002 0.499 0.001 0.001 0.    0.    0.489 0.001 0.002]]
Adversarial Training Loop 56/300:
  Label Loss: 0.0012
  Image Loss: 0.0085
  Total Loss: 0.0091
  Image grad max: 0.0015275076730176806
  Output probs: [[0.005 0.002 0.481 0.001 0.001 0.    0.    0.507 0.001 0.002]]
Adversarial Training Loop 57/300:
  Label Loss: 0.0013
  Image Loss: 0.0083
  Total Loss: 0.0090
  Image grad max: 0.0017674651462584734
  Output probs: [[0.005 0.002 0.468 0.001 0.001 0.    0.    0.52  0.001 0.002]]
Adversarial Training Loop 58/300:
  Label Loss: 0.0014
  Image Loss: 0.0082
  Total Loss: 0.0089
  Image grad max: 0.0025437057483941317
  Output probs: [[0.005 0.002 0.462 0.001 0.001 0.    0.    0.525 0.001 0.002]]
Adversarial Training Loop 59/300:
  Label Loss: 0.0015
  Image Loss: 0.0081
  Total Loss: 0.0088
  Image grad max: 0.0030321648810058832
  Output probs: [[0.005 0.002 0.465 0.001 0.001 0.    0.    0.523 0.001 0.002]]
Adversarial Training Loop 60/300:
  Label Loss: 0.0014
  Image Loss: 0.0080
  Total Loss: 0.0087
  Image grad max: 0.0028250531759113073
  Output probs: [[0.005 0.002 0.474 0.001 0.001 0.    0.    0.514 0.001 0.002]]
Adversarial Training Loop 61/300:
  Label Loss: 0.0013
  Image Loss: 0.0079
  Total Loss: 0.0085
  Image grad max: 0.002053696196526289
  Output probs: [[0.005 0.002 0.487 0.001 0.001 0.    0.    0.5   0.002 0.002]]
Adversarial Training Loop 62/300:
  Label Loss: 0.0012
  Image Loss: 0.0078
  Total Loss: 0.0084
  Image grad max: 0.0014767867978662252
  Output probs: [[0.005 0.002 0.501 0.001 0.001 0.    0.    0.487 0.002 0.002]]
Adversarial Training Loop 63/300:
  Label Loss: 0.0012
  Image Loss: 0.0077
  Total Loss: 0.0083
  Image grad max: 0.0014968964969739318
  Output probs: [[0.005 0.002 0.511 0.001 0.001 0.    0.    0.477 0.002 0.002]]
Adversarial Training Loop 64/300:
  Label Loss: 0.0013
  Image Loss: 0.0076
  Total Loss: 0.0082
  Image grad max: 0.0017647059867158532
  Output probs: [[0.005 0.002 0.516 0.001 0.001 0.    0.    0.472 0.002 0.002]]
Adversarial Training Loop 65/300:
  Label Loss: 0.0013
  Image Loss: 0.0075
  Total Loss: 0.0082
  Image grad max: 0.002033521421253681
  Output probs: [[0.005 0.002 0.514 0.001 0.001 0.    0.    0.474 0.002 0.002]]
Adversarial Training Loop 66/300:
  Label Loss: 0.0013
  Image Loss: 0.0074
  Total Loss: 0.0081
  Image grad max: 0.0019406182691454887
  Output probs: [[0.005 0.002 0.507 0.001 0.001 0.    0.    0.481 0.002 0.002]]
Adversarial Training Loop 67/300:
  Label Loss: 0.0013
  Image Loss: 0.0073
  Total Loss: 0.0079
  Image grad max: 0.001579851028509438
  Output probs: [[0.005 0.002 0.497 0.001 0.001 0.    0.    0.491 0.002 0.002]]
Adversarial Training Loop 68/300:
  Label Loss: 0.0012
  Image Loss: 0.0072
  Total Loss: 0.0078
  Image grad max: 0.0013749958015978336
  Output probs: [[0.005 0.002 0.487 0.001 0.001 0.    0.    0.501 0.002 0.002]]
Adversarial Training Loop 69/300:
  Label Loss: 0.0012
  Image Loss: 0.0071
  Total Loss: 0.0077
  Image grad max: 0.0014533434296026826
  Output probs: [[0.005 0.002 0.48  0.001 0.001 0.    0.    0.508 0.002 0.002]]
Adversarial Training Loop 70/300:
  Label Loss: 0.0013
  Image Loss: 0.0070
  Total Loss: 0.0077
  Image grad max: 0.0017764695221558213
  Output probs: [[0.005 0.002 0.477 0.001 0.001 0.    0.    0.511 0.002 0.002]]
Adversarial Training Loop 71/300:
  Label Loss: 0.0013
  Image Loss: 0.0069
  Total Loss: 0.0076
  Image grad max: 0.001905506127513945
  Output probs: [[0.005 0.002 0.479 0.001 0.001 0.    0.    0.509 0.002 0.002]]
Adversarial Training Loop 72/300:
  Label Loss: 0.0013
  Image Loss: 0.0068
  Total Loss: 0.0075
  Image grad max: 0.0018193931318819523
  Output probs: [[0.005 0.002 0.484 0.001 0.001 0.    0.    0.503 0.002 0.002]]
Adversarial Training Loop 73/300:
  Label Loss: 0.0012
  Image Loss: 0.0068
  Total Loss: 0.0074
  Image grad max: 0.0015584760112687945
  Output probs: [[0.005 0.002 0.492 0.001 0.001 0.    0.    0.496 0.002 0.002]]
Adversarial Training Loop 74/300:
  Label Loss: 0.0012
  Image Loss: 0.0067
  Total Loss: 0.0073
  Image grad max: 0.001211209804750979
  Output probs: [[0.005 0.001 0.499 0.001 0.001 0.    0.    0.488 0.002 0.002]]
Adversarial Training Loop 75/300:
  Label Loss: 0.0012
  Image Loss: 0.0066
  Total Loss: 0.0072
  Image grad max: 0.0013439040631055832
  Output probs: [[0.005 0.001 0.504 0.001 0.001 0.    0.    0.484 0.002 0.002]]
Adversarial Training Loop 76/300:
  Label Loss: 0.0012
  Image Loss: 0.0065
  Total Loss: 0.0072
  Image grad max: 0.001429257681593299
  Output probs: [[0.005 0.001 0.506 0.001 0.001 0.    0.    0.482 0.002 0.002]]
Adversarial Training Loop 77/300:
  Label Loss: 0.0012
  Image Loss: 0.0065
  Total Loss: 0.0071
  Image grad max: 0.0014433740871027112
  Output probs: [[0.005 0.001 0.503 0.001 0.001 0.    0.    0.485 0.002 0.002]]
Adversarial Training Loop 78/300:
  Label Loss: 0.0012
  Image Loss: 0.0064
  Total Loss: 0.0070
  Image grad max: 0.0013850941322743893
  Output probs: [[0.005 0.001 0.498 0.001 0.001 0.    0.    0.49  0.002 0.002]]
Adversarial Training Loop 79/300:
  Label Loss: 0.0012
  Image Loss: 0.0063
  Total Loss: 0.0069
  Image grad max: 0.0012737445067614317
  Output probs: [[0.005 0.001 0.492 0.001 0.001 0.    0.    0.496 0.002 0.002]]
Adversarial Training Loop 80/300:
  Label Loss: 0.0012
  Image Loss: 0.0062
  Total Loss: 0.0068
  Image grad max: 0.0011859156657010317
  Output probs: [[0.005 0.001 0.487 0.001 0.001 0.    0.    0.501 0.002 0.002]]
Adversarial Training Loop 81/300:
  Label Loss: 0.0012
  Image Loss: 0.0062
  Total Loss: 0.0068
  Image grad max: 0.001404237817041576
  Output probs: [[0.005 0.001 0.485 0.001 0.001 0.    0.    0.504 0.002 0.002]]
Adversarial Training Loop 82/300:
  Label Loss: 0.0012
  Image Loss: 0.0061
  Total Loss: 0.0067
  Image grad max: 0.0015170266851782799
  Output probs: [[0.005 0.001 0.485 0.001 0.001 0.    0.    0.503 0.002 0.002]]
Adversarial Training Loop 83/300:
  Label Loss: 0.0012
  Image Loss: 0.0060
  Total Loss: 0.0066
  Image grad max: 0.0014979271218180656
  Output probs: [[0.005 0.001 0.488 0.001 0.001 0.    0.    0.5   0.002 0.002]]
Adversarial Training Loop 84/300:
  Label Loss: 0.0012
  Image Loss: 0.0060
  Total Loss: 0.0066
  Image grad max: 0.0013632196933031082
  Output probs: [[0.005 0.001 0.492 0.001 0.001 0.    0.    0.496 0.002 0.002]]
Adversarial Training Loop 85/300:
  Label Loss: 0.0012
  Image Loss: 0.0059
  Total Loss: 0.0065
  Image grad max: 0.0011637177085503936
  Output probs: [[0.005 0.001 0.497 0.001 0.001 0.    0.    0.492 0.002 0.002]]
Adversarial Training Loop 86/300:
  Label Loss: 0.0012
  Image Loss: 0.0058
  Total Loss: 0.0064
  Image grad max: 0.0011677220463752747
  Output probs: [[0.005 0.001 0.5   0.001 0.001 0.    0.    0.489 0.002 0.002]]
Adversarial Training Loop 87/300:
  Label Loss: 0.0012
  Image Loss: 0.0058
  Total Loss: 0.0064
  Image grad max: 0.00121905910782516
  Output probs: [[0.005 0.001 0.501 0.001 0.001 0.    0.    0.488 0.002 0.002]]
Adversarial Training Loop 88/300:
  Label Loss: 0.0012
  Image Loss: 0.0057
  Total Loss: 0.0063
  Image grad max: 0.001226455788128078
  Output probs: [[0.005 0.001 0.499 0.001 0.001 0.    0.    0.489 0.002 0.002]]
Adversarial Training Loop 89/300:
  Label Loss: 0.0012
  Image Loss: 0.0057
  Total Loss: 0.0062
  Image grad max: 0.0011880197562277317
  Output probs: [[0.005 0.001 0.496 0.001 0.001 0.    0.    0.492 0.002 0.002]]
Adversarial Training Loop 90/300:
  Label Loss: 0.0012
  Image Loss: 0.0056
  Total Loss: 0.0062
  Image grad max: 0.0011515866499394178
  Output probs: [[0.005 0.001 0.493 0.001 0.001 0.    0.    0.496 0.002 0.002]]
Adversarial Training Loop 91/300:
  Label Loss: 0.0012
  Image Loss: 0.0055
  Total Loss: 0.0061
  Image grad max: 0.0011461449321359396
  Output probs: [[0.005 0.001 0.49  0.001 0.001 0.    0.    0.499 0.002 0.002]]
Adversarial Training Loop 92/300:
  Label Loss: 0.0012
  Image Loss: 0.0055
  Total Loss: 0.0061
  Image grad max: 0.001241811434738338
  Output probs: [[0.004 0.001 0.489 0.001 0.001 0.    0.    0.5   0.002 0.002]]
Adversarial Training Loop 93/300:
  Label Loss: 0.0012
  Image Loss: 0.0054
  Total Loss: 0.0060
  Image grad max: 0.001296364120207727
  Output probs: [[0.004 0.001 0.489 0.001 0.001 0.    0.    0.499 0.002 0.002]]
Adversarial Training Loop 94/300:
  Label Loss: 0.0012
  Image Loss: 0.0054
  Total Loss: 0.0059
  Image grad max: 0.001268738298676908
  Output probs: [[0.004 0.001 0.491 0.001 0.001 0.    0.    0.497 0.002 0.002]]
Adversarial Training Loop 95/300:
  Label Loss: 0.0011
  Image Loss: 0.0053
  Total Loss: 0.0059
  Image grad max: 0.0011730747064575553
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.495 0.002 0.002]]
Adversarial Training Loop 96/300:
  Label Loss: 0.0011
  Image Loss: 0.0053
  Total Loss: 0.0058
  Image grad max: 0.0011470606550574303
  Output probs: [[0.004 0.001 0.496 0.001 0.001 0.    0.    0.492 0.002 0.002]]
Adversarial Training Loop 97/300:
  Label Loss: 0.0011
  Image Loss: 0.0052
  Total Loss: 0.0058
  Image grad max: 0.0011504010763019323
  Output probs: [[0.004 0.001 0.498 0.001 0.001 0.    0.    0.491 0.002 0.002]]
Adversarial Training Loop 98/300:
  Label Loss: 0.0011
  Image Loss: 0.0052
  Total Loss: 0.0057
  Image grad max: 0.0011521890992298722
  Output probs: [[0.004 0.001 0.498 0.001 0.001 0.    0.    0.491 0.002 0.002]]
Adversarial Training Loop 99/300:
  Label Loss: 0.0011
  Image Loss: 0.0051
  Total Loss: 0.0057
  Image grad max: 0.0011519207619130611
  Output probs: [[0.004 0.001 0.496 0.001 0.001 0.    0.    0.493 0.002 0.002]]
Adversarial Training Loop 100/300:
  Label Loss: 0.0011
  Image Loss: 0.0051
  Total Loss: 0.0056
  Image grad max: 0.0011498542735353112
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.495 0.002 0.002]]
Adversarial Training Loop 101/300:
  Label Loss: 0.0011
  Image Loss: 0.0050
  Total Loss: 0.0056
  Image grad max: 0.0011468668235465884
  Output probs: [[0.004 0.001 0.492 0.001 0.001 0.    0.    0.497 0.002 0.002]]
Adversarial Training Loop 102/300:
  Label Loss: 0.0011
  Image Loss: 0.0050
  Total Loss: 0.0055
  Image grad max: 0.001144037814810872
  Output probs: [[0.004 0.001 0.491 0.001 0.001 0.    0.    0.498 0.002 0.002]]
Adversarial Training Loop 103/300:
  Label Loss: 0.0011
  Image Loss: 0.0049
  Total Loss: 0.0055
  Image grad max: 0.0011428756406530738
  Output probs: [[0.004 0.001 0.491 0.001 0.001 0.    0.    0.498 0.002 0.002]]
Adversarial Training Loop 104/300:
  Label Loss: 0.0011
  Image Loss: 0.0049
  Total Loss: 0.0054
  Image grad max: 0.001142724184319377
  Output probs: [[0.004 0.001 0.492 0.001 0.001 0.    0.    0.497 0.002 0.002]]
Adversarial Training Loop 105/300:
  Label Loss: 0.0011
  Image Loss: 0.0048
  Total Loss: 0.0054
  Image grad max: 0.0011432347819209099
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.495 0.002 0.002]]
Adversarial Training Loop 106/300:
  Label Loss: 0.0011
  Image Loss: 0.0048
  Total Loss: 0.0053
  Image grad max: 0.0011452276958152652
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.494 0.002 0.002]]
Adversarial Training Loop 107/300:
  Label Loss: 0.0011
  Image Loss: 0.0047
  Total Loss: 0.0053
  Image grad max: 0.0011471257312223315
  Output probs: [[0.004 0.001 0.496 0.001 0.001 0.    0.    0.493 0.002 0.002]]
Adversarial Training Loop 108/300:
  Label Loss: 0.0011
  Image Loss: 0.0047
  Total Loss: 0.0052
  Image grad max: 0.0011483359849080443
  Output probs: [[0.004 0.001 0.496 0.001 0.001 0.    0.    0.493 0.002 0.002]]
Adversarial Training Loop 109/300:
  Label Loss: 0.0011
  Image Loss: 0.0046
  Total Loss: 0.0052
  Image grad max: 0.0011484140995889902
  Output probs: [[0.004 0.001 0.496 0.001 0.001 0.    0.    0.493 0.002 0.002]]
Adversarial Training Loop 110/300:
  Label Loss: 0.0011
  Image Loss: 0.0046
  Total Loss: 0.0052
  Image grad max: 0.001147389761172235
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.495 0.002 0.002]]
Adversarial Training Loop 111/300:
  Label Loss: 0.0011
  Image Loss: 0.0046
  Total Loss: 0.0051
  Image grad max: 0.0011457105865702033
  Output probs: [[0.004 0.001 0.493 0.001 0.001 0.    0.    0.496 0.002 0.002]]
Adversarial Training Loop 112/300:
  Label Loss: 0.0011
  Image Loss: 0.0045
  Total Loss: 0.0051
  Image grad max: 0.0011441035894677043
  Output probs: [[0.004 0.001 0.493 0.001 0.001 0.    0.    0.497 0.002 0.002]]
Adversarial Training Loop 113/300:
  Label Loss: 0.0011
  Image Loss: 0.0045
  Total Loss: 0.0050
  Image grad max: 0.001143057830631733
  Output probs: [[0.004 0.001 0.493 0.001 0.001 0.    0.    0.497 0.002 0.002]]
Adversarial Training Loop 114/300:
  Label Loss: 0.0011
  Image Loss: 0.0044
  Total Loss: 0.0050
  Image grad max: 0.0011429445585235953
  Output probs: [[0.004 0.001 0.493 0.001 0.001 0.    0.    0.496 0.002 0.002]]
Adversarial Training Loop 115/300:
  Label Loss: 0.0011
  Image Loss: 0.0044
  Total Loss: 0.0049
  Image grad max: 0.0011435679625719786
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.495 0.002 0.002]]
Adversarial Training Loop 116/300:
  Label Loss: 0.0011
  Image Loss: 0.0044
  Total Loss: 0.0049
  Image grad max: 0.0011445996351540089
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.494 0.002 0.002]]
Adversarial Training Loop 117/300:
  Label Loss: 0.0011
  Image Loss: 0.0043
  Total Loss: 0.0049
  Image grad max: 0.0011455935891717672
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.494 0.002 0.002]]
Adversarial Training Loop 118/300:
  Label Loss: 0.0011
  Image Loss: 0.0043
  Total Loss: 0.0048
  Image grad max: 0.0011461697285994887
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.494 0.002 0.002]]
Adversarial Training Loop 119/300:
  Label Loss: 0.0011
  Image Loss: 0.0043
  Total Loss: 0.0048
  Image grad max: 0.0011460828827694058
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.494 0.002 0.002]]
Adversarial Training Loop 120/300:
  Label Loss: 0.0011
  Image Loss: 0.0042
  Total Loss: 0.0048
  Image grad max: 0.0011453949846327305
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.495 0.002 0.002]]
Adversarial Training Loop 121/300:
  Label Loss: 0.0011
  Image Loss: 0.0042
  Total Loss: 0.0047
  Image grad max: 0.0011443938128650188
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.002 0.002]]
Adversarial Training Loop 122/300:
  Label Loss: 0.0011
  Image Loss: 0.0042
  Total Loss: 0.0047
  Image grad max: 0.001143469475209713
  Output probs: [[0.004 0.001 0.493 0.001 0.001 0.    0.    0.496 0.002 0.002]]
Adversarial Training Loop 123/300:
  Label Loss: 0.0011
  Image Loss: 0.0041
  Total Loss: 0.0047
  Image grad max: 0.001142934081144631
  Output probs: [[0.004 0.001 0.493 0.001 0.001 0.    0.    0.496 0.002 0.002]]
Adversarial Training Loop 124/300:
  Label Loss: 0.0011
  Image Loss: 0.0041
  Total Loss: 0.0046
  Image grad max: 0.0011429719161242247
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.002 0.002]]
Adversarial Training Loop 125/300:
  Label Loss: 0.0011
  Image Loss: 0.0041
  Total Loss: 0.0046
  Image grad max: 0.001143463421612978
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.495 0.002 0.002]]
Adversarial Training Loop 126/300:
  Label Loss: 0.0011
  Image Loss: 0.0040
  Total Loss: 0.0046
  Image grad max: 0.0011441140668466687
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.002 0.002]]
Adversarial Training Loop 127/300:
  Label Loss: 0.0011
  Image Loss: 0.0040
  Total Loss: 0.0045
  Image grad max: 0.001144618378020823
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.494 0.002 0.002]]
Adversarial Training Loop 128/300:
  Label Loss: 0.0011
  Image Loss: 0.0040
  Total Loss: 0.0045
  Image grad max: 0.0011447573779150844
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 129/300:
  Label Loss: 0.0010
  Image Loss: 0.0039
  Total Loss: 0.0045
  Image grad max: 0.0011444969568401575
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 130/300:
  Label Loss: 0.0010
  Image Loss: 0.0039
  Total Loss: 0.0044
  Image grad max: 0.001144038513302803
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 131/300:
  Label Loss: 0.0010
  Image Loss: 0.0039
  Total Loss: 0.0044
  Image grad max: 0.001143473549745977
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 132/300:
  Label Loss: 0.0010
  Image Loss: 0.0039
  Total Loss: 0.0044
  Image grad max: 0.0011430010199546814
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 133/300:
  Label Loss: 0.0010
  Image Loss: 0.0038
  Total Loss: 0.0044
  Image grad max: 0.0011427794815972447
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 134/300:
  Label Loss: 0.0010
  Image Loss: 0.0038
  Total Loss: 0.0043
  Image grad max: 0.0011429068399593234
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 135/300:
  Label Loss: 0.0010
  Image Loss: 0.0038
  Total Loss: 0.0043
  Image grad max: 0.0011432630708441138
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 136/300:
  Label Loss: 0.0010
  Image Loss: 0.0038
  Total Loss: 0.0043
  Image grad max: 0.0011436494532972574
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 137/300:
  Label Loss: 0.0010
  Image Loss: 0.0037
  Total Loss: 0.0042
  Image grad max: 0.0011438685469329357
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 138/300:
  Label Loss: 0.0010
  Image Loss: 0.0037
  Total Loss: 0.0042
  Image grad max: 0.0011438240762799978
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 139/300:
  Label Loss: 0.0010
  Image Loss: 0.0037
  Total Loss: 0.0042
  Image grad max: 0.0011435369960963726
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 140/300:
  Label Loss: 0.0010
  Image Loss: 0.0037
  Total Loss: 0.0042
  Image grad max: 0.001143127796240151
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 141/300:
  Label Loss: 0.0010
  Image Loss: 0.0036
  Total Loss: 0.0041
  Image grad max: 0.0011427587596699595
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 142/300:
  Label Loss: 0.0010
  Image Loss: 0.0036
  Total Loss: 0.0041
  Image grad max: 0.001142563414759934
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 143/300:
  Label Loss: 0.0010
  Image Loss: 0.0036
  Total Loss: 0.0041
  Image grad max: 0.0011425893753767014
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 144/300:
  Label Loss: 0.0010
  Image Loss: 0.0036
  Total Loss: 0.0041
  Image grad max: 0.0011427858844399452
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 145/300:
  Label Loss: 0.0010
  Image Loss: 0.0035
  Total Loss: 0.0041
  Image grad max: 0.0011430515442043543
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 146/300:
  Label Loss: 0.0010
  Image Loss: 0.0035
  Total Loss: 0.0040
  Image grad max: 0.001143258879892528
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 147/300:
  Label Loss: 0.0010
  Image Loss: 0.0035
  Total Loss: 0.0040
  Image grad max: 0.0011432989267632365
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 148/300:
  Label Loss: 0.0010
  Image Loss: 0.0035
  Total Loss: 0.0040
  Image grad max: 0.0011431598104536533
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 149/300:
  Label Loss: 0.0010
  Image Loss: 0.0035
  Total Loss: 0.0040
  Image grad max: 0.0011428783182054758
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 150/300:
  Label Loss: 0.0010
  Image Loss: 0.0034
  Total Loss: 0.0039
  Image grad max: 0.0011425708653405309
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 151/300:
  Label Loss: 0.0010
  Image Loss: 0.0034
  Total Loss: 0.0039
  Image grad max: 0.0011423564283177257
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 152/300:
  Label Loss: 0.0010
  Image Loss: 0.0034
  Total Loss: 0.0039
  Image grad max: 0.001142300316132605
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 153/300:
  Label Loss: 0.0010
  Image Loss: 0.0034
  Total Loss: 0.0039
  Image grad max: 0.001142397872172296
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 154/300:
  Label Loss: 0.0010
  Image Loss: 0.0034
  Total Loss: 0.0039
  Image grad max: 0.0011425720294937491
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 155/300:
  Label Loss: 0.0010
  Image Loss: 0.0033
  Total Loss: 0.0038
  Image grad max: 0.0011427226709201932
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 156/300:
  Label Loss: 0.0010
  Image Loss: 0.0033
  Total Loss: 0.0038
  Image grad max: 0.001142766559496522
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 157/300:
  Label Loss: 0.0010
  Image Loss: 0.0033
  Total Loss: 0.0038
  Image grad max: 0.0011427216231822968
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 158/300:
  Label Loss: 0.0010
  Image Loss: 0.0033
  Total Loss: 0.0038
  Image grad max: 0.001142652123235166
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 159/300:
  Label Loss: 0.0010
  Image Loss: 0.0033
  Total Loss: 0.0038
  Image grad max: 0.001142481924034655
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 160/300:
  Label Loss: 0.0010
  Image Loss: 0.0033
  Total Loss: 0.0038
  Image grad max: 0.001142284949310124
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 161/300:
  Label Loss: 0.0010
  Image Loss: 0.0032
  Total Loss: 0.0037
  Image grad max: 0.0011421327944844961
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 162/300:
  Label Loss: 0.0010
  Image Loss: 0.0032
  Total Loss: 0.0037
  Image grad max: 0.0011421296512708068
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 163/300:
  Label Loss: 0.0010
  Image Loss: 0.0032
  Total Loss: 0.0037
  Image grad max: 0.0011423848336562514
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 164/300:
  Label Loss: 0.0010
  Image Loss: 0.0032
  Total Loss: 0.0037
  Image grad max: 0.001142640132457018
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 165/300:
  Label Loss: 0.0010
  Image Loss: 0.0032
  Total Loss: 0.0037
  Image grad max: 0.0011427338467910886
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 166/300:
  Label Loss: 0.0010
  Image Loss: 0.0032
  Total Loss: 0.0037
  Image grad max: 0.0011425804113969207
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 167/300:
  Label Loss: 0.0010
  Image Loss: 0.0032
  Total Loss: 0.0036
  Image grad max: 0.0011422515381127596
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 168/300:
  Label Loss: 0.0010
  Image Loss: 0.0031
  Total Loss: 0.0036
  Image grad max: 0.0011418949579820037
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 169/300:
  Label Loss: 0.0010
  Image Loss: 0.0031
  Total Loss: 0.0036
  Image grad max: 0.0011416585184633732
  Output probs: [[0.004 0.001 0.494 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 170/300:
  Label Loss: 0.0010
  Image Loss: 0.0031
  Total Loss: 0.0036
  Image grad max: 0.0011416346533223987
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 171/300:
  Label Loss: 0.0010
  Image Loss: 0.0031
  Total Loss: 0.0036
  Image grad max: 0.001141836284659803
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 172/300:
  Label Loss: 0.0010
  Image Loss: 0.0031
  Total Loss: 0.0036
  Image grad max: 0.0011420861119404435
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 173/300:
  Label Loss: 0.0010
  Image Loss: 0.0031
  Total Loss: 0.0036
  Image grad max: 0.0011422450188547373
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 174/300:
  Label Loss: 0.0010
  Image Loss: 0.0031
  Total Loss: 0.0035
  Image grad max: 0.001142233028076589
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 175/300:
  Label Loss: 0.0010
  Image Loss: 0.0030
  Total Loss: 0.0035
  Image grad max: 0.001142052817158401
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 176/300:
  Label Loss: 0.0010
  Image Loss: 0.0030
  Total Loss: 0.0035
  Image grad max: 0.0011417889036238194
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 177/300:
  Label Loss: 0.0010
  Image Loss: 0.0030
  Total Loss: 0.0035
  Image grad max: 0.0011415600311011076
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 178/300:
  Label Loss: 0.0010
  Image Loss: 0.0030
  Total Loss: 0.0035
  Image grad max: 0.0011414560722187161
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 179/300:
  Label Loss: 0.0010
  Image Loss: 0.0030
  Total Loss: 0.0035
  Image grad max: 0.001141497166827321
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 180/300:
  Label Loss: 0.0010
  Image Loss: 0.0030
  Total Loss: 0.0035
  Image grad max: 0.0011416373308748007
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 181/300:
  Label Loss: 0.0010
  Image Loss: 0.0030
  Total Loss: 0.0035
  Image grad max: 0.0011417835485190153
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 182/300:
  Label Loss: 0.0010
  Image Loss: 0.0030
  Total Loss: 0.0035
  Image grad max: 0.0011418513022363186
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 183/300:
  Label Loss: 0.0010
  Image Loss: 0.0030
  Total Loss: 0.0034
  Image grad max: 0.0011418006615713239
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 184/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0034
  Image grad max: 0.001141657237894833
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 185/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0034
  Image grad max: 0.0011414913460612297
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 186/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0034
  Image grad max: 0.0011413623578846455
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 187/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0034
  Image grad max: 0.0011413154425099492
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 188/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0034
  Image grad max: 0.0011413765605539083
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 189/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0034
  Image grad max: 0.0011414728360250592
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 190/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0034
  Image grad max: 0.001141538959927857
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 191/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0034
  Image grad max: 0.001141532906331122
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.495 0.001 0.002]]
Adversarial Training Loop 192/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0033
  Image grad max: 0.00114148436114192
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 193/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0033
  Image grad max: 0.0011414482723921537
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 194/300:
  Label Loss: 0.0010
  Image Loss: 0.0029
  Total Loss: 0.0033
  Image grad max: 0.0011413975153118372
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 195/300:
  Label Loss: 0.0010
  Image Loss: 0.0028
  Total Loss: 0.0033
  Image grad max: 0.0011413791216909885
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 196/300:
  Label Loss: 0.0010
  Image Loss: 0.0028
  Total Loss: 0.0033
  Image grad max: 0.0011413362808525562
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 197/300:
  Label Loss: 0.0010
  Image Loss: 0.0028
  Total Loss: 0.0033
  Image grad max: 0.0011412824969738722
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 198/300:
  Label Loss: 0.0010
  Image Loss: 0.0028
  Total Loss: 0.0033
  Image grad max: 0.0011412347666919231
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 199/300:
  Label Loss: 0.0010
  Image Loss: 0.0028
  Total Loss: 0.0033
  Image grad max: 0.0011412084568291903
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 200/300:
  Label Loss: 0.0010
  Image Loss: 0.0028
  Total Loss: 0.0033
  Image grad max: 0.0011412036838009953
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 201/300:
  Label Loss: 0.0010
  Image Loss: 0.0028
  Total Loss: 0.0033
  Image grad max: 0.0011412124149501324
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 202/300:
  Label Loss: 0.0010
  Image Loss: 0.0028
  Total Loss: 0.0033
  Image grad max: 0.0011412195162847638
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 203/300:
  Label Loss: 0.0010
  Image Loss: 0.0028
  Total Loss: 0.0033
  Image grad max: 0.0011412142775952816
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 204/300:
  Label Loss: 0.0010
  Image Loss: 0.0028
  Total Loss: 0.0032
  Image grad max: 0.0011411869199946523
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 205/300:
  Label Loss: 0.0009
  Image Loss: 0.0028
  Total Loss: 0.0032
  Image grad max: 0.0011411476880311966
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 206/300:
  Label Loss: 0.0009
  Image Loss: 0.0028
  Total Loss: 0.0032
  Image grad max: 0.0011411074083298445
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 207/300:
  Label Loss: 0.0009
  Image Loss: 0.0028
  Total Loss: 0.0032
  Image grad max: 0.0011410786537453532
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 208/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011410894803702831
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 209/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011411482701078057
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 210/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011411674786359072
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 211/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011411324376240373
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 212/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011410630540922284
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 213/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.001140990643762052
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 214/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011409835424274206
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 215/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011410273145884275
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 216/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011410537408664823
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 217/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011410420993342996
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 218/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011409964645281434
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 219/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0032
  Image grad max: 0.0011409376747906208
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 220/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0031
  Image grad max: 0.0011409041471779346
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 221/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0031
  Image grad max: 0.0011409306898713112
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 222/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0031
  Image grad max: 0.001140956999734044
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 223/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0031
  Image grad max: 0.001141031738370657
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 224/300:
  Label Loss: 0.0009
  Image Loss: 0.0027
  Total Loss: 0.0031
  Image grad max: 0.001141044427640736
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 225/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011409854050725698
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 226/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011408885475248098
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 227/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011407992569729686
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 228/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011407585116103292
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 229/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011407757410779595
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 230/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011408309219405055
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 231/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.001140883774496615
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 232/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011408996069803834
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 233/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011408673599362373
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 234/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011408028658479452
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 235/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011407373240217566
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 236/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011406999547034502
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 237/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011407028650864959
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 238/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011407551355659962
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 239/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011408074060454965
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 240/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0031
  Image grad max: 0.0011408196296542883
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 241/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.0011407838901504874
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 242/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.0011407195124775171
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 243/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.0011406575795263052
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 244/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.0011406256817281246
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 245/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.0011406356934458017
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 246/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.0011406721314415336
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 247/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.001140706823207438
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 248/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.0011407157871872187
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 249/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.0011406916892156005
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 250/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.0011406478006392717
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 251/300:
  Label Loss: 0.0009
  Image Loss: 0.0026
  Total Loss: 0.0030
  Image grad max: 0.0011406035628169775
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 252/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011405762052163482
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 253/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011405678233131766
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 254/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011405878467485309
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 255/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.001140613341704011
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 256/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011406269622966647
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 257/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011406148551031947
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 258/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011405842378735542
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 259/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.001140545355156064
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 260/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011405193945392966
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 261/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011405148543417454
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 262/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011405267287045717
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 263/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011405424447730184
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 264/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.001140547450631857
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 265/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011405356926843524
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 266/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.001140511129051447
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 267/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.001140483538620174
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 268/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.001140465959906578
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 269/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011404635151848197
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 270/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011404706165194511
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 271/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011404782999306917
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 272/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011404785327613354
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 273/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011404658434912562
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 274/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.001140448497608304
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 275/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011404297547414899
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 276/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0030
  Image grad max: 0.0011404171818867326
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 277/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011404226534068584
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 278/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.001140433014370501
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 279/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.001140434993430972
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 280/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011404240503907204
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 281/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.001140404725447297
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 282/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011403862154111266
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 283/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.001140375155955553
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 284/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.001140374457463622
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 285/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011404015822336078
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 286/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.001140423584729433
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 287/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011404136894270778
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 288/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.001140375854447484
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 289/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.001140363747254014
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 290/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011403512908145785
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 291/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011403386015444994
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 292/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011403263779357076
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 293/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011403189273551106
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 294/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011403149692341685
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.002]]
Adversarial Training Loop 295/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011403124080970883
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.001]]
Adversarial Training Loop 296/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011403069365769625
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.001]]
Adversarial Training Loop 297/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011402996024116874
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.001]]
Adversarial Training Loop 298/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011402873788028955
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.001]]
Adversarial Training Loop 299/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011402771342545748
  Output probs: [[0.004 0.001 0.495 0.001 0.001 0.    0.    0.496 0.001 0.001]]
Adversarial Training Loop 300/300:
  Label Loss: 0.0009
  Image Loss: 0.0025
  Total Loss: 0.0029
  Image grad max: 0.0011402692180126905
Visualization saved to adversarial_figures/adversarial_testing.png
